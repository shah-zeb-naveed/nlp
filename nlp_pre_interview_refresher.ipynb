{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/nlp/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "36f-Q0WtvfCh"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pyLDAvis scikit-learn hdbscan scipy==1.10.1 svgling --quiet --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kNfQ119kve_7"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "assert scipy.__version__ == '1.10.1'\n",
        "from __future__ import print_function\n",
        "import pyLDAvis\n",
        "#import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "#import torch\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "#from bertopic import BERTopic\n",
        "#from umap import UMAP\n",
        "\n",
        "import hdbscan\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define docs"
      ],
      "metadata": {
        "id": "-wbJfySTl6fU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSvfrKkv-ub",
        "outputId": "830ae456-04f1-4b5a-df1f-cff6caea26ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "# docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data'][0:1000]\n",
        "\n",
        "docs = [\n",
        "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\",\n",
        "    \"The tower is 324 meters tall, about the same height as an 81-story building.\",\n",
        "    \"It held this title for 41 years until the Chrysler Building in New York City was finished in 1930.\",\n",
        "    \"The tower has three levels for visitors, with restaurants on the first and second levels.\",\n",
        "    \"Tickets can be purchased to ascend by stairs or lift to the first and second levels.\",\n",
        "]\n",
        "\n",
        "\n",
        "# # Save the documents to disk\n",
        "# with open('docs.pkl', 'wb') as file:\n",
        "#     pickle.dump(docs, file)\n",
        "\n",
        "docs[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('docs.pkl', 'rb') as file:\n",
        "#     docs = pickle.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFK-Bcl7KGZM",
        "outputId": "5df905ff-be52-4148-dece-e4be11842a6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "jWlLeyIPl9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpasIcBvmBoD",
        "outputId": "916255d3-1860-4c00-decb-33db39121024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Qu6VCWHKmBlt",
        "outputId": "181c1779-0332-4313-9da6-f69996ce58e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This is the second second document.',\n",
        "    'And the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG8pMGFsmBjX",
        "outputId": "42e66d2c-4eb2-4501-98bf-fdcc8476c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 19 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "analyze(\"This is a text document to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb268R6omBhA",
        "outputId": "7ea2f1cf-dd48-46a4-f9cf-a9389b2a0e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'text', 'document', 'to', 'analyze']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()\n",
        "\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbEf9xTImBe8",
        "outputId": "d8633aab-bd38-4329-af74-5634335488e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform(['Something completely new.']).toarray() # ignored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGAYAHRmj5x",
        "outputId": "d263dc0d-483d-444e-8514-0b2311a7e7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to preserve ordering to some extent can use bigrams\n",
        "bigram_counts = CountVectorizer(ngram_range=(1,2))\n",
        "bigram_counts.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ1JQhOAmj3b",
        "outputId": "62f2c863-b01c-4ed9-e944-6a51a9f3a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4vd6ptdmj1F",
        "outputId": "7d42c116-5b11-4ed0-8af5-db3f8951b706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'and the', 'document', 'first', 'first document', 'is',\n",
              "       'is the', 'is this', 'one', 'second', 'second document',\n",
              "       'second second', 'the', 'the first', 'the second', 'the third',\n",
              "       'third', 'third one', 'this', 'this is', 'this the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "\n",
        "transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "J1IboAHSmjyN",
        "outputId": "cc8766d4-2a59-43e7-f149-400dd184c096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(smooth_idf=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer(smooth_idf=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfTransformer(smooth_idf=False)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = [[3, 0, 1],\n",
        "          [2, 0, 0],\n",
        "          [3, 0, 0],\n",
        "          [4, 0, 0],\n",
        "          [3, 2, 0],\n",
        "          [3, 0, 2]]\n",
        "tfidf = transformer.fit_transform(counts)\n",
        "tfidf\n",
        "\n",
        "tfidf.toarray() # each row a unit vector normalzied by eculidean norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBH68Wbmjvn",
        "outputId": "c60bce10-370a-4631-c80e-a9dc09c69337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x3 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81940995, 0.        , 0.57320793],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.47330339, 0.88089948, 0.        ],\n",
              "       [0.58149261, 0.        , 0.81355169]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TfidfTransformer()\n",
        "transformer.fit_transform(counts).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILrkmPBjmjsw",
        "outputId": "5c6569af-8880-40f5-ce7b-8ef31af7007d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85151335, 0.        , 0.52433293],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.55422893, 0.83236428, 0.        ],\n",
              "       [0.63035731, 0.        , 0.77630514]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.idf_ # weifhts of each feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDQQ_KrxmjqK",
        "outputId": "153b4188-78c0-4486-d719-910f776d9588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 2.25276297, 1.84729786])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPuAvFHcmjlM",
        "outputId": "a47b0bbe-33c4-440d-a871-c9ec76ffb964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674],\n",
              "       [0.        , 0.27230147, 0.        , 0.27230147, 0.        ,\n",
              "        0.85322574, 0.22262429, 0.        , 0.27230147],\n",
              "       [0.55280532, 0.        , 0.        , 0.        , 0.55280532,\n",
              "        0.        , 0.28847675, 0.55280532, 0.        ],\n",
              "       [0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short texts noisty tfidf. binary occurrence as used in naive bayes can be set in CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuU5a8Y8mjit",
        "outputId": "696f88c8-2ed2-475b-d5ed-1ea0e9e2afb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bow: cannot capture phrases/multi-words although can use ngrams, order, grammaer, potential misspellings, word derivations\n",
        "# chars can help in misspellings\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
        "counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "counts.toarray().astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5oGexxypy_R",
        "outputId": "629f609e-df09-45b7-8de3-13b317caea03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 1, 1, 1, 0],\n",
              "       [1, 1, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# across words. more noisy than white-space aware char_wb\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqW2mfzmBaQ",
        "outputId": "66225f6a-253d-4b52-f6f5-43039061e755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', ' ju', 'fox', 'jum', 'mpy', 'ox ', 'py ', 'ump'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x7 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 7 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', 'fox', 'jum', 'mpy', 'py ', 'ump', 'y f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGjXSy2frFCb",
        "outputId": "c83363d2-2316-47f9-eebd-9cca32d302ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jum': 2, 'ump': 5, 'mpy': 3, 'py ': 4, 'y f': 6, ' fo': 0, 'fox': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.get_stop_words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbZsBKZsHDf",
        "outputId": "316cc555-a0a7-473b-e1d8-9686f3e1a294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "x2jimh2bUA_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# # Sample corpus\n",
        "# corpus = [\"hello world\", \"hello\", \"world hello\"]\n",
        "\n",
        "# Step 1: Build the vocabulary\n",
        "# Create a set of unique words\n",
        "vocab = set()\n",
        "for sentence in docs:\n",
        "    vocab.update(sentence.split())\n",
        "\n",
        "# Create a word-to-index dictionary\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "word_to_index"
      ],
      "metadata": {
        "id": "M1jvOiErRFGR",
        "outputId": "b644b6f7-7e1c-4d13-c2bb-0805fdcc3066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'or': 0,\n",
              " 'lattice': 1,\n",
              " 'Building': 2,\n",
              " '81-story': 3,\n",
              " 'second': 4,\n",
              " 'a': 5,\n",
              " 'about': 6,\n",
              " 'first': 7,\n",
              " 'was': 8,\n",
              " 'tall,': 9,\n",
              " 'held': 10,\n",
              " 'Paris,': 11,\n",
              " 'Tower': 12,\n",
              " 'on': 13,\n",
              " 'building.': 14,\n",
              " 'Champ': 15,\n",
              " 'Chrysler': 16,\n",
              " 'for': 17,\n",
              " 'with': 18,\n",
              " 'ascend': 19,\n",
              " 'title': 20,\n",
              " '1930.': 21,\n",
              " 'visitors,': 22,\n",
              " 'three': 23,\n",
              " 'City': 24,\n",
              " 'finished': 25,\n",
              " 'tower': 26,\n",
              " 'this': 27,\n",
              " 'wrought-iron': 28,\n",
              " 'purchased': 29,\n",
              " 'by': 30,\n",
              " 'be': 31,\n",
              " 'stairs': 32,\n",
              " 'It': 33,\n",
              " 'levels.': 34,\n",
              " 'de': 35,\n",
              " 'has': 36,\n",
              " 'the': 37,\n",
              " 'as': 38,\n",
              " 'in': 39,\n",
              " 'New': 40,\n",
              " 'levels': 41,\n",
              " 'height': 42,\n",
              " 'to': 43,\n",
              " 'years': 44,\n",
              " 'until': 45,\n",
              " 'Tickets': 46,\n",
              " '324': 47,\n",
              " 'can': 48,\n",
              " 'is': 49,\n",
              " 'Eiffel': 50,\n",
              " 'lift': 51,\n",
              " 'meters': 52,\n",
              " 'The': 53,\n",
              " 'Mars': 54,\n",
              " 'and': 55,\n",
              " 'York': 56,\n",
              " 'France.': 57,\n",
              " '41': 58,\n",
              " 'restaurants': 59,\n",
              " 'an': 60,\n",
              " 'same': 61}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create one-hot representations\n",
        "def one_hot_encode(word, word_to_index):\n",
        "    \"\"\"\n",
        "    Create a one-hot vector for the given word.\n",
        "    \"\"\"\n",
        "    vector = torch.zeros(len(word_to_index), dtype=torch.float32)\n",
        "    vector[word_to_index[word]] = 1.0\n",
        "    return vector\n",
        "\n",
        "# Encode the entire docs\n",
        "one_hot_encoded_docs = []\n",
        "for sentence in docs:\n",
        "    encoded_sentence = []\n",
        "    for word in sentence.split():\n",
        "        encoded_sentence.append(one_hot_encode(word, word_to_index))\n",
        "    one_hot_encoded_docs.append(encoded_sentence)\n",
        "\n",
        "one_hot_encoded_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNhmwg59Touf",
        "outputId": "6986e346-7d1b-4edd-d5c0-f2f517302853"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          1., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0.])],\n",
              " [tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1., 0.]),\n",
              "  tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.])],\n",
              " [tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.])],\n",
              " [tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.])],\n",
              " [tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.])]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "aSEQn2lKe_Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec (Google) - 2 techniques: Continuous Bag of Words (CBoW) and Skip-Gram;\n",
        "Bow: use context of window size m to predict target. softmax layer and negative log-likelihood given context to train. faster.\n",
        "\n",
        "Skip-gram: use center to predict context in window size m to predict context words. one output layer + softmax predicts (center, context) pair. Avg. neg. log likelihood to train. better for infrequent words.\n",
        "\n",
        "Goal is to learn weights that are the vectors. Both Can use negative sampling to optimize (better for frequent). Hierarchical softmax (better for infrequent words).\n",
        "Linear substructures like vector(man) - vector(woman) + vector(king) = vector(queen). Can average embeddings of multiple words to find closest vectors during inference.\n",
        "\n",
        "\n",
        "Global Vectors or GloVe (Stanford); trained on co-occurence/frequency matrix of word pairs. Can use KNN to get similar words. Linear substructurs: vector difference of man-woman is similar to king-queen. This is encoded as its trained so its dot product equals log of prob ratio. This encodes meaning of the word e.g. ice/steam/gas/water example.\n",
        "\n",
        "fastText (Facebook) —interesting fact: accounts for out of vocabulary words.\n"
      ],
      "metadata": {
        "id": "VMZk8nJVhA7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "PazLVjeTRTEY",
        "outputId": "44062b37-4eb6-490a-e31b-211b8a6c1b1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"I love natural language processing\",\n",
        "    \"word2vec is a cool technique\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec model using CBOW\n",
        "model_cbow = Word2Vec(tokenized_sentences, vector_size=100, window=2, min_count=1, sg=0) # switch skip-gram\n",
        "\n",
        "# Get the word vector for a word\n",
        "vector = model_cbow.wv['fox']\n",
        "print(vector)\n",
        "\n",
        "# Find most similar words\n",
        "similar_words = model_cbow.wv.most_similar('fox')\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJv9GlWJfAwn",
        "outputId": "a94068ee-af5b-402b-f83e-b4451854f89d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n",
            "[('processing', 0.2529142200946808), ('quick', 0.1701662242412567), ('language', 0.15018442273139954), ('jumps', 0.13887980580329895), ('a', 0.10852645337581635), ('over', 0.034764934331178665), ('is', 0.016065234318375587), ('cool', 0.004503022879362106), ('natural', -0.005900727119296789), ('the', -0.027750348672270775)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use pre-trained\n",
        "\n",
        "# import gensim.downloader as api\n",
        "\n",
        "# # Load the pre-trained Word2Vec model (Google's pretrained model)\n",
        "# model = api.load(\"word2vec-google-news-300\")\n",
        "# model.most_similar('fox')"
      ],
      "metadata": {
        "id": "stp69JgJfAuh",
        "outputId": "ead8702d-fb1e-4bf5-d4f0-0c295b11d810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc2Vec"
      ],
      "metadata": {
        "id": "CagFqGHY4E7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- based on word2vec, shallow network. random init doc vvector to predict a sample of words in that document (somewhat similar to skipgram, uses only doc vector. another variant that uses doc and word vectors in context to predict next token similar to cbow). results in static embeddings, treats all context words equally regardless of order/sposition.\n",
        "\n",
        "- BERT is bidirection (processes words right and left), is deep, finetuend on sentence similarity, higher scores in benchmakrs,"
      ],
      "metadata": {
        "id": "lOVOLHMh4uqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"I love machine learning.\",\n",
        "    \"Gensim is a useful library for NLP.\",\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"This is an example document.\"\n",
        "]\n",
        "\n",
        "# Preprocess and tag the documents\n",
        "tagged_documents = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "\n",
        "# Initialize and train the Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, window=2, min_count=1, workers=4, epochs=100)\n",
        "\n",
        "# Build the vocabulary\n",
        "model.build_vocab(tagged_documents)\n",
        "\n",
        "# Train the model\n",
        "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "# Inference: Get the vector for a new document\n",
        "new_doc = \"Machine learning is fascinating.\"\n",
        "new_vec = model.infer_vector(new_doc.split())\n",
        "\n",
        "# Print the vector\n",
        "print(f\"Vector for the new document: {new_vec}\")\n"
      ],
      "metadata": {
        "id": "gYpLIHLsfAqF",
        "outputId": "301e121a-026d-413a-a054-e4c5aac13a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for the new document: [-0.00927261  0.00080162 -0.0076728  -0.00838101 -0.00284593 -0.00364679\n",
            "  0.00345291  0.00047671 -0.00730357  0.00868686 -0.00672406 -0.00843491\n",
            " -0.0081366  -0.00902079 -0.00549584  0.0092644  -0.0101813   0.00171979\n",
            "  0.00329426  0.00550255 -0.00590506 -0.00887692  0.00852981 -0.00430639\n",
            "  0.00767699  0.0081518   0.00753653 -0.00840271  0.00081497 -0.00584543\n",
            "  0.00995204  0.00494215  0.00385145 -0.00645179 -0.00608489  0.00313796\n",
            " -0.00912819 -0.00295534 -0.00113508 -0.00752973 -0.00014922 -0.0002747\n",
            "  0.00958485 -0.00033238 -0.0004992   0.00529813  0.00878078  0.00669311\n",
            " -0.00239134  0.00502931]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "jaP_tMYU-gE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DSqtPdQ4-6Xs",
        "outputId": "2e972723-3c57-4d9f-9bd4-c7b50a2e44d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# brief chatgpt example:\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the SpaCy English model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Example set of documents\n",
        "documents = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\",\n",
        "    \"This is not a document.\",\n",
        "    \"We have more documents to explore.\"\n",
        "]\n",
        "\n",
        "# Function to convert documents to vectors\n",
        "def document_vectors(documents):\n",
        "    doc_vectors = []\n",
        "    for doc in documents:\n",
        "        doc_vector = nlp(doc).vector\n",
        "        doc_vectors.append(doc_vector)\n",
        "    return np.array(doc_vectors)\n",
        "\n",
        "# Convert documents to vectors\n",
        "doc_vectors = document_vectors(documents)\n",
        "\n",
        "# Test document\n",
        "test_doc = \"More documents should be explored.\"\n",
        "\n",
        "# Convert test document to vector\n",
        "test_doc_vector = nlp(test_doc).vector\n",
        "\n",
        "# Calculate cosine similarity between test document and each document in the set\n",
        "similarities = cosine_similarity([test_doc_vector], doc_vectors)[0]\n",
        "\n",
        "# Retrieve indices of most similar documents\n",
        "most_similar_indices = similarities.argsort()[:-4:-1]\n",
        "\n",
        "# Print most similar documents\n",
        "print(\"Most similar documents to the test document:\")\n",
        "for idx in most_similar_indices:\n",
        "    print(f\"Document {idx}: {documents[idx]}\")\n"
      ],
      "metadata": {
        "id": "EBaOuy9v-hui",
        "outputId": "f2a7e15e-5b3e-4879-a498-5c72a523c292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar documents to the test document:\n",
            "Document 5: We have more documents to explore.\n",
            "Document 1: This document is the second document.\n",
            "Document 0: This is the first document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.tag_, token.has_vector, token.vector_norm)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "sWiq7Fdu-hsv",
        "outputId": "da8f40bd-8fc0-485e-f073-b392b6f52a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN nsubj NNP True 49.544395\n",
            "is be AUX aux VBZ True 110.41255\n",
            "looking look VERB ROOT VBG True 48.28714\n",
            "at at ADP prep IN True 118.82375\n",
            "buying buy VERB pcomp VBG True 45.90773\n",
            "U.K. U.K. PROPN compound NNP True 34.055897\n",
            "startup startup NOUN dobj NN True 39.72299\n",
            "for for ADP prep IN True 69.12914\n",
            "$ $ SYM quantmod $ True 190.25487\n",
            "1 1 NUM compound CD True 118.7086\n",
            "billion billion NUM pobj CD True 67.87469\n",
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))\n"
      ],
      "metadata": {
        "id": "P-5oXL2u-hqo",
        "outputId": "e707d1b1-9be0-414c-fb9c-b07d09d33273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
            "salty fries <-> hamburgers 0.6938489675521851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "64Rgzdm2eTrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
        "    return similarity\n",
        "\n",
        "# Example vectors\n",
        "vec1 = np.array([1, 2, 3])\n",
        "vec2 = np.array([4, 5, 6])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity(vec1, vec2)\n",
        "print(f\"Cosine Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "id": "ycey4uqU0tUD",
        "outputId": "566f0808-3a95-436c-b7b6-33470c235a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.9746318461970762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter('A quick brown fox jumps')\n",
        "\n",
        "Counter(['Abc', 'def'])"
      ],
      "metadata": {
        "id": "YMnKymUmeHZA",
        "outputId": "0a241fc0-ec31-43e5-cc57-094c81258126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'A': 1,\n",
              "         ' ': 4,\n",
              "         'q': 1,\n",
              "         'u': 2,\n",
              "         'i': 1,\n",
              "         'c': 1,\n",
              "         'k': 1,\n",
              "         'b': 1,\n",
              "         'r': 1,\n",
              "         'o': 2,\n",
              "         'w': 1,\n",
              "         'n': 1,\n",
              "         'f': 1,\n",
              "         'x': 1,\n",
              "         'j': 1,\n",
              "         'm': 1,\n",
              "         'p': 1,\n",
              "         's': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Abc': 1, 'def': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK Stuff"
      ],
      "metadata": {
        "id": "eWiz7u1_3Y2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "puncs = set(string.punctuation)\n",
        "print(puncs)"
      ],
      "metadata": {
        "id": "Mi1rmXY64U20",
        "outputId": "5aafd24e-8422-4670-cf81-67bbc0d1ced0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_', '-', ',', ']', '`', '(', '.', '!', '*', '+', '~', '?', '#', '@', '\"', '$', ')', '<', '\\\\', ';', '&', '%', '|', '>', '}', ':', '{', '/', '[', \"'\", '^', '='}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "0Nmk7ETcrFAG",
        "outputId": "f424164e-079b-4fc5-9dcc-22721cf1ffc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) # can also just specify in sklearn\n",
        "len(stop_words)"
      ],
      "metadata": {
        "id": "jp7vWTKl5un_",
        "outputId": "61ba2096-aef4-4c69-c99e-2da4a8dcc5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "8lZl8Vvf3a_-",
        "outputId": "50d64807-ee37-4ee9-b7b7-6c7c7cd4bded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "  tokens = [lemmatizer.lemmatize(word.lower()) for word in doc.split(' ') if word not in stop_words and word not in puncs]\n",
        "  return tokens\n",
        "\n",
        "tokenized_docs = [preprocess(doc) for doc in docs]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "id": "XVabJuxw3a94",
        "outputId": "82b08ffa-dfc9-4e89-f0da-fc1921152e31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'eiffel', 'tower', 'wrought-iron', 'lattice', 'tower', 'champ', 'de', 'mar', 'paris,', 'france.'], ['the', 'tower', '324', 'meter', 'tall,', 'height', '81-story', 'building.'], ['it', 'held', 'title', '41', 'year', 'chrysler', 'building', 'new', 'york', 'city', 'finished', '1930.'], ['the', 'tower', 'three', 'level', 'visitors,', 'restaurant', 'first', 'second', 'levels.'], ['ticket', 'purchased', 'ascend', 'stair', 'lift', 'first', 'second', 'levels.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since already tokenized, if wanna create BoW, can use:\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, smooth_idf=True, stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(tokenized_docs)\n",
        "\n",
        "tfidf_matrix.toarray().shape\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "id": "grNrPvfJ3a72",
        "outputId": "afa38511-7295-484c-e455-84bdf4da1617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.33721386 0.         0.         0.33721386 0.\n",
            "  0.33721386 0.         0.         0.33721386 0.         0.\n",
            "  0.         0.33721386 0.         0.         0.33721386 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.4516721  0.         0.33721386 0.         0.        ]\n",
            " [0.         0.39379499 0.         0.39379499 0.         0.\n",
            "  0.39379499 0.         0.         0.         0.         0.\n",
            "  0.         0.39379499 0.         0.         0.         0.\n",
            "  0.         0.         0.39379499 0.         0.         0.\n",
            "  0.         0.         0.         0.39379499 0.         0.\n",
            "  0.26372909 0.         0.         0.         0.        ]\n",
            " [0.30151134 0.         0.30151134 0.         0.         0.30151134\n",
            "  0.         0.         0.30151134 0.30151134 0.         0.30151134\n",
            "  0.         0.         0.30151134 0.         0.         0.\n",
            "  0.         0.         0.         0.30151134 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.30151134\n",
            "  0.         0.         0.         0.30151134 0.30151134]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.45881476 0.37016886\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.45881476 0.37016886 0.         0.         0.         0.\n",
            "  0.30727359 0.45881476 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.39835162 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.32138758\n",
            "  0.39835162 0.         0.         0.         0.         0.39835162\n",
            "  0.         0.32138758 0.39835162 0.         0.39835162 0.\n",
            "  0.         0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "# for better handling of ambiguous situations like U.S.A.\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "text = \"Natural language processing is an exciting area. Huge budget have been allocated for this.\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "id": "WkSQfyIV69Md",
        "outputId": "57d2dc4a-627e-4711-e821-adc14983d6b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing is an exciting area.', 'Huge budget have been allocated for this.']\n",
            "['Natural', 'language', 'processing', 'is', 'an', 'exciting', 'area', '.', 'Huge', 'budget', 'have', 'been', 'allocated', 'for', 'this', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos tagging\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "\n",
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(text))\n",
        "tagged"
      ],
      "metadata": {
        "id": "CNS3KQ8HNivU",
        "outputId": "a599ed7f-2f92-405b-dfa7-cc29e324c4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('processing', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('exciting', 'JJ'),\n",
              " ('area', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Huge', 'NNP'),\n",
              " ('budget', 'NN'),\n",
              " ('have', 'VBP'),\n",
              " ('been', 'VBN'),\n",
              " ('allocated', 'VBN'),\n",
              " ('for', 'IN'),\n",
              " ('this', 'DT'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Trees"
      ],
      "metadata": {
        "id": "WZQ8uNptcaKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty grammar example\n",
        "\n",
        "# Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {} # To extract Noun Phrases\n",
        "                    P: {}    # To extract Prepositions\n",
        "                    V: {}    # To extract Verbs\n",
        "                    PP: {}   # To extract Prepositional Phrases\n",
        "                    VP: {}   # To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)\n",
        "\n",
        "# another set of grammar rules:\n",
        "\n",
        "#Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "                    P: {<IN>}            #To extract Prepositions\n",
        "                    V: {<V.*>}           #To extract Verbs\n",
        "                    PP: {<p> <NP>}       #To extract Prepositional Phrases\n",
        "                    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)"
      ],
      "metadata": {
        "id": "ihFxRklMNXmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# CFGs can not be used with english as its not as expressive.\n",
        "\n",
        "# Define a context-free grammar\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N | 'I'\n",
        "    VP -> V NP | V\n",
        "    Det -> 'the' | 'a'\n",
        "    N -> 'dog' | 'cat'\n",
        "    V -> 'chased' | 'ate'\n",
        "\"\"\")\n",
        "\n",
        "# Create a recursive descent parser\n",
        "parser = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "# Define a sentence to parse\n",
        "sentence = \"I chased the cat\"\n",
        "\n",
        "# Parse the sentence and print the parse trees\n",
        "for tree in parser.parse(sentence.split()):\n",
        "    print(tree)\n",
        "    display(tree)\n"
      ],
      "metadata": {
        "id": "buLE6Z7ZMxXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_syntactic_analysis.htm\n",
        "2. https://www.analyticsvidhya.com/blog/2022/03/syntactical-parsing-in-nlp/\n",
        "3. https://intellipaat.com/blog/what-is-parsing-in-nlp/"
      ],
      "metadata": {
        "id": "ExlT62TJcSeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "eM2KJwbrdAoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [5, 2, 5]])\n",
        "t"
      ],
      "metadata": {
        "id": "ouPBT0I8XP0U",
        "outputId": "195807b3-e7d2-40a6-d4de-2f46d25f225c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.t()"
      ],
      "metadata": {
        "id": "I_TqwXs4XPxc",
        "outputId": "a0a748ef-99ba-4e08-bf6a-a5f61ca7cc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 5],\n",
              "        [2, 2],\n",
              "        [3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape\n",
        "\n",
        "un_t = torch.unsqueeze(t, dim=0) # equivalent of np.expand(x, axis=0)\n",
        "un_t"
      ],
      "metadata": {
        "id": "YBHdVErTD3Eg",
        "outputId": "402d8839-33e4-41ff-a771-74e9a92ba273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [5, 2, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.squeeze()"
      ],
      "metadata": {
        "id": "ZqTRarNhD3Bp",
        "outputId": "97cbac31-c942-4bf6-9b69-ac9dcc48c54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(un_t).item()"
      ],
      "metadata": {
        "id": "anUwsI4cD2_S",
        "outputId": "a57f31a1-69f3-476f-eacd-a22001e86aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.view(-1, 1, 1) # only one dimension can be inferred"
      ],
      "metadata": {
        "id": "qhb5t_GVEK-_",
        "outputId": "3d0e897a-8e70-447e-e8b9-0fa51fc74dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[3]],\n",
              "\n",
              "        [[5]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 3, 5)"
      ],
      "metadata": {
        "id": "o35wGkAPEK7d",
        "outputId": "75934357-be00-464c-f63c-4577bbea32bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(t) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(t, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "ZiFToM1xNysP",
        "outputId": "15279304-a561-4aba-f062-9e83aa23dcd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1, 1],\n",
            "        [1, 1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7808, 0.9895, 0.2857],\n",
            "        [0.7399, 0.2903, 0.7733]]) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # not conformal\n",
        "# t @ t\n",
        "\n",
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = t @ t.T\n",
        "y2 = t.matmul(t.T)\n",
        "y1\n",
        "y2\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = t * t\n",
        "z2 = t.mul(t)\n",
        "z1\n",
        "z2"
      ],
      "metadata": {
        "id": "zN7GHbOPOKi5",
        "outputId": "e8b56cac-06a8-4bd1-ddfb-ac43031d098c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 24],\n",
              "        [24, 54]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 24],\n",
              "        [24, 54]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  4,  9],\n",
              "        [25,  4, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  4,  9],\n",
              "        [25,  4, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(1,-1)\n",
        "\n",
        "t.view(1,-1).squeeze()\n",
        "\n",
        "n = t.view(1,-1).squeeze().numpy()\n",
        "np.dot(n, n)"
      ],
      "metadata": {
        "id": "8z0AXWvsOKgt",
        "outputId": "97c3bfbc-48ed-408e-88c0-bb30692f816f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 5, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((t, t), dim=1)"
      ],
      "metadata": {
        "id": "YTj6M4PEHe6B",
        "outputId": "9d96b2a7-deff-47d5-bf5f-e7d96e657062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 1, 2, 3],\n",
              "        [5, 2, 5, 5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "id": "L8Vjt-nEH-yp",
        "outputId": "c9e49c51-bc12-428f-8934-e475173e4d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[-1, 0:2]"
      ],
      "metadata": {
        "id": "yMBpdFt8He3Z",
        "outputId": "60641020-16fd-4427-8329-3cb585e3aadc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.tensor([[1, 2, 0, -1]]) == 1) # masking"
      ],
      "metadata": {
        "id": "tdjIAB-ofPj6",
        "outputId": "4c05980a-a5f3-4759-aee6-cc99908dd96c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sz = 2\n",
        "mask = (torch.triu(torch.ones((sz, sz))) == 1)\n",
        "\n",
        "mask\n",
        "mask.transpose(0, 1)\n"
      ],
      "metadata": {
        "id": "NkfIpAONfAuS",
        "outputId": "ddf35078-a505-4723-93e2-729ccb940e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True],\n",
              "        [False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False],\n",
              "        [ True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.float()\n",
        "\n",
        "mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "metadata": {
        "id": "03yrPTOGfAsW",
        "outputId": "0462ad0a-42d2-4d80-a368-8672a9175266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [-inf, 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(torch.tensor(5))"
      ],
      "metadata": {
        "id": "uITKOw5AHe03",
        "outputId": "6c817766-700c-45bd-99d1-a7ac298dd0d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9933)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.X returns a callable\n",
        "\n",
        "probs = torch.nn.Softmax(dim=0)(torch.tensor([9, 10, 1], dtype=float))\n",
        "probs\n",
        "\n",
        "probs.argmax(0)"
      ],
      "metadata": {
        "id": "3Y6R13IQJnCw",
        "outputId": "fc87f371-772a-4309-f697-5ec915ce66ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.6892e-01, 7.3099e-01, 9.0212e-05], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.ReLU()(torch.tensor(-4))"
      ],
      "metadata": {
        "id": "roKqlUQ0JnAa",
        "outputId": "8d4e921c-a87c-43cc-ded0-cad7d74626f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t\n",
        "\n",
        "# can't flatten like this (flatten is a layer)\n",
        "torch.nn.Flatten()(t)"
      ],
      "metadata": {
        "id": "Uk0RMTjbUAQR",
        "outputId": "f9965a8b-5af5-490b-f965-697933029f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an ordered container\n",
        "seq_modules = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(784, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "yiPbaCPsLB4A",
        "outputId": "5c9a7ce5-4f50-4e13-d27a-376f57dbeda1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.to('cpu')\n",
        "\n",
        "t.to('cuda')"
      ],
      "metadata": {
        "id": "r5l0EiPcU1JO",
        "outputId": "23707afb-492b-4bb7-c069-80a92cc5bf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-1f5961e5ca30>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gives error\n",
        "t.to('gpu')"
      ],
      "metadata": {
        "id": "wNesJLZIVZsP",
        "outputId": "fb4939b2-ff84-4857-95fc-bd3ce191f0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-61d72b461b62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can use within collate_fn in dataloader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Example list of sequences with varying lengths\n",
        "sequences = [torch.tensor([1, 2, 3], dtype=torch.float),\n",
        "             torch.tensor([4, 5], dtype=torch.float),\n",
        "             torch.tensor([6], dtype=torch.float)]\n",
        "\n",
        "# Pad the sequences\n",
        "padded_sequence = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
        "padded_sequence"
      ],
      "metadata": {
        "id": "1X4qRbMiXaOx",
        "outputId": "3b0140b1-3ff5-4e49-a0b2-0f523c583c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 0.],\n",
              "        [6., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serves different purpose.\n",
        "# ignores pad values and leads to better memory utilization\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "lengths = torch.tensor([len(t) for t in padded_sequence])\n",
        "packed_sequence = pack_padded_sequence(padded_sequence, lengths, batch_first=True, enforce_sorted=False)\n",
        "packed_sequence"
      ],
      "metadata": {
        "id": "C31KE7KNXPvH",
        "outputId": "3dc102dd-5a3b-427a-f165-22a5fecc9956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([1., 4., 6., 2., 5., 0., 3., 0., 0.]), batch_sizes=tensor([3, 3, 3]), sorted_indices=tensor([0, 1, 2]), unsorted_indices=tensor([0, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "# can't use tensordataset directly for variable input lengths\n",
        "# need to implement class\n",
        "\n",
        "# can't init tensor on array. otherwise, just init as tensor and use tensordataset\n",
        "X = [[1, 2, 3], [5, 7], [5]]\n",
        "\n",
        "# needed\n",
        "X = list(map(torch.tensor, X))\n",
        "\n",
        "y = torch.tensor([0, 1, 1])\n",
        "\n",
        "# can't use for array\n",
        "#dataset = TensorDataset(X, y)\n",
        "\n",
        "class SequenceDataset(Dataset): # just a protocol class so doesn't inherit anythinmg no super()\n",
        "  def __init__(self, sequences, labels):\n",
        "    self.sequences = sequences\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sequences)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.sequences[idx], self.labels[idx]\n",
        "\n",
        "dataset = SequenceDataset(X, y)"
      ],
      "metadata": {
        "id": "zBg1bgVGftR5",
        "outputId": "7160841a-9176-45dc-8bf0-1fafe95ca337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t\n",
        "\n",
        "for x in zip(t):\n",
        "  print(x)\n",
        "\n",
        "for x in zip(*t):\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "pScGfCDoWw6D",
        "outputId": "0122fb8b-9e27-41c1-ad52-d7fb836e9ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([1, 2, 3]),)\n",
            "(tensor([5, 2, 5]),)\n",
            "(tensor(1), tensor(5))\n",
            "(tensor(2), tensor(2))\n",
            "(tensor(3), tensor(5))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_fn(batch):\n",
        "  sequences, labels = zip(*batch)\n",
        "  lengths = [len(seq) for seq in sequences]\n",
        "  padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "  return padded, lengths, labels\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through DataLoader\n",
        "for batch in dataloader:\n",
        "    padded_sequences, lengths, labels = batch\n",
        "    print(\"Padded Sequences:\\n\", padded_sequences)\n",
        "    print(\"Lengths:\\n\", lengths)\n",
        "    print(\"Labels:\\n\", labels)"
      ],
      "metadata": {
        "id": "_JqCGnZ1Wslo",
        "outputId": "fe8ef430-b8ad-4081-a627-29f7e820eee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences:\n",
            " tensor([[1, 2, 3],\n",
            "        [5, 7, 0]])\n",
            "Lengths:\n",
            " [3, 2]\n",
            "Labels:\n",
            " (tensor(0), tensor(1))\n",
            "Padded Sequences:\n",
            " tensor([[5]])\n",
            "Lengths:\n",
            " [1]\n",
            "Labels:\n",
            " (tensor(1),)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Streaming Data\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Create an HDF5 file\n",
        "with h5py.File('example3.h5', 'w') as f:\n",
        "    f.create_dataset('data', data=np.arange(100), compression=\"gzip\")\n",
        "    f.create_dataset('labels', data=np.random.randint(0, 3, size=(100,)), compression=\"gzip\")\n",
        "\n",
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, h5_file, transform=None):\n",
        "        self.file = h5_file\n",
        "        self.dataset = h5py.File(h5_file, 'r')\n",
        "        self.data = self.dataset['data']\n",
        "        self.labels = self.dataset['labels']\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# Usage example\n",
        "h5_file = 'example3.h5'\n",
        "dataset = HDF5Dataset(h5_file)"
      ],
      "metadata": {
        "id": "5SuvxbxOfAcZ",
        "outputId": "222a13ed-bbbd-4908-e10b-8396c3377907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<HDF5 dataset \"data\": shape (100,), type \"<i8\">"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<HDF5 dataset \"labels\": shape (100,), type \"<i8\">"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Iterate over DataLoader in training loop\n",
        "for inputs, labels in data_loader:\n",
        "    # Perform training step\n",
        "    print(inputs)\n",
        "    print('===========')"
      ],
      "metadata": {
        "id": "jeNRRLuBfAaR",
        "outputId": "365100c3-e24c-4e3a-bd15-181d54672e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([55.,  1., 58., 90., 80., 44., 85., 22., 50., 61., 88., 72., 42., 16.,\n",
            "        73., 18., 49.,  0., 79., 20.,  5., 89., 74., 34.,  4., 51., 75., 47.,\n",
            "        77., 81., 95., 65.])\n",
            "===========\n",
            "tensor([93., 91., 68., 35., 87., 96., 10.,  2., 67., 27., 52., 17., 32., 59.,\n",
            "        38., 19., 46., 83., 84., 15., 54., 39.,  7., 57., 33., 29., 70., 37.,\n",
            "        76., 97., 71., 12.])\n",
            "===========\n",
            "tensor([99., 28., 86., 63., 48., 62., 82.,  3., 43., 94., 41., 24., 78.,  9.,\n",
            "        98., 13., 25., 45., 66., 36., 30., 21., 14., 92.,  8., 69., 40.,  6.,\n",
            "        26., 23., 11., 56.])\n",
            "===========\n",
            "tensor([31., 60., 53., 64.])\n",
            "===========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "Zs37MjfFKfSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# IMDb reviews data as a dictionary\n",
        "imdb_reviews = {\n",
        "    \"review\": [\n",
        "        \"The Shawshank Redemption is an incredible movie. The acting is superb and the storyline is captivating.\",\n",
        "        \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n",
        "        \"Great movie! The special effects were amazing and the characters were well-developed.\",\n",
        "        \"The dialogue felt forced and unrealistic. I couldn't connect with any of the characters.\",\n",
        "        \"The Godfather is a masterpiece. The performances are outstanding and the direction is flawless.\",\n",
        "        \"The pacing of the film was too slow, and I found myself losing interest halfway through.\",\n",
        "        \"Titanic is a classic love story that will tug at your heartstrings. I highly recommend it.\",\n",
        "        \"The acting was wooden and the plot was predictable. I was not impressed.\",\n",
        "        \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n",
        "        \"I felt the movie lacked depth and the characters were one-dimensional. Overall, it was underwhelming.\"\n",
        "    ],\n",
        "    \"sentiment\": [\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(imdb_reviews)\n",
        "df = pd.concat([df, df]).reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "eXpQALyWdB6_",
        "outputId": "cb781a31-a216-4b2a-efca-2173868e4005"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review sentiment\n",
              "0   The Shawshank Redemption is an incredible movi...  positive\n",
              "1   I found the plot to be confusing and the actin...  negative\n",
              "2   Great movie! The special effects were amazing ...  positive\n",
              "3   The dialogue felt forced and unrealistic. I co...  negative\n",
              "4   The Godfather is a masterpiece. The performanc...  positive\n",
              "5   The pacing of the film was too slow, and I fou...  negative\n",
              "6   Titanic is a classic love story that will tug ...  positive\n",
              "7   The acting was wooden and the plot was predict...  negative\n",
              "8   Jurassic Park is a thrilling adventure that ke...  positive\n",
              "9   I felt the movie lacked depth and the characte...  negative\n",
              "10  The Shawshank Redemption is an incredible movi...  positive\n",
              "11  I found the plot to be confusing and the actin...  negative\n",
              "12  Great movie! The special effects were amazing ...  positive\n",
              "13  The dialogue felt forced and unrealistic. I co...  negative\n",
              "14  The Godfather is a masterpiece. The performanc...  positive\n",
              "15  The pacing of the film was too slow, and I fou...  negative\n",
              "16  Titanic is a classic love story that will tug ...  positive\n",
              "17  The acting was wooden and the plot was predict...  negative\n",
              "18  Jurassic Park is a thrilling adventure that ke...  positive\n",
              "19  I felt the movie lacked depth and the characte...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95325af8-0c89-4693-b599-a999977cff45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95325af8-0c89-4693-b599-a999977cff45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95325af8-0c89-4693-b599-a999977cff45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95325af8-0c89-4693-b599-a999977cff45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ce3c304-61bc-4ee0-8289-139d0069e1bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ce3c304-61bc-4ee0-8289-139d0069e1bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ce3c304-61bc-4ee0-8289-139d0069e1bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_36a11b1b-09d2-4354-a91d-a8cfaddbe6ff\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_36a11b1b-09d2-4354-a91d-a8cfaddbe6ff button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n          \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n          \"The pacing of the film was too slow, and I found myself losing interest halfway through.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['review'].values, df['sentiment'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# can also use random_split() by torch on top of pytorch's dataset\n",
        "# like: train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A7tNkD7dB4o",
        "outputId": "5ff4baa0-c74b-48c4-dac9-27fb04985103"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "counts = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=['positive', 'negative'], y=counts.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "WP8H2ZL5dB2m",
        "outputId": "a170047e-cb56-47f7-e0fe-de0860990de2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import string\n",
        "\n",
        "def preprocess_word(w):\n",
        "    return w.lower()\n",
        "\n",
        "def build_vocab(X_train):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_list = set()\n",
        "\n",
        "    # Building the vocabulary\n",
        "    for sent in X_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_word(word)\n",
        "            if word not in stop_words and word != '' and word not in string.punctuation:\n",
        "                word_list.add(word)\n",
        "\n",
        "    # could've done a single pass actually\n",
        "    vocab = {w: i for i, w in enumerate(word_list)}\n",
        "    return vocab\n",
        "\n",
        "def tokenize(sentences):\n",
        "    tokenized_list = []\n",
        "    for sent in sentences:\n",
        "        tokenized_words = [vocab[preprocess_word(w)] for w in sent.lower().split() if preprocess_word(w) in vocab]\n",
        "        if len(tokenized_words) == 0:\n",
        "          print(sent)\n",
        "          continue\n",
        "        tokenized_list.append(torch.tensor(tokenized_words))\n",
        "    return tokenized_list\n",
        "\n",
        "def encode_labels(labels):\n",
        "  return torch.tensor([1 if label == 'positive' else 0 for label in labels])\n",
        "\n",
        "\n",
        "def preprocess(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    # Tokenize the sentences\n",
        "    tokenized_train = tokenize(X_train)\n",
        "    tokenized_test = tokenize(X_test)\n",
        "\n",
        "    # Encode labels\n",
        "    encoded_train = encode_labels(y_train)\n",
        "    encoded_test = encode_labels(y_test)\n",
        "\n",
        "    return tokenized_train, encoded_train, tokenized_test, encoded_test\n",
        "\n",
        "vocab = build_vocab(X_train)\n",
        "\n",
        "# Tokenize and pad the sequences\n",
        "X_train_tokenized, y_train_tokenized, X_test_tokenized, y_test_tokenized = preprocess(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(X_train_tokenized)\n",
        "print(y_train_tokenized)\n",
        "print(X_test_tokenized)\n",
        "print(y_test_tokenized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G1H_gL2tL7A",
        "outputId": "b88adc9f-fc61-41ec-c30d-2e5e7806ccee"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([53, 17, 31,  0,  4, 50, 26]), tensor([38, 23, 43, 21, 11, 18]), tensor([49, 55, 51, 41, 42, 35, 45,  5, 14]), tensor([38, 23, 43, 21, 11, 18]), tensor([23, 15, 46, 36, 50, 33,  8, 27]), tensor([ 7, 56, 10, 39, 57]), tensor([ 7, 56, 10, 39, 57]), tensor([12, 32,  2,  9, 24, 25, 19,  3, 52]), tensor([23, 15, 46, 36, 50, 33,  8, 27]), tensor([34, 37,  1,  6, 58, 20]), tensor([53, 17, 31,  0,  4, 50, 26]), tensor([49, 55, 51, 41, 42, 35, 45,  5, 14]), tensor([22, 28, 54, 13,  7, 16, 48, 59]), tensor([22, 28, 54, 13,  7, 16, 48, 59]), tensor([47, 10, 40,  7, 29,  8, 44, 30]), tensor([47, 10, 40,  7, 29,  8, 44, 30])]\n",
            "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0])\n",
            "[tensor([47]), tensor([34, 37,  1,  6, 58, 20]), tensor([47]), tensor([12, 32,  2,  9, 24, 25, 19,  3, 52])]\n",
            "tensor([0, 1, 0, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "# create Tensor datasets\n",
        "\n",
        "# using custom class for variable input\n",
        "train_data = SequenceDataset(X_train_tokenized, y_train_tokenized)\n",
        "valid_data = SequenceDataset(X_test_tokenized, y_test_tokenized)\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 2\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences, labels = zip(*batch)\n",
        "    lengths = torch.tensor([len(sent) for sent in sentences])\n",
        "    padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    return padded, lengths, torch.tensor(labels)\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_lengths, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample output: \\n', sample_y)\n",
        "print('Sample sample_lengths: \\n', sample_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBPixNFHdBvg",
        "outputId": "3c0b77f1-ab9c-4502-b7b0-ec09a5fcad46"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([2, 9])\n",
            "Sample input: \n",
            " tensor([[49, 55, 51, 41, 42, 35, 45,  5, 14],\n",
            "        [ 7, 56, 10, 39, 57,  0,  0,  0,  0]])\n",
            "Sample output: \n",
            " tensor([1, 0])\n",
            "Sample sample_lengths: \n",
            " tensor([9, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwlossk_-Te",
        "outputId": "445d3bc4-702d-4233-ab6f-5a2f6ec90cc2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, CPU used\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(torch.nn.Module):\n",
        "    def __init__(self, no_layers, vocab_size,hidden_dim,embedding_dim,output_dim,drop_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #lstm: DOES NOT DEPEND ON SEQUENCE LENGTH. SHARED WEIGHTS.\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=no_layers,\n",
        "            batch_first=True #bidirectional=True\n",
        "        )\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layer\n",
        "        self.fc = torch.nn.Linear(self.hidden_dim, output_dim) # *2 because of bidirectional\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, lengths, hidden):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "\n",
        "        # using packed sequences\n",
        "        packed_embed = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # handles feedback loop and processes all the tokens in a sequence\n",
        "        lstm_out, hidden = self.lstm(packed_embed, hidden)\n",
        "\n",
        "        # for BILSTM: concatenate the final forward and backward hidden states\n",
        "        # forward even indices, backward odd\n",
        "        # hidden_concat = torch.cat((hidden[0][-2, :, :], hidden[0][-1, :, :]), dim=1)\n",
        "\n",
        "        # Unpack the PackedSequence\n",
        "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        \"\"\"\n",
        "        Reshapes the lstm_out tensor to have shape (batch_size * sequence_length, hidden_dim).\n",
        "        The -1 is a placeholder that infers the appropriate size automatically based on the\n",
        "        other dimension (hidden_dim). This essentially flattens the tensor so that each time step\n",
        "        for each batch item is treated as an independent sample.\n",
        "        \"\"\"\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "\n",
        "        # Not sure if it is correct to sigmoid all the logits at once.\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels (i beleive this is last token of each batch)\n",
        "\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "\n",
        "        # twice layers for BILSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden\n",
        "\n",
        "    # optionally:\n",
        "    # def init_weights(self):\n",
        "    #     for param in self.parameters():\n",
        "    #         nn.init.kaiming_uniform_(param, a=math.sqrt(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5G35IyndBtb",
        "outputId": "37dca119-7ad5-4486-d2fb-2874a6c9d42d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 # extra 1 for padding????\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 12\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,output_dim,drop_prob=0.5)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vOR2JzBBr5",
        "outputId": "615b281b-cd0e-4e4b-8e58-57a7b380b330"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()}\\n\")\n",
        "\n",
        "\n",
        "sum(p.numel() for p in model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeS8f0YaLiGg",
        "outputId": "d0ccc467-ca1c-428b-9c50-f39f68975351"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: embedding.weight | Size: torch.Size([61, 64])\n",
            "\n",
            "Layer: lstm.weight_ih_l0 | Size: torch.Size([48, 64])\n",
            "\n",
            "Layer: lstm.weight_hh_l0 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.weight_ih_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.weight_hh_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: fc.weight | Size: torch.Size([1, 12])\n",
            "\n",
            "Layer: fc.bias | Size: torch.Size([1])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8909"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# function to calculate accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item() # returns standard python number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWwZs9nzBBpZ",
        "outputId": "ecc7d369-0931-4589-ae4a-32b81187ebbe"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5 # gradient clipping for exploding gradients\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "\n",
        "    # layers like dropout are enabled. gradients ar eclcualed. batch normalziation uses batch statistics.\n",
        "    model.train()\n",
        "\n",
        "    # initialize hidden states and cell states of LSTM\n",
        "    h = model.init_hidden(batch_size)\n",
        "\n",
        "    for inputs, lengths, labels in train_loader:\n",
        "        # move to GPU\n",
        "        inputs, lengths, labels = inputs.to(device), lengths.to(device), labels.to(device)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise we'd backprop through the entire training history\n",
        "        # don't recall what this meant but copying data so can't initialize here\n",
        "        # maybe this just breaks loop so backprogation only done using this batch\n",
        "        # previous's batches hidden states used as a starting point\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # clear grad to prevent gradient accumulation across batches.\n",
        "        model.zero_grad()\n",
        "\n",
        "        # forward() pass. maintain operations gradient functions in DAG .grad_fn\n",
        "        output, _ = model(inputs, lengths, h)  # h not used outside\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels.float())\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # calculate gradients through backpropagation into .grad, applies chain rule\n",
        "        loss.backward()\n",
        "\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculating accuracy (correct labels)\n",
        "        accuracy = acc(output, labels)\n",
        "        train_acc += accuracy # actually correct predictions\n",
        "\n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, lengths, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "        output, val_h = model(inputs, lengths, val_h)\n",
        "        val_loss = criterion(output, labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "        accuracy = acc(output,labels)\n",
        "        val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8370CoXE9tq",
        "outputId": "48650191-1683-4655-ee5a-d879861644ff"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5613)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6677)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5108)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4582)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6750)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4657)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5985)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5982)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.6962824985384941 val_loss : 0.7056528627872467\n",
            "train_accuracy : 50.0 val_accuracy : 50.0\n",
            "Validation loss decreased (inf --> 0.705653).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5439)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6650)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1441)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4696)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2009)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1759)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5807)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2204)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "train_loss : 0.6880582794547081 val_loss : 0.7052414417266846\n",
            "train_accuracy : 50.0 val_accuracy : 50.0\n",
            "Validation loss decreased (0.705653 --> 0.705241).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1943)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5449)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2091)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5825)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2039)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2076)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1185)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1841)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "train_loss : 0.6914873197674751 val_loss : 0.7022280097007751\n",
            "train_accuracy : 50.0 val_accuracy : 50.0\n",
            "Validation loss decreased (0.705241 --> 0.702228).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1991)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1915)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2172)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2100)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1523)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1848)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1864)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1933)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "train_loss : 0.6943126618862152 val_loss : 0.696195662021637\n",
            "train_accuracy : 50.0 val_accuracy : 50.0\n",
            "Validation loss decreased (0.702228 --> 0.696196).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4795)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5868)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6452)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2096)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1922)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2723)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2226)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4822)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(61, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5\n",
            "train_loss : 0.6758159622550011 val_loss : 0.6915813684463501\n",
            "train_accuracy : 50.0 val_accuracy : 50.0\n",
            "Validation loss decreased (0.696196 --> 0.691581).  Saving model ...\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "  model.eval()\n",
        "\n",
        "  word_seq = np.array([vocab[preprocess_word(word)] for word in text.split() if preprocess_word(word) in vocab])\n",
        "  length = torch.tensor([len(word_seq)])\n",
        "  word_seq = np.expand_dims(word_seq, axis=0) # skipped padding. does it matter?\n",
        "  inputs = torch.from_numpy(word_seq).to(device)\n",
        "  batch_size = 1\n",
        "  h = model.init_hidden(batch_size)\n",
        "  # h = tuple([each.data for each in h]) # maybe unnecessary\n",
        "  with torch.no_grad():\n",
        "    output, h = model(inputs, length, h)\n",
        "  probability = output.item()\n",
        "  return probability\n",
        "\n",
        "index = 0\n",
        "predict_text('this movie sucks.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnFpZq2xE9qu",
        "outputId": "4a17c78a-dd4d-4e78-e37f-45b61e5807bc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5574951767921448"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "id": "xnbpvCZ6f9Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline / Sklearn"
      ],
      "metadata": {
        "id": "TbynZe0D8Ydm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X = pd.DataFrame(\n",
        "    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n",
        "     'state' : ['NY', 'NJ', 'ON', 'QB'],\n",
        "     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n",
        "               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n",
        "     'expert_rating': [5, 3, 4, 5],\n",
        "     'user_rating': [4, 5, 4, 3]})\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "RYB5Axo269HR",
        "outputId": "40c707e6-bff2-4f66-f72f-b2bf1be32e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       city state                         title  expert_rating  user_rating\n",
              "0    London    NY                  His Last Bow              5            4\n",
              "1    London    NJ  How Watson Learned the Trick              3            5\n",
              "2     Paris    ON              A Moveable Feast              4            4\n",
              "3  Sallisaw    QB           The Grapes of Wrath              5            3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2a05e5a-154a-46ae-8ba3-55e16518257f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>title</th>\n",
              "      <th>expert_rating</th>\n",
              "      <th>user_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>London</td>\n",
              "      <td>NY</td>\n",
              "      <td>His Last Bow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>London</td>\n",
              "      <td>NJ</td>\n",
              "      <td>How Watson Learned the Trick</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paris</td>\n",
              "      <td>ON</td>\n",
              "      <td>A Moveable Feast</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sallisaw</td>\n",
              "      <td>QB</td>\n",
              "      <td>The Grapes of Wrath</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2a05e5a-154a-46ae-8ba3-55e16518257f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2a05e5a-154a-46ae-8ba3-55e16518257f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2a05e5a-154a-46ae-8ba3-55e16518257f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4074cf60-d94d-4eb3-8f47-4d166e05dc48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4074cf60-d94d-4eb3-8f47-4d166e05dc48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4074cf60-d94d-4eb3-8f47-4d166e05dc48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"London\",\n          \"Paris\",\n          \"Sallisaw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"NJ\",\n          \"QB\",\n          \"NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"How Watson Learned the Trick\",\n          \"The Grapes of Wrath\",\n          \"His Last Bow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expert_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector\n",
        "\n",
        "# using columntrasnformer avoids data leakage that happens if we preprocess before splitting/sklearn training.\n",
        "# Also, can be parameterized.\n",
        "\n",
        "column_trans = ColumnTransformer(\n",
        "    [('categories', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['city']), # list for most transformers like this one\n",
        "     ('title_bow', CountVectorizer(), 'title'),\n",
        "     ('standard_scaler', StandardScaler(), make_column_selector(dtype_include=np.number))\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# NOTE:\n",
        "# shouldn't fit before split\n",
        "column_trans.fit(X)\n",
        "\n",
        "column_trans.get_feature_names_out()\n",
        "\n",
        "feature_set = column_trans.transform(X)#.toarray()\n",
        "feature_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "bpPEb5Px8dIf",
        "outputId": "2e7048c2-e784-44ae-8df9-16f508cb53c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('categories',\n",
              "                                 OneHotEncoder(dtype='int',\n",
              "                                               handle_unknown='ignore'),\n",
              "                                 ['city']),\n",
              "                                ('title_bow', CountVectorizer(), 'title'),\n",
              "                                ('standard_scaler', StandardScaler(),\n",
              "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80>)])"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-11 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-11 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-11 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-11 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-11 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">title_bow</label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">standard_scaler</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['categories__city_London', 'categories__city_Paris',\n",
              "       'categories__city_Sallisaw', 'title_bow__bow', 'title_bow__feast',\n",
              "       'title_bow__grapes', 'title_bow__his', 'title_bow__how',\n",
              "       'title_bow__last', 'title_bow__learned', 'title_bow__moveable',\n",
              "       'title_bow__of', 'title_bow__the', 'title_bow__trick',\n",
              "       'title_bow__watson', 'title_bow__wrath',\n",
              "       'standard_scaler__expert_rating', 'standard_scaler__user_rating'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.90453403,  0.        ],\n",
              "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
              "         0.        , -1.50755672,  1.41421356],\n",
              "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        , -0.30151134,  0.        ],\n",
              "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.90453403, -1.41421356]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "import joblib\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = make_pipeline(column_trans, RandomForestClassifier())\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X.drop(columns=['user_rating']),\n",
        "    X['user_rating'],\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the pipeline for future use\n",
        "joblib.dump(pipeline, 'pipeline.pkl')\n",
        "\n",
        "# Later, load the pipeline and use it to make predictions on new data\n",
        "pipeline_loaded = joblib.load('pipeline.pkl')\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = pipeline_loaded.predict(X_valid)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yaMpQrVS-vEO",
        "outputId": "7748907d-bb5f-4245-d78b-fad2d05ac48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('categories',\n",
              "                                                  OneHotEncoder(dtype='int',\n",
              "                                                                handle_unknown='ignore'),\n",
              "                                                  ['city']),\n",
              "                                                 ('title_bow',\n",
              "                                                  CountVectorizer(), 'title'),\n",
              "                                                 ('standard_scaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80>)])),\n",
              "                ('randomforestclassifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-12 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-12 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-12 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-12 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-12 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;columntransformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">title_bow</label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">standard_scaler</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# can use cross_val_score for pileine\n",
        "\n",
        "scores = cross_val_score(pipeline, X.drop(columns=['user_rating']), X['user_rating'], cv=2)\n",
        "print(f\"Mean accuracy: {scores.mean():.2f}+/-{scores.std():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bErLizKk8dGK",
        "outputId": "e24ec8a3-d3b0-4cdb-b74f-0bc2f42384b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.25+/-0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkN8LvtF8dEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKQu19YN8brh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JjXIKtj8bpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "eN9R03nzkIG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "embedding_model = \"all-MiniLM-L12-v2\""
      ],
      "metadata": {
        "id": "Cjamqpgpll2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "782BsT8iv-rR",
        "outputId": "694350b3-8a95-49de-8255-2adb1f6e244f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
        "                                stop_words = 'english',\n",
        "                                lowercase = True,\n",
        "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
        "                                max_df = 0.5,\n",
        "                                min_df = 1)\n",
        "\n",
        "dtm_tf = tf_vectorizer.fit_transform(docs)\n",
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "dtm_tfidf = tfidf_vectorizer.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = dtm_tf.toarray()\n",
        "dense_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZSqLl0eNca7",
        "outputId": "d7a5d45d-112a-4610-ce8a-067f232cc0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix_tfidf = dtm_tfidf.toarray()\n",
        "print(dense_matrix_tfidf.shape)\n",
        "dense_matrix_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkuUfBpcN9yE",
        "outputId": "0a2d8cbc-7996-49a0-cb28-745e6e8296db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99, 213)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.31802142, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "uDxUZISdv-pM",
        "outputId": "67ff433b-7e99-43af-c7a5-fdb481de319c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LatentDirichletAllocation<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# for TF DTM\n",
        "lda_tf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tf.fit(dtm_tf)\n",
        "\n",
        "# for TFIDF DTM\n",
        "lda_tfidf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tfidf.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCKyiTWEve41",
        "outputId": "cfe7d55f-f5e4-4b27-fa7e-e7013dd9eb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from pyLDAvis import lda_model as psk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "_UC_HKnLPA_n",
        "outputId": "da270a1b-f388-4d0e-c665-1504dd5c3fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "corpus = docs.copy()\n",
        "\n",
        "# Preprocessing the corpus\n",
        "tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# Creating the dictionary\n",
        "dictionary = corpora.Dictionary(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35wyJZsXOq2N",
        "outputId": "ef8ee599-402d-4936-82ec-26491825430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BHIyW4OrTm",
        "outputId": "348632ee-c1cc-4d09-d405-cdb6823967b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'wrought-iron',\n",
              "  'lattice',\n",
              "  'tower',\n",
              "  'on',\n",
              "  'the',\n",
              "  'champ',\n",
              "  'de',\n",
              "  'mars',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'france.'],\n",
              " ['constructed',\n",
              "  'from',\n",
              "  '1887',\n",
              "  'to',\n",
              "  '1889',\n",
              "  'as',\n",
              "  'the',\n",
              "  'entrance',\n",
              "  'to',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair,',\n",
              "  'it',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'criticized',\n",
              "  'by',\n",
              "  'some',\n",
              "  'of',\n",
              "  \"france's\",\n",
              "  'leading',\n",
              "  'artists',\n",
              "  'and',\n",
              "  'intellectuals.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall,',\n",
              "  'about',\n",
              "  'the',\n",
              "  'same',\n",
              "  'height',\n",
              "  'as',\n",
              "  'an',\n",
              "  '81-story',\n",
              "  'building.'],\n",
              " ['during',\n",
              "  'its',\n",
              "  'construction,',\n",
              "  'the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'surpassed',\n",
              "  'the',\n",
              "  'washington',\n",
              "  'monument',\n",
              "  'to',\n",
              "  'become',\n",
              "  'the',\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'held',\n",
              "  'this',\n",
              "  'title',\n",
              "  'for',\n",
              "  '41',\n",
              "  'years',\n",
              "  'until',\n",
              "  'the',\n",
              "  'chrysler',\n",
              "  'building',\n",
              "  'in',\n",
              "  'new',\n",
              "  'york',\n",
              "  'city',\n",
              "  'was',\n",
              "  'finished',\n",
              "  'in',\n",
              "  '1930.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'three',\n",
              "  'levels',\n",
              "  'for',\n",
              "  'visitors,',\n",
              "  'with',\n",
              "  'restaurants',\n",
              "  'on',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.'],\n",
              " ['the',\n",
              "  'top',\n",
              "  \"level's\",\n",
              "  'upper',\n",
              "  'platform',\n",
              "  'is',\n",
              "  '276',\n",
              "  'm',\n",
              "  'above',\n",
              "  'the',\n",
              "  'ground',\n",
              "  '–',\n",
              "  'the',\n",
              "  'highest',\n",
              "  'observation',\n",
              "  'deck',\n",
              "  'accessible',\n",
              "  'to',\n",
              "  'the',\n",
              "  'public',\n",
              "  'in',\n",
              "  'the',\n",
              "  'european',\n",
              "  'union.'],\n",
              " ['tickets',\n",
              "  'can',\n",
              "  'be',\n",
              "  'purchased',\n",
              "  'to',\n",
              "  'ascend',\n",
              "  'by',\n",
              "  'stairs',\n",
              "  'or',\n",
              "  'lift',\n",
              "  'to',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.'],\n",
              " ['to',\n",
              "  'reach',\n",
              "  'the',\n",
              "  'top',\n",
              "  'level,',\n",
              "  'a',\n",
              "  'lift',\n",
              "  'must',\n",
              "  'be',\n",
              "  'taken',\n",
              "  'from',\n",
              "  'the',\n",
              "  'second',\n",
              "  'level.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monument',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world;',\n",
              "  '6.91',\n",
              "  'million',\n",
              "  'people',\n",
              "  'ascended',\n",
              "  'it',\n",
              "  'in',\n",
              "  '2015.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'received',\n",
              "  'its',\n",
              "  '250',\n",
              "  'millionth',\n",
              "  'visitor',\n",
              "  'in',\n",
              "  '2010.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'named',\n",
              "  'after',\n",
              "  'the',\n",
              "  'engineer',\n",
              "  'gustave',\n",
              "  'eiffel,',\n",
              "  'whose',\n",
              "  'company',\n",
              "  'designed',\n",
              "  'and',\n",
              "  'built',\n",
              "  'the',\n",
              "  'tower.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'intended',\n",
              "  'to',\n",
              "  'be',\n",
              "  'dismantled',\n",
              "  'and',\n",
              "  'scrapped',\n",
              "  'after',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['eiffel',\n",
              "  'had',\n",
              "  'a',\n",
              "  'permit',\n",
              "  'for',\n",
              "  'the',\n",
              "  'tower',\n",
              "  'to',\n",
              "  'stand',\n",
              "  'for',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['but',\n",
              "  'as',\n",
              "  'it',\n",
              "  'proved',\n",
              "  'valuable',\n",
              "  'for',\n",
              "  'radiotelegraphy,',\n",
              "  'it',\n",
              "  'was',\n",
              "  'allowed',\n",
              "  'to',\n",
              "  'remain',\n",
              "  'after',\n",
              "  'the',\n",
              "  'permit',\n",
              "  'expired',\n",
              "  'in',\n",
              "  '1909.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'became',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'featured',\n",
              "  'in',\n",
              "  'media',\n",
              "  'and',\n",
              "  'has',\n",
              "  'been',\n",
              "  'used',\n",
              "  'in',\n",
              "  'various',\n",
              "  'films,',\n",
              "  'advertisements,',\n",
              "  'and',\n",
              "  'television',\n",
              "  'shows.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'been',\n",
              "  'visited',\n",
              "  'by',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'people',\n",
              "  'since',\n",
              "  'it',\n",
              "  'was',\n",
              "  'completed',\n",
              "  'in',\n",
              "  '1889.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'also',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'been',\n",
              "  'both',\n",
              "  'praised',\n",
              "  'and',\n",
              "  'criticized',\n",
              "  'since',\n",
              "  'its',\n",
              "  'construction.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'the',\n",
              "  \"world's\",\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'until',\n",
              "  'the',\n",
              "  'completion',\n",
              "  'of',\n",
              "  'the',\n",
              "  'chrysler',\n",
              "  'building',\n",
              "  'in',\n",
              "  'new',\n",
              "  'york',\n",
              "  'city',\n",
              "  'in',\n",
              "  '1930.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'and',\n",
              "  'regularly',\n",
              "  'repainted',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'rust.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'iconic',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'paris',\n",
              "  'and',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'also',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'cultural',\n",
              "  'and',\n",
              "  'historical',\n",
              "  'landmark.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'tourists',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'illuminated',\n",
              "  'by',\n",
              "  '20,000',\n",
              "  'light',\n",
              "  'bulbs',\n",
              "  'every',\n",
              "  'evening.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'featured',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'films',\n",
              "  'and',\n",
              "  'television',\n",
              "  'shows.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'innovation',\n",
              "  'and',\n",
              "  'engineering',\n",
              "  'excellence.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'built',\n",
              "  'for',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'celebrating',\n",
              "  'the',\n",
              "  '100th',\n",
              "  'anniversary',\n",
              "  'of',\n",
              "  'the',\n",
              "  'french',\n",
              "  'revolution.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'named',\n",
              "  'after',\n",
              "  'its',\n",
              "  'engineer,',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monuments',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'stands',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall',\n",
              "  'and',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'paris.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'three',\n",
              "  'visitor',\n",
              "  'levels',\n",
              "  'with',\n",
              "  'restaurants',\n",
              "  'and',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'criticized',\n",
              "  'by',\n",
              "  'some',\n",
              "  'of',\n",
              "  \"france's\",\n",
              "  'leading',\n",
              "  'artists',\n",
              "  'and',\n",
              "  'intellectuals.'],\n",
              " ['today,',\n",
              "  'it',\n",
              "  'is',\n",
              "  'widely',\n",
              "  'regarded',\n",
              "  'as',\n",
              "  'a',\n",
              "  'masterpiece',\n",
              "  'of',\n",
              "  'structural',\n",
              "  'art.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'architectural',\n",
              "  'marvel',\n",
              "  'and',\n",
              "  'a',\n",
              "  'must-see',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'constructed',\n",
              "  'using',\n",
              "  '18,038',\n",
              "  'pieces',\n",
              "  'of',\n",
              "  'wrought',\n",
              "  'iron.'],\n",
              " ['it', 'weighs', 'approximately', '10,100', 'tons.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'the',\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'until',\n",
              "  '1930.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'repainted',\n",
              "  'every',\n",
              "  'seven',\n",
              "  'years',\n",
              "  'to',\n",
              "  'maintain',\n",
              "  'its',\n",
              "  'appearance.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'elevators',\n",
              "  'travel',\n",
              "  'a',\n",
              "  'combined',\n",
              "  'distance',\n",
              "  'of',\n",
              "  '103,000',\n",
              "  'km',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'appeared',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'movies,',\n",
              "  'tv',\n",
              "  'shows,',\n",
              "  'and',\n",
              "  'advertisements.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'popular',\n",
              "  'destination',\n",
              "  'for',\n",
              "  'tourists',\n",
              "  'visiting',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'enduring',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'art',\n",
              "  'and',\n",
              "  'engineering.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'from',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'globally.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'by',\n",
              "  'the',\n",
              "  'city',\n",
              "  'of',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'attractions',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'human',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'creativity.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'construction',\n",
              "  'involved',\n",
              "  'more',\n",
              "  'than',\n",
              "  '300',\n",
              "  'workers.'],\n",
              " ['it',\n",
              "  'took',\n",
              "  'two',\n",
              "  'years,',\n",
              "  'two',\n",
              "  'months,',\n",
              "  'and',\n",
              "  'five',\n",
              "  'days',\n",
              "  'to',\n",
              "  'complete.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'prime',\n",
              "  'example',\n",
              "  'of',\n",
              "  '19th-century',\n",
              "  'engineering.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'repainted',\n",
              "  '19',\n",
              "  'times',\n",
              "  'since',\n",
              "  'it',\n",
              "  'was',\n",
              "  'built.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'coated',\n",
              "  'with',\n",
              "  '60',\n",
              "  'tons',\n",
              "  'of',\n",
              "  'paint',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'the',\n",
              "  'elements.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'and',\n",
              "  'construction',\n",
              "  'were',\n",
              "  'revolutionary',\n",
              "  'for',\n",
              "  'its',\n",
              "  'time.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'originally',\n",
              "  'intended',\n",
              "  'to',\n",
              "  'be',\n",
              "  'dismantled',\n",
              "  'after',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['it',\n",
              "  'became',\n",
              "  'a',\n",
              "  'permanent',\n",
              "  'fixture',\n",
              "  'due',\n",
              "  'to',\n",
              "  'its',\n",
              "  'usefulness',\n",
              "  'as',\n",
              "  'a',\n",
              "  'radiotelegraph',\n",
              "  'station.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'now',\n",
              "  'an',\n",
              "  'iconic',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'paris',\n",
              "  'and',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'landmarks',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'must-visit',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'traveling',\n",
              "  'to',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'three',\n",
              "  'observation',\n",
              "  'levels.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'pride',\n",
              "  'and',\n",
              "  'innovation',\n",
              "  'since',\n",
              "  'its',\n",
              "  'completion.'],\n",
              " ['it',\n",
              "  'continues',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'draw',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'influenced',\n",
              "  'many',\n",
              "  'other',\n",
              "  'structures',\n",
              "  'worldwide.'],\n",
              " ['it',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'vision',\n",
              "  'of',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'historical',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'landmark.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'each',\n",
              "  'year,',\n",
              "  'making',\n",
              "  'it',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'destinations',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'illuminated',\n",
              "  'by',\n",
              "  '20,000',\n",
              "  'light',\n",
              "  'bulbs',\n",
              "  'every',\n",
              "  'evening.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'love',\n",
              "  'and',\n",
              "  'romance,',\n",
              "  'attracting',\n",
              "  'couples',\n",
              "  'from',\n",
              "  'all',\n",
              "  'over',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'appeared',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'films,',\n",
              "  'television',\n",
              "  'shows,',\n",
              "  'and',\n",
              "  'advertisements.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'construction',\n",
              "  'was',\n",
              "  'a',\n",
              "  'feat',\n",
              "  'of',\n",
              "  'engineering',\n",
              "  'and',\n",
              "  'design.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'stood',\n",
              "  'the',\n",
              "  'test',\n",
              "  'of',\n",
              "  'time',\n",
              "  'and',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'beloved',\n",
              "  'landmark.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'major',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'tourists',\n",
              "  'visiting',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'human',\n",
              "  'creativity',\n",
              "  'and',\n",
              "  'innovation.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'and',\n",
              "  'construction',\n",
              "  'were',\n",
              "  'revolutionary',\n",
              "  'for',\n",
              "  'its',\n",
              "  'time.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'and',\n",
              "  'regularly',\n",
              "  'repainted',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'rust.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'architectural',\n",
              "  'marvel',\n",
              "  'and',\n",
              "  'a',\n",
              "  'must-see',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'stands',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall',\n",
              "  'and',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'built',\n",
              "  'for',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'constructed',\n",
              "  'using',\n",
              "  '18,038',\n",
              "  'pieces',\n",
              "  'of',\n",
              "  'wrought',\n",
              "  'iron.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monuments',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'from',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'pride',\n",
              "  'and',\n",
              "  'innovation',\n",
              "  'since',\n",
              "  'its',\n",
              "  'completion.'],\n",
              " ['it',\n",
              "  'continues',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'draw',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'influenced',\n",
              "  'many',\n",
              "  'other',\n",
              "  'structures',\n",
              "  'worldwide.'],\n",
              " ['it',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'vision',\n",
              "  'of',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'historical',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'landmark.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'each',\n",
              "  'year,',\n",
              "  'making',\n",
              "  'it',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'destinations',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'must-visit',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'traveling',\n",
              "  'to',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.']]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XidTIK7yOtHg",
        "outputId": "7d73c1fa-f9ff-4786-ec4d-f449f593ab6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x794a3e0984f0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRm-v7jeP-sk",
        "outputId": "d4bb7abb-aea1-4076-8e8a-f441e68d43e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'champ': 1, 'de': 2, 'eiffel': 3, 'france.': 4, 'in': 5, 'is': 6, 'lattice': 7, 'mars': 8, 'on': 9, 'paris,': 10, 'the': 11, 'tower': 12, 'wrought-iron': 13, '1887': 14, '1889': 15, 'and': 16, 'artists': 17, 'as': 18, 'by': 19, 'constructed': 20, 'criticized': 21, 'entrance': 22, 'fair,': 23, \"france's\": 24, 'from': 25, 'initially': 26, 'intellectuals.': 27, 'it': 28, 'leading': 29, 'of': 30, 'some': 31, 'to': 32, 'was': 33, \"world's\": 34, '324': 35, '81-story': 36, 'about': 37, 'an': 38, 'building.': 39, 'height': 40, 'meters': 41, 'same': 42, 'tall,': 43, 'become': 44, 'construction,': 45, 'during': 46, 'its': 47, 'man-made': 48, 'monument': 49, 'structure': 50, 'surpassed': 51, 'tallest': 52, 'washington': 53, 'world.': 54, '1930.': 55, '41': 56, 'building': 57, 'chrysler': 58, 'city': 59, 'finished': 60, 'for': 61, 'held': 62, 'new': 63, 'this': 64, 'title': 65, 'until': 66, 'years': 67, 'york': 68, 'first': 69, 'has': 70, 'levels': 71, 'levels.': 72, 'restaurants': 73, 'second': 74, 'three': 75, 'visitors,': 76, 'with': 77, '276': 78, 'above': 79, 'accessible': 80, 'deck': 81, 'european': 82, 'ground': 83, 'highest': 84, \"level's\": 85, 'm': 86, 'observation': 87, 'platform': 88, 'public': 89, 'top': 90, 'union.': 91, 'upper': 92, '–': 93, 'ascend': 94, 'be': 95, 'can': 96, 'lift': 97, 'or': 98, 'purchased': 99, 'stairs': 100, 'tickets': 101, 'level,': 102, 'level.': 103, 'must': 104, 'reach': 105, 'taken': 106, '2015.': 107, '6.91': 108, 'ascended': 109, 'million': 110, 'most-visited': 111, 'paid': 112, 'people': 113, 'world;': 114, '2010.': 115, '250': 116, 'millionth': 117, 'received': 118, 'visitor': 119, 'after': 120, 'built': 121, 'company': 122, 'designed': 123, 'eiffel,': 124, 'engineer': 125, 'gustave': 126, 'named': 127, 'tower.': 128, 'whose': 129, '20': 130, 'dismantled': 131, 'intended': 132, 'scrapped': 133, 'years.': 134, 'had': 135, 'permit': 136, 'stand': 137, '1909.': 138, 'allowed': 139, 'but': 140, 'expired': 141, 'proved': 142, 'radiotelegraphy,': 143, 'remain': 144, 'valuable': 145, 'became': 146, 'cultural': 147, 'france': 148, 'global': 149, 'icon.': 150, 'symbol': 151, 'most': 152, 'one': 153, 'recognizable': 154, 'structures': 155, 'advertisements,': 156, 'been': 157, 'featured': 158, 'films,': 159, 'media': 160, 'shows.': 161, 'television': 162, 'used': 163, 'various': 164, 'attraction': 165, 'major': 166, 'tourist': 167, '1889.': 168, 'completed': 169, 'millions': 170, 'since': 171, 'visited': 172, 'also': 173, 'around': 174, 'inspired': 175, 'many': 176, 'replicas': 177, 'similar': 178, 'both': 179, 'construction.': 180, 'design': 181, 'praised': 182, \"tower's\": 183, 'completion': 184, 'maintained': 185, 'protect': 186, 'regularly': 187, 'repainted': 188, 'rust.': 189, 'iconic': 190, 'paris': 191, 'historical': 192, 'landmark.': 193, 'significant': 194, 'attracts': 195, 'each': 196, 'tourists': 197, 'year.': 198, '20,000': 199, 'bulbs': 200, 'evening.': 201, 'every': 202, 'illuminated': 203, 'light': 204, 'films': 205, 'numerous': 206, 'engineering': 207, 'excellence.': 208, 'innovation': 209, '100th': 210, 'anniversary': 211, 'celebrating': 212, 'fair': 213, 'french': 214, 'revolution.': 215, 'eiffel.': 216, 'engineer,': 217, 'monuments': 218, 'offers': 219, 'paris.': 220, 'stands': 221, 'stunning': 222, 'tall': 223, 'views': 224, 'decks.': 225, 'art.': 226, 'masterpiece': 227, 'regarded': 228, 'structural': 229, 'today,': 230, 'widely': 231, 'architectural': 232, 'marvel': 233, 'must-see': 234, '18,038': 235, 'iron.': 236, 'pieces': 237, 'using': 238, 'wrought': 239, '10,100': 240, 'approximately': 241, 'tons.': 242, 'weighs': 243, 'appearance.': 244, 'maintain': 245, 'seven': 246, '103,000': 247, 'combined': 248, 'distance': 249, 'elevators': 250, 'km': 251, 'travel': 252, 'advertisements.': 253, 'appeared': 254, 'movies,': 255, 'shows,': 256, 'tv': 257, 'destination': 258, 'popular': 259, 'visiting': 260, 'breathtaking': 261, 'art': 262, 'enduring': 263, 'engineering.': 264, 'visitors': 265, 'world': 266, 'globally.': 267, 'attractions': 268, 'creativity.': 269, 'human': 270, 'ingenuity': 271, 'testament': 272, '300': 273, 'construction': 274, 'involved': 275, 'more': 276, 'than': 277, 'workers.': 278, 'complete.': 279, 'days': 280, 'five': 281, 'months,': 282, 'took': 283, 'two': 284, 'years,': 285, '19th-century': 286, 'example': 287, 'prime': 288, '19': 289, 'built.': 290, 'times': 291, '60': 292, 'coated': 293, 'elements.': 294, 'paint': 295, 'tons': 296, 'revolutionary': 297, 'time.': 298, 'were': 299, 'originally': 300, 'due': 301, 'fixture': 302, 'permanent': 303, 'radiotelegraph': 304, 'station.': 305, 'usefulness': 306, 'now': 307, 'landmarks': 308, 'anyone': 309, 'must-visit': 310, 'traveling': 311, 'completion.': 312, 'pride': 313, 'continues': 314, 'draw': 315, 'influenced': 316, 'other': 317, 'worldwide.': 318, 'remains': 319, 'vision': 320, 'destinations': 321, 'making': 322, 'year,': 323, 'all': 324, 'attracting': 325, 'couples': 326, 'love': 327, 'over': 328, 'romance,': 329, 'design.': 330, 'feat': 331, 'beloved': 332, 'stood': 333, 'test': 334, 'time': 335, 'creativity': 336, 'innovation.': 337, 'city.': 338}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the document-term-frequency matrix\n",
        "doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcFKUHZPUju",
        "outputId": "9ca94ee4-0c50-4392-cc20-99e397e741b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1),\n",
              "  (1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 2),\n",
              "  (12, 2),\n",
              "  (13, 1)],\n",
              " [(11, 2),\n",
              "  (14, 1),\n",
              "  (15, 2),\n",
              "  (16, 1),\n",
              "  (17, 1),\n",
              "  (18, 1),\n",
              "  (19, 1),\n",
              "  (20, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 2),\n",
              "  (33, 1),\n",
              "  (34, 1)],\n",
              " [(6, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (18, 1),\n",
              "  (35, 1),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1)],\n",
              " [(3, 1),\n",
              "  (5, 1),\n",
              "  (11, 4),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (44, 1),\n",
              "  (45, 1),\n",
              "  (46, 1),\n",
              "  (47, 1),\n",
              "  (48, 1),\n",
              "  (49, 1),\n",
              "  (50, 1),\n",
              "  (51, 1),\n",
              "  (52, 1),\n",
              "  (53, 1),\n",
              "  (54, 1)],\n",
              " [(5, 2),\n",
              "  (11, 1),\n",
              "  (28, 1),\n",
              "  (33, 1),\n",
              "  (55, 1),\n",
              "  (56, 1),\n",
              "  (57, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (60, 1),\n",
              "  (61, 1),\n",
              "  (62, 1),\n",
              "  (63, 1),\n",
              "  (64, 1),\n",
              "  (65, 1),\n",
              "  (66, 1),\n",
              "  (67, 1),\n",
              "  (68, 1)],\n",
              " [(9, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (61, 1),\n",
              "  (69, 1),\n",
              "  (70, 1),\n",
              "  (71, 1),\n",
              "  (72, 1),\n",
              "  (73, 1),\n",
              "  (74, 1),\n",
              "  (75, 1),\n",
              "  (76, 1),\n",
              "  (77, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 5),\n",
              "  (32, 1),\n",
              "  (78, 1),\n",
              "  (79, 1),\n",
              "  (80, 1),\n",
              "  (81, 1),\n",
              "  (82, 1),\n",
              "  (83, 1),\n",
              "  (84, 1),\n",
              "  (85, 1),\n",
              "  (86, 1),\n",
              "  (87, 1),\n",
              "  (88, 1),\n",
              "  (89, 1),\n",
              "  (90, 1),\n",
              "  (91, 1),\n",
              "  (92, 1),\n",
              "  (93, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (19, 1),\n",
              "  (32, 2),\n",
              "  (69, 1),\n",
              "  (72, 1),\n",
              "  (74, 1),\n",
              "  (94, 1),\n",
              "  (95, 1),\n",
              "  (96, 1),\n",
              "  (97, 1),\n",
              "  (98, 1),\n",
              "  (99, 1),\n",
              "  (100, 1),\n",
              "  (101, 1)],\n",
              " [(0, 1),\n",
              "  (11, 2),\n",
              "  (25, 1),\n",
              "  (32, 1),\n",
              "  (74, 1),\n",
              "  (90, 1),\n",
              "  (95, 1),\n",
              "  (97, 1),\n",
              "  (102, 1),\n",
              "  (103, 1),\n",
              "  (104, 1),\n",
              "  (105, 1),\n",
              "  (106, 1)],\n",
              " [(3, 1),\n",
              "  (5, 2),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (28, 1),\n",
              "  (49, 1),\n",
              "  (107, 1),\n",
              "  (108, 1),\n",
              "  (109, 1),\n",
              "  (110, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (113, 1),\n",
              "  (114, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (47, 1),\n",
              "  (115, 1),\n",
              "  (116, 1),\n",
              "  (117, 1),\n",
              "  (118, 1),\n",
              "  (119, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (120, 1),\n",
              "  (121, 1),\n",
              "  (122, 1),\n",
              "  (123, 1),\n",
              "  (124, 1),\n",
              "  (125, 1),\n",
              "  (126, 1),\n",
              "  (127, 1),\n",
              "  (128, 1),\n",
              "  (129, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (26, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (95, 1),\n",
              "  (120, 1),\n",
              "  (130, 1),\n",
              "  (131, 1),\n",
              "  (132, 1),\n",
              "  (133, 1),\n",
              "  (134, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 2),\n",
              "  (130, 1),\n",
              "  (134, 1),\n",
              "  (135, 1),\n",
              "  (136, 1),\n",
              "  (137, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (18, 1),\n",
              "  (28, 2),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (61, 1),\n",
              "  (120, 1),\n",
              "  (136, 1),\n",
              "  (138, 1),\n",
              "  (139, 1),\n",
              "  (140, 1),\n",
              "  (141, 1),\n",
              "  (142, 1),\n",
              "  (143, 1),\n",
              "  (144, 1),\n",
              "  (145, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (146, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(5, 2),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 2),\n",
              "  (70, 1),\n",
              "  (156, 1),\n",
              "  (157, 1),\n",
              "  (158, 1),\n",
              "  (159, 1),\n",
              "  (160, 1),\n",
              "  (161, 1),\n",
              "  (162, 1),\n",
              "  (163, 1),\n",
              "  (164, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (10, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (165, 1),\n",
              "  (166, 1),\n",
              "  (167, 1)],\n",
              " [(5, 1),\n",
              "  (19, 1),\n",
              "  (28, 2),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (70, 1),\n",
              "  (113, 1),\n",
              "  (157, 1),\n",
              "  (168, 1),\n",
              "  (169, 1),\n",
              "  (170, 1),\n",
              "  (171, 1),\n",
              "  (172, 1)],\n",
              " [(11, 2),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (173, 1),\n",
              "  (174, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (21, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (179, 1),\n",
              "  (180, 1),\n",
              "  (181, 1),\n",
              "  (182, 1),\n",
              "  (183, 1)],\n",
              " [(5, 2),\n",
              "  (11, 3),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (48, 1),\n",
              "  (50, 1),\n",
              "  (52, 1),\n",
              "  (55, 1),\n",
              "  (57, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (63, 1),\n",
              "  (66, 1),\n",
              "  (68, 1),\n",
              "  (184, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (185, 1),\n",
              "  (186, 1),\n",
              "  (187, 1),\n",
              "  (188, 1),\n",
              "  (189, 1)],\n",
              " [(3, 1),\n",
              "  (4, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (190, 1),\n",
              "  (191, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (147, 1),\n",
              "  (173, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (197, 1),\n",
              "  (198, 1)],\n",
              " [(6, 1),\n",
              "  (19, 1),\n",
              "  (28, 1),\n",
              "  (199, 1),\n",
              "  (200, 1),\n",
              "  (201, 1),\n",
              "  (202, 1),\n",
              "  (203, 1),\n",
              "  (204, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (158, 1),\n",
              "  (161, 1),\n",
              "  (162, 1),\n",
              "  (205, 1),\n",
              "  (206, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (207, 1),\n",
              "  (208, 1),\n",
              "  (209, 1)],\n",
              " [(5, 1),\n",
              "  (10, 1),\n",
              "  (11, 3),\n",
              "  (15, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (61, 1),\n",
              "  (121, 1),\n",
              "  (210, 1),\n",
              "  (211, 1),\n",
              "  (212, 1),\n",
              "  (213, 1),\n",
              "  (214, 1),\n",
              "  (215, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (47, 1),\n",
              "  (120, 1),\n",
              "  (126, 1),\n",
              "  (127, 1),\n",
              "  (216, 1),\n",
              "  (217, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (153, 1),\n",
              "  (218, 1)],\n",
              " [(16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (35, 1),\n",
              "  (41, 1),\n",
              "  (219, 1),\n",
              "  (220, 1),\n",
              "  (221, 1),\n",
              "  (222, 1),\n",
              "  (223, 1),\n",
              "  (224, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (71, 1),\n",
              "  (73, 1),\n",
              "  (75, 1),\n",
              "  (77, 1),\n",
              "  (87, 1),\n",
              "  (119, 1),\n",
              "  (225, 1)],\n",
              " [(16, 1),\n",
              "  (17, 1),\n",
              "  (19, 1),\n",
              "  (21, 1),\n",
              "  (24, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (33, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (18, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (226, 1),\n",
              "  (227, 1),\n",
              "  (228, 1),\n",
              "  (229, 1),\n",
              "  (230, 1),\n",
              "  (231, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (38, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (232, 1),\n",
              "  (233, 1),\n",
              "  (234, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (20, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (235, 1),\n",
              "  (236, 1),\n",
              "  (237, 1),\n",
              "  (238, 1),\n",
              "  (239, 1)],\n",
              " [(28, 1), (240, 1), (241, 1), (242, 1), (243, 1)],\n",
              " [(3, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (33, 1),\n",
              "  (48, 1),\n",
              "  (50, 1),\n",
              "  (52, 1),\n",
              "  (55, 1),\n",
              "  (66, 1)],\n",
              " [(6, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (47, 1),\n",
              "  (67, 1),\n",
              "  (188, 1),\n",
              "  (202, 1),\n",
              "  (244, 1),\n",
              "  (245, 1),\n",
              "  (246, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (30, 1),\n",
              "  (183, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (247, 1),\n",
              "  (248, 1),\n",
              "  (249, 1),\n",
              "  (250, 1),\n",
              "  (251, 1),\n",
              "  (252, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (70, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(5, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (70, 1),\n",
              "  (206, 1),\n",
              "  (253, 1),\n",
              "  (254, 1),\n",
              "  (255, 1),\n",
              "  (256, 1),\n",
              "  (257, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (61, 1),\n",
              "  (197, 1),\n",
              "  (220, 1),\n",
              "  (258, 1),\n",
              "  (259, 1),\n",
              "  (260, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (214, 1),\n",
              "  (262, 1),\n",
              "  (263, 1),\n",
              "  (264, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (174, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (265, 1),\n",
              "  (266, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1),\n",
              "  (267, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (19, 1),\n",
              "  (30, 1),\n",
              "  (59, 1),\n",
              "  (185, 1),\n",
              "  (220, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (259, 1),\n",
              "  (268, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (32, 1),\n",
              "  (269, 1),\n",
              "  (270, 1),\n",
              "  (271, 1),\n",
              "  (272, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (183, 1),\n",
              "  (273, 1),\n",
              "  (274, 1),\n",
              "  (275, 1),\n",
              "  (276, 1),\n",
              "  (277, 1),\n",
              "  (278, 1)],\n",
              " [(16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (279, 1),\n",
              "  (280, 1),\n",
              "  (281, 1),\n",
              "  (282, 1),\n",
              "  (283, 1),\n",
              "  (284, 2),\n",
              "  (285, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (264, 1),\n",
              "  (286, 1),\n",
              "  (287, 1),\n",
              "  (288, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (28, 1),\n",
              "  (33, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (188, 1),\n",
              "  (289, 1),\n",
              "  (290, 1),\n",
              "  (291, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (25, 1),\n",
              "  (28, 2),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (77, 1),\n",
              "  (186, 1),\n",
              "  (292, 1),\n",
              "  (293, 1),\n",
              "  (294, 1),\n",
              "  (295, 1),\n",
              "  (296, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (47, 1),\n",
              "  (61, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (274, 1),\n",
              "  (297, 1),\n",
              "  (298, 1),\n",
              "  (299, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (95, 1),\n",
              "  (120, 1),\n",
              "  (130, 1),\n",
              "  (131, 1),\n",
              "  (132, 1),\n",
              "  (134, 1),\n",
              "  (300, 1)],\n",
              " [(0, 2),\n",
              "  (18, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (47, 1),\n",
              "  (146, 1),\n",
              "  (301, 1),\n",
              "  (302, 1),\n",
              "  (303, 1),\n",
              "  (304, 1),\n",
              "  (305, 1),\n",
              "  (306, 1)],\n",
              " [(4, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (190, 1),\n",
              "  (191, 1),\n",
              "  (307, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (308, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (309, 1),\n",
              "  (310, 1),\n",
              "  (311, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (72, 1),\n",
              "  (75, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (222, 1),\n",
              "  (224, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (209, 1),\n",
              "  (214, 1),\n",
              "  (312, 1),\n",
              "  (313, 1)],\n",
              " [(0, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (95, 1),\n",
              "  (147, 1),\n",
              "  (150, 1),\n",
              "  (166, 1),\n",
              "  (167, 1),\n",
              "  (314, 1),\n",
              "  (315, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (176, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (316, 1),\n",
              "  (317, 1),\n",
              "  (318, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (126, 1),\n",
              "  (216, 1),\n",
              "  (271, 1),\n",
              "  (272, 1),\n",
              "  (319, 1),\n",
              "  (320, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (147, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (28, 2),\n",
              "  (30, 2),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (259, 1),\n",
              "  (265, 1),\n",
              "  (321, 1),\n",
              "  (322, 1),\n",
              "  (323, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (19, 1),\n",
              "  (199, 1),\n",
              "  (200, 1),\n",
              "  (201, 1),\n",
              "  (202, 1),\n",
              "  (203, 1),\n",
              "  (204, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (324, 1),\n",
              "  (325, 1),\n",
              "  (326, 1),\n",
              "  (327, 1),\n",
              "  (328, 1),\n",
              "  (329, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (159, 1),\n",
              "  (162, 1),\n",
              "  (206, 1),\n",
              "  (253, 1),\n",
              "  (254, 1),\n",
              "  (256, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (183, 1),\n",
              "  (207, 1),\n",
              "  (274, 1),\n",
              "  (330, 1),\n",
              "  (331, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (70, 1),\n",
              "  (193, 1),\n",
              "  (319, 1),\n",
              "  (332, 1),\n",
              "  (333, 1),\n",
              "  (334, 1),\n",
              "  (335, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (166, 1),\n",
              "  (197, 1),\n",
              "  (220, 1),\n",
              "  (260, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (32, 1),\n",
              "  (270, 1),\n",
              "  (272, 1),\n",
              "  (336, 1),\n",
              "  (337, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (47, 1),\n",
              "  (61, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (274, 1),\n",
              "  (297, 1),\n",
              "  (298, 1),\n",
              "  (299, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (70, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (174, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (185, 1),\n",
              "  (186, 1),\n",
              "  (187, 1),\n",
              "  (188, 1),\n",
              "  (189, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (38, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (232, 1),\n",
              "  (233, 1),\n",
              "  (234, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (35, 1),\n",
              "  (41, 1),\n",
              "  (219, 1),\n",
              "  (221, 1),\n",
              "  (222, 1),\n",
              "  (223, 1),\n",
              "  (224, 1),\n",
              "  (338, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (15, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (61, 1),\n",
              "  (121, 1),\n",
              "  (213, 1),\n",
              "  (220, 1)],\n",
              " [(20, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (235, 1),\n",
              "  (236, 1),\n",
              "  (237, 1),\n",
              "  (238, 1),\n",
              "  (239, 1)],\n",
              " [(3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (153, 1),\n",
              "  (218, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (174, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (265, 1),\n",
              "  (266, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (209, 1),\n",
              "  (214, 1),\n",
              "  (312, 1),\n",
              "  (313, 1)],\n",
              " [(0, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (95, 1),\n",
              "  (147, 1),\n",
              "  (150, 1),\n",
              "  (166, 1),\n",
              "  (167, 1),\n",
              "  (314, 1),\n",
              "  (315, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (176, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (316, 1),\n",
              "  (317, 1),\n",
              "  (318, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (126, 1),\n",
              "  (216, 1),\n",
              "  (271, 1),\n",
              "  (272, 1),\n",
              "  (319, 1),\n",
              "  (320, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (147, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (28, 2),\n",
              "  (30, 2),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (259, 1),\n",
              "  (265, 1),\n",
              "  (321, 1),\n",
              "  (322, 1),\n",
              "  (323, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (309, 1),\n",
              "  (310, 1),\n",
              "  (311, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLxrzWRZwDy6",
        "outputId": "d2cafd90-ccaf-4c29-e787-155687e52fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic ID: 0\n",
            "Keywords: 0.039*\"a\" + 0.025*\"of\" + 0.021*\"been\" + 0.019*\"its\" + 0.018*\"the\" + 0.017*\"it\" + 0.017*\"since\" + 0.017*\"innovation\" + 0.016*\"has\" + 0.016*\"symbol\"\n",
            "\n",
            "Topic ID: 1\n",
            "Keywords: 0.100*\"the\" + 0.041*\"tower\" + 0.036*\"and\" + 0.034*\"of\" + 0.032*\"it\" + 0.030*\"is\" + 0.027*\"eiffel\" + 0.025*\"a\" + 0.025*\"in\" + 0.017*\"to\"\n",
            "\n",
            "Topic ID: 2\n",
            "Keywords: 0.037*\"it\" + 0.024*\"to\" + 0.019*\"by\" + 0.019*\"was\" + 0.015*\"every\" + 0.014*\"is\" + 0.014*\"in\" + 0.014*\"the\" + 0.013*\"of\" + 0.013*\"and\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the LDA model\n",
        "lda_model = models.LdaModel(\n",
        "    corpus=doc_term_matrix,\n",
        "    id2word=dictionary,\n",
        "    num_topics=3,\n",
        "    passes=10\n",
        ")\n",
        "\n",
        "# Print the topics and their associated keywords\n",
        "for topic_id, topic_keywords in lda_model.print_topics():\n",
        "    print(f\"Topic ID: {topic_id}\")\n",
        "    print(f\"Keywords: {topic_keywords}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.039 + 0.025 + 0.021 + 0.019 + 0.018 + 0.017 + 0.017 + 0.017 + 0.017 + 0.017 + 0.016 + 0.016"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3Sde2YeMEb",
        "outputId": "4a9e009c-f581-411f-ee85-028b424cc9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2390000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# probabilityies of classes\n",
        "count = 0\n",
        "for doc in lda_model[doc_term_matrix]:\n",
        "  print('doc: ', count, doc)\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A588pKN5SQlS",
        "outputId": "25a3708f-b323-43c2-c436-ce2da5c91162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc:  0 [(0, 0.020409942), (1, 0.95948577), (2, 0.020104341)]\n",
            "doc:  1 [(0, 0.013743013), (1, 0.9680504), (2, 0.01820659)]\n",
            "doc:  2 [(0, 0.02487912), (1, 0.9516799), (2, 0.023440963)]\n",
            "doc:  3 [(0, 0.017305374), (1, 0.9654825), (2, 0.0172121)]\n",
            "doc:  4 [(0, 0.017075544), (1, 0.9644006), (2, 0.01852387)]\n",
            "doc:  5 [(0, 0.021536697), (1, 0.95377016), (2, 0.02469314)]\n",
            "doc:  6 [(0, 0.013790201), (1, 0.97232884), (2, 0.01388099)]\n",
            "doc:  7 [(0, 0.02024811), (1, 0.0247129), (2, 0.95503896)]\n",
            "doc:  8 [(0, 0.023253094), (1, 0.9502289), (2, 0.02651797)]\n",
            "doc:  9 [(0, 0.018043192), (1, 0.9627467), (2, 0.019210184)]\n",
            "doc:  10 [(0, 0.03561684), (1, 0.92980516), (2, 0.034577973)]\n",
            "doc:  11 [(0, 0.019063858), (1, 0.96175236), (2, 0.01918373)]\n",
            "doc:  12 [(0, 0.024361571), (1, 0.94975674), (2, 0.025881682)]\n",
            "doc:  13 [(0, 0.026733823), (1, 0.9440816), (2, 0.02918454)]\n",
            "doc:  14 [(0, 0.018368734), (1, 0.022262083), (2, 0.9593692)]\n",
            "doc:  15 [(0, 0.030910153), (1, 0.9449308), (2, 0.02415906)]\n",
            "doc:  16 [(0, 0.028435117), (1, 0.94275266), (2, 0.028812222)]\n",
            "doc:  17 [(0, 0.020129688), (1, 0.37788385), (2, 0.6019865)]\n",
            "doc:  18 [(0, 0.028678782), (1, 0.9430488), (2, 0.028272403)]\n",
            "doc:  19 [(0, 0.026773496), (1, 0.026800402), (2, 0.9464261)]\n",
            "doc:  20 [(0, 0.024478145), (1, 0.95133626), (2, 0.024185592)]\n",
            "doc:  21 [(0, 0.22459318), (1, 0.7501917), (2, 0.025215147)]\n",
            "doc:  22 [(0, 0.016218945), (1, 0.9672132), (2, 0.016567813)]\n",
            "doc:  23 [(0, 0.026359366), (1, 0.9461076), (2, 0.027533006)]\n",
            "doc:  24 [(0, 0.029558867), (1, 0.94208634), (2, 0.028354809)]\n",
            "doc:  25 [(0, 0.03497868), (1, 0.93047476), (2, 0.03454659)]\n",
            "doc:  26 [(0, 0.03608321), (1, 0.92966735), (2, 0.03424949)]\n",
            "doc:  27 [(0, 0.033838376), (1, 0.03547523), (2, 0.93068635)]\n",
            "doc:  28 [(0, 0.0369452), (1, 0.9222983), (2, 0.04075649)]\n",
            "doc:  29 [(0, 0.5906214), (1, 0.38295633), (2, 0.026422262)]\n",
            "doc:  30 [(0, 0.019165823), (1, 0.96238434), (2, 0.018449798)]\n",
            "doc:  31 [(0, 0.031826627), (1, 0.93662125), (2, 0.03155215)]\n",
            "doc:  32 [(0, 0.02625197), (1, 0.947509), (2, 0.02623903)]\n",
            "doc:  33 [(0, 0.02857591), (1, 0.94278836), (2, 0.02863576)]\n",
            "doc:  34 [(0, 0.026424851), (1, 0.94749075), (2, 0.02608441)]\n",
            "doc:  35 [(0, 0.026425133), (1, 0.9418209), (2, 0.031753927)]\n",
            "doc:  36 [(0, 0.9346196), (1, 0.034924734), (2, 0.030455617)]\n",
            "doc:  37 [(0, 0.024622167), (1, 0.9510835), (2, 0.024294367)]\n",
            "doc:  38 [(0, 0.02843537), (1, 0.94275445), (2, 0.028810145)]\n",
            "doc:  39 [(0, 0.03198185), (1, 0.21524635), (2, 0.75277185)]\n",
            "doc:  40 [(0, 0.8799002), (1, 0.059579905), (2, 0.060519874)]\n",
            "doc:  41 [(0, 0.030777993), (1, 0.9377851), (2, 0.031436853)]\n",
            "doc:  42 [(0, 0.033535987), (1, 0.034949545), (2, 0.9315145)]\n",
            "doc:  43 [(0, 0.9423748), (1, 0.031510353), (2, 0.026114829)]\n",
            "doc:  44 [(0, 0.024552891), (1, 0.9528874), (2, 0.022559714)]\n",
            "doc:  45 [(0, 0.031645585), (1, 0.9365188), (2, 0.031835623)]\n",
            "doc:  46 [(0, 0.03157023), (1, 0.93746984), (2, 0.03095993)]\n",
            "doc:  47 [(0, 0.029183524), (1, 0.94220334), (2, 0.028613146)]\n",
            "doc:  48 [(0, 0.031336416), (1, 0.9423884), (2, 0.026275173)]\n",
            "doc:  49 [(0, 0.029734047), (1, 0.9413838), (2, 0.028882118)]\n",
            "doc:  50 [(0, 0.031408902), (1, 0.9376792), (2, 0.030911917)]\n",
            "doc:  51 [(0, 0.031061484), (1, 0.9331959), (2, 0.0357426)]\n",
            "doc:  52 [(0, 0.026296739), (1, 0.94709814), (2, 0.026605133)]\n",
            "doc:  53 [(0, 0.03234512), (1, 0.9360693), (2, 0.031585548)]\n",
            "doc:  54 [(0, 0.03482527), (1, 0.93103415), (2, 0.034140572)]\n",
            "doc:  55 [(0, 0.028578024), (1, 0.029895281), (2, 0.9415267)]\n",
            "doc:  56 [(0, 0.0356879), (1, 0.929992), (2, 0.034320083)]\n",
            "doc:  57 [(0, 0.17563123), (1, 0.7940778), (2, 0.030290918)]\n",
            "doc:  58 [(0, 0.023163406), (1, 0.95308715), (2, 0.023749433)]\n",
            "doc:  59 [(0, 0.032201264), (1, 0.9367437), (2, 0.03105504)]\n",
            "doc:  60 [(0, 0.026153537), (1, 0.94591814), (2, 0.02792835)]\n",
            "doc:  61 [(0, 0.9472922), (1, 0.026376573), (2, 0.026331242)]\n",
            "doc:  62 [(0, 0.029707257), (1, 0.9418434), (2, 0.0284494)]\n",
            "doc:  63 [(0, 0.028539255), (1, 0.94255686), (2, 0.028903922)]\n",
            "doc:  64 [(0, 0.026576089), (1, 0.9469086), (2, 0.026515296)]\n",
            "doc:  65 [(0, 0.026870782), (1, 0.9458399), (2, 0.027289284)]\n",
            "doc:  66 [(0, 0.9423346), (1, 0.03458553), (2, 0.023079885)]\n",
            "doc:  67 [(0, 0.02897031), (1, 0.9415778), (2, 0.0294519)]\n",
            "doc:  68 [(0, 0.03149549), (1, 0.937775), (2, 0.030729514)]\n",
            "doc:  69 [(0, 0.02698104), (1, 0.94616944), (2, 0.026849534)]\n",
            "doc:  70 [(0, 0.034876432), (1, 0.93119025), (2, 0.033933353)]\n",
            "doc:  71 [(0, 0.017248362), (1, 0.9653964), (2, 0.017355224)]\n",
            "doc:  72 [(0, 0.028494043), (1, 0.28959954), (2, 0.6819064)]\n",
            "doc:  73 [(0, 0.021385368), (1, 0.9583007), (2, 0.020313986)]\n",
            "doc:  74 [(0, 0.02876526), (1, 0.9410359), (2, 0.030198792)]\n",
            "doc:  75 [(0, 0.033289753), (1, 0.93760383), (2, 0.029106447)]\n",
            "doc:  76 [(0, 0.02760001), (1, 0.94565845), (2, 0.026741516)]\n",
            "doc:  77 [(0, 0.031432465), (1, 0.9377044), (2, 0.030863142)]\n",
            "doc:  78 [(0, 0.02918103), (1, 0.94220585), (2, 0.028613104)]\n",
            "doc:  79 [(0, 0.27127784), (1, 0.6996186), (2, 0.029103637)]\n",
            "doc:  80 [(0, 0.028435031), (1, 0.94275534), (2, 0.028809652)]\n",
            "doc:  81 [(0, 0.03220127), (1, 0.9367437), (2, 0.031055035)]\n",
            "doc:  82 [(0, 0.024557495), (1, 0.95288277), (2, 0.022559717)]\n",
            "doc:  83 [(0, 0.02866349), (1, 0.94271755), (2, 0.028618958)]\n",
            "doc:  84 [(0, 0.026359374), (1, 0.9461064), (2, 0.027534263)]\n",
            "doc:  85 [(0, 0.024626013), (1, 0.9510792), (2, 0.024294816)]\n",
            "doc:  86 [(0, 0.02645868), (1, 0.9470567), (2, 0.026484635)]\n",
            "doc:  87 [(0, 0.028152931), (1, 0.9427909), (2, 0.029056145)]\n",
            "doc:  88 [(0, 0.034834273), (1, 0.036347065), (2, 0.92881864)]\n",
            "doc:  89 [(0, 0.024336062), (1, 0.9513426), (2, 0.024321374)]\n",
            "doc:  90 [(0, 0.029731452), (1, 0.9413864), (2, 0.028882086)]\n",
            "doc:  91 [(0, 0.942336), (1, 0.034584083), (2, 0.023079887)]\n",
            "doc:  92 [(0, 0.02897), (1, 0.94157666), (2, 0.029453281)]\n",
            "doc:  93 [(0, 0.031489167), (1, 0.93778133), (2, 0.030729463)]\n",
            "doc:  94 [(0, 0.026981317), (1, 0.9461694), (2, 0.026849322)]\n",
            "doc:  95 [(0, 0.034880362), (1, 0.9311862), (2, 0.033933397)]\n",
            "doc:  96 [(0, 0.017248534), (1, 0.965395), (2, 0.017356439)]\n",
            "doc:  97 [(0, 0.026575632), (1, 0.9469095), (2, 0.026514865)]\n",
            "doc:  98 [(0, 0.029186146), (1, 0.9422007), (2, 0.028613118)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "zLltgZMQwDvl",
        "outputId": "84a46e79-d012-4ef4-aacb-c1266f8aeaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el43871333597757920646228810497\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el43871333597757920646228810497_data = {\"mdsDat\": {\"x\": [-0.1021711599843856, 0.07846078729121515, 0.02371037269317039], \"y\": [-0.020784163540546838, -0.047786713235198966, 0.0685708767757458], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [80.06768233200468, 11.093628527846503, 8.838689140148807]}, \"tinfo\": {\"Term\": [\"a\", \"it\", \"of\", \"to\", \"its\", \"was\", \"symbol\", \"has\", \"been\", \"by\", \"and\", \"since\", \"in\", \"as\", \"french\", \"innovation\", \"tower\", \"every\", \"is\", \"tower's\", \"constructed\", \"each\", \"year.\", \"completion.\", \"pride\", \"using\", \"pieces\", \"18,038\", \"wrought\", \"iron.\", \"eiffel\", \"world.\", \"from\", \"the\", \"one\", \"paris.\", \"tower\", \"structures\", \"cultural\", \"most\", \"city\", \"observation\", \"an\", \"views\", \"offers\", \"tourist\", \"attraction\", \"attracts\", \"many\", \"icon.\", \"design\", \"in\", \"is\", \"for\", \"and\", \"1889\", \"world's\", \"visitors\", \"become\", \"gustave\", \"of\", \"a\", \"it\", \"has\", \"to\", \"was\", \"tower's\", \"its\", \"symbol\", \"every\", \"using\", \"18,038\", \"pieces\", \"wrought\", \"iron.\", \"two\", \"evening.\", \"illuminated\", \"light\", \"20,000\", \"bulbs\", \"remain\", \"1909.\", \"but\", \"expired\", \"valuable\", \"proved\", \"radiotelegraphy,\", \"allowed\", \"can\", \"purchased\", \"stairs\", \"tickets\", \"visited\", \"ascend\", \"or\", \"1889.\", \"completed\", \"five\", \"by\", \"constructed\", \"it\", \"was\", \"to\", \"been\", \"in\", \"is\", \"of\", \"and\", \"the\", \"has\", \"permit\", \"lift\", \"first\", \"second\", \"levels.\", \"people\", \"as\", \"innovation\", \"completion.\", \"pride\", \"station.\", \"usefulness\", \"elevators\", \"distance\", \"due\", \"permanent\", \"fixture\", \"travel\", \"radiotelegraph\", \"combined\", \"widely\", \"structural\", \"103,000\", \"today,\", \"regarded\", \"masterpiece\", \"art.\", \"km\", \"approximately\", \"tons.\", \"10,100\", \"weighs\", \"excellence.\", \"creativity\", \"innovation.\", \"since\", \"been\", \"french\", \"a\", \"as\", \"symbol\", \"its\", \"of\", \"has\", \"it\", \"the\", \"and\", \"tower\", \"became\", \"tower's\", \"to\", \"year.\", \"is\", \"each\"], \"Freq\": [29.0, 38.0, 38.0, 20.0, 11.0, 12.0, 8.0, 17.0, 5.0, 5.0, 38.0, 3.0, 26.0, 4.0, 3.0, 2.0, 42.0, 2.0, 32.0, 7.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 26.746252808463986, 11.461175703444935, 10.601485372900628, 98.27213390493341, 8.022193336855489, 8.015831660327907, 40.541962931447245, 7.162312687989457, 7.160825453489822, 6.302800752209368, 6.302581083592247, 5.443118676435642, 5.442920561941703, 5.442626600389355, 5.44238537764905, 5.434861612863042, 5.432968518809852, 4.583434307670087, 4.582978460894682, 4.581870028645031, 4.575756453833238, 24.496050042375558, 29.58406316357409, 10.587967727476249, 35.389015950466906, 3.724005378194171, 3.723990932345655, 3.723846703159674, 3.7236096078046597, 3.723593327562681, 33.589505314154, 24.990231972357517, 31.95531755424588, 14.731812113203581, 16.45200907938296, 9.759194264347126, 6.193012303485101, 8.694090388277425, 6.4156384214665, 1.992133999932999, 1.401555789529008, 1.4014972054258878, 1.4014738226168333, 1.4013674562517322, 1.4012787540739058, 1.3979322166084656, 1.3955453909581315, 1.3954727009212882, 1.395445759858682, 1.3954307643615709, 1.3953693844878028, 0.8013600010160331, 0.8013080250980804, 0.8013044033042866, 0.8012853412316878, 0.8012696467919149, 0.8012386391538209, 0.801204518043869, 0.8012023576756412, 0.8008194006371319, 0.8006378026255077, 0.8006229342088805, 0.8005710218311699, 0.8002162766601068, 0.8003488851451522, 0.8002299378121359, 0.7998509202686304, 0.7995178423200878, 0.7993848525935904, 2.642130596834619, 1.4222128492823602, 5.092542492299839, 2.589878151748804, 3.2569314912118044, 1.29555821199241, 1.9044517700712362, 1.9285181450491207, 1.7806273422402676, 1.7661870597637948, 1.8686618392036558, 0.9950611579357044, 0.8182404194058747, 0.8170600323303168, 0.8149892558436703, 0.814421523781437, 0.8129608606984351, 0.809518441007823, 0.8111360484885548, 1.840393221295464, 1.2883586035361971, 1.2882108804430796, 0.736913663154803, 0.7369128531584048, 0.7369111825408335, 0.7369071325588427, 0.7369028800777523, 0.7368996907169345, 0.7368976151011641, 0.7369010069610815, 0.73688835076736, 0.7368926032484504, 0.7368851107817673, 0.7368820732952741, 0.7368789851840061, 0.7368669871123581, 0.7368670377371329, 0.7368628358808174, 0.7368585327749521, 0.7368515465560178, 0.7352449187002343, 0.7349404106792948, 0.7348864446692662, 0.7348569304255077, 0.7339644662690417, 0.7002724129630077, 0.6969029798209173, 1.8524514351760208, 2.305802976750824, 1.3189615837034596, 4.194719842275461, 1.3123291306960894, 1.7707626909226026, 2.011945800949998, 2.7492626398119935, 1.775427662678802, 1.860925414994646, 1.989370998833714, 1.6055012520431573, 1.5637290290423367, 0.7622262530969242, 0.8082312641507416, 0.8013376379297342, 0.751686630588624, 0.7659703601979462, 0.7463205057002531], \"Total\": [29.0, 38.0, 38.0, 20.0, 11.0, 12.0, 8.0, 17.0, 5.0, 5.0, 38.0, 3.0, 26.0, 4.0, 3.0, 2.0, 42.0, 2.0, 32.0, 7.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 27.260129714611498, 11.847885137523187, 10.988105820784204, 102.13016674297079, 8.408713643690422, 8.40648795059436, 42.718806878085644, 7.548868643300819, 7.54840250591001, 6.6891515626807525, 6.689077346762376, 5.8293726325789645, 5.829301863433985, 5.829197865084473, 5.829126431023492, 5.826895681525786, 5.8261830402410615, 4.969595933441017, 4.969447755594448, 4.9691163619655825, 4.9668628324572754, 26.590184199764487, 32.27855166882116, 11.585017526243147, 38.760704262273855, 4.109915974582277, 4.10990855722668, 4.109856317498526, 4.109763919430605, 4.109771048231007, 38.119395296206264, 29.39404985237237, 38.90878546154037, 17.502300933818088, 20.5102782085245, 12.53856383410656, 7.202798647937538, 11.457096654495386, 8.387961069404373, 2.479731731899831, 1.8745525713126692, 1.874553911583644, 1.8745736570240044, 1.874615849017764, 1.8746445302500259, 1.8761322392425852, 1.8771264775760936, 1.8771488965361907, 1.8771702116860518, 1.877159726402514, 1.8771894348529268, 1.2727704182369144, 1.272799646546634, 1.272797762397568, 1.2728116162415313, 1.2728108590803515, 1.2728296647735096, 1.2728430797046324, 1.2728400874207468, 1.2727858716506315, 1.272824072192293, 1.2728450044527553, 1.272842747133772, 1.2725688445909578, 1.2728991669058525, 1.2728986527435406, 1.2725428684433144, 1.2725204385619155, 1.2735904163337874, 5.639027786109352, 2.725155821585085, 38.90878546154037, 12.53856383410656, 20.5102782085245, 5.900992603872593, 26.590184199764487, 32.27855166882116, 38.119395296206264, 38.760704262273855, 102.13016674297079, 17.502300933818088, 2.1248033883057102, 2.1250973167096063, 2.125835809607084, 2.9859141560392364, 2.9865792739340673, 2.127931227123973, 4.081384633643376, 2.331053469746207, 1.777812725198602, 1.7778977052566904, 1.2241987992790924, 1.2241979599068475, 1.2242061651728329, 1.2242090356163409, 1.224203966984248, 1.2242003655483948, 1.2242013595704726, 1.2242146070792996, 1.2242040398142278, 1.2242118528331323, 1.2242073221088465, 1.224205994298767, 1.2242147373192762, 1.2242108525895743, 1.2242117144123283, 1.2242119047701008, 1.224212986720304, 1.2242315928357534, 1.2244007577034608, 1.224422361903539, 1.2244145803437672, 1.2244335277042802, 1.225790367958129, 1.2438648124795657, 1.2457907956506111, 3.7858264017163514, 5.900992603872593, 3.4800847819278298, 29.39404985237237, 4.081384633643376, 8.387961069404373, 11.457096654495386, 38.119395296206264, 17.502300933818088, 38.90878546154037, 102.13016674297079, 38.760704262273855, 42.718806878085644, 2.069561740011655, 7.202798647937538, 20.5102782085245, 3.794983262232259, 32.27855166882116, 5.5176683993720985], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.6061, -4.4535, -4.5315, -2.3047, -4.8103, -4.8111, -3.1901, -4.9236, -4.9238, -5.0515, -5.0515, -5.1981, -5.1982, -5.1982, -5.1983, -5.1996, -5.2, -5.37, -5.3701, -5.3704, -5.3717, -3.694, -3.5052, -4.5328, -3.3261, -5.5777, -5.5777, -5.5777, -5.5778, -5.5778, -3.3783, -3.674, -3.4281, -4.2025, -4.092, -4.6143, -5.069, -4.7298, -5.0337, -4.2268, -4.5784, -4.5784, -4.5784, -4.5785, -4.5786, -4.581, -4.5827, -4.5827, -4.5828, -4.5828, -4.5828, -5.1374, -5.1375, -5.1375, -5.1375, -5.1375, -5.1376, -5.1376, -5.1376, -5.1381, -5.1383, -5.1383, -5.1384, -5.1388, -5.1387, -5.1388, -5.1393, -5.1397, -5.1399, -3.9444, -4.5638, -3.2882, -3.9644, -3.7352, -4.657, -4.2718, -4.2592, -4.339, -4.3471, -4.2907, -4.9209, -5.1166, -5.118, -5.1206, -5.1212, -5.123, -5.1273, -5.1253, -4.0788, -4.4354, -4.4355, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9963, -4.9967, -4.9968, -4.9968, -4.998, -5.045, -5.0498, -4.0722, -3.8533, -4.4119, -3.2549, -4.4169, -4.1173, -3.9896, -3.6774, -4.1147, -4.0677, -4.0009, -4.2153, -4.2417, -4.9602, -4.9016, -4.9102, -4.9742, -4.9553, -4.9813], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2033, 0.1891, 0.1865, 0.1838, 0.1752, 0.1747, 0.17, 0.1697, 0.1696, 0.1628, 0.1628, 0.1537, 0.1537, 0.1537, 0.1536, 0.1526, 0.1524, 0.1414, 0.1413, 0.1412, 0.1403, 0.1403, 0.1351, 0.1323, 0.1313, 0.1237, 0.1237, 0.1237, 0.1236, 0.1236, 0.0958, 0.06, 0.0254, 0.05, 0.0018, -0.0283, 0.0712, -0.0537, -0.0458, 1.9799, 1.908, 1.908, 1.9079, 1.9078, 1.9078, 1.9046, 1.9023, 1.9023, 1.9022, 1.9022, 1.9022, 1.7362, 1.7361, 1.7361, 1.736, 1.736, 1.736, 1.7359, 1.7359, 1.7355, 1.7352, 1.7352, 1.7351, 1.7349, 1.7348, 1.7346, 1.7345, 1.7341, 1.733, 1.4407, 1.5485, 0.1654, 0.6216, 0.3587, 0.6826, -0.4375, -0.6189, -0.865, -0.8898, -1.8022, -0.6685, 1.2445, 1.2429, 1.2401, 0.8996, 0.8976, 1.2323, 0.583, 2.1897, 2.104, 2.1039, 1.9185, 1.9185, 1.9185, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9183, 1.916, 1.9156, 1.9155, 1.9155, 1.9132, 1.8515, 1.8452, 1.7113, 1.4863, 1.4558, 0.4791, 1.2914, 0.8706, 0.6865, -0.2034, 0.1377, -0.6141, -1.5124, -0.7579, -0.8815, 1.4272, 0.2387, -0.8164, 0.8069, -1.315, 0.4255]}, \"token.table\": {\"Topic\": [3, 3, 2, 1, 2, 2, 2, 1, 3, 2, 1, 1, 2, 3, 3, 3, 1, 2, 3, 2, 1, 1, 1, 3, 1, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 2, 3, 1, 2, 3, 1, 1, 3, 3, 1, 3, 1, 3, 2, 2, 3, 2, 1, 2, 2, 3, 1, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 1, 2, 2, 1, 3, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 3, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 3, 2, 3, 3, 1, 1, 3, 1, 2, 3, 2, 1, 2, 3, 3, 3, 1, 1, 2, 3, 1, 3, 3, 2, 3, 2, 2, 1, 2, 1, 1, 2, 3, 3, 1, 1, 2, 1, 3], \"Freq\": [0.8167168343578852, 0.8168501566888091, 0.5334602509005403, 0.973255907112931, 0.7858281436312533, 0.7856696084990318, 0.5327197179519996, 0.8505122678079104, 0.1360819628492657, 0.7856446460814858, 0.8577356460752144, 0.90297636913852, 0.05159864966505828, 0.05159864966505828, 0.816726054527803, 0.8168513247674525, 0.49002977654047697, 0.24501488827023848, 0.24501488827023848, 0.7856081816997238, 0.8581948018909344, 1.00611801582386, 0.48319408919608675, 0.48319408919608675, 0.9732919161337589, 0.3389260306287246, 0.1694630153143623, 0.3389260306287246, 0.5327112871154357, 0.7856707715421348, 0.5320066000366085, 0.5320066000366085, 0.7856781115138676, 0.8969846944443091, 0.8168520813499314, 0.7858419949074509, 0.5624889426349947, 0.36695149395837146, 0.36695149395837146, 0.8039458870185123, 0.9273485342785259, 1.006671649421478, 0.816853961134619, 0.8168573431953821, 0.9061798640471022, 0.18123597280942044, 0.9904575026848802, 0.8168558764436711, 0.532729153813485, 0.8065388583254981, 0.8158001776973975, 0.7856622199543456, 0.4704032152816303, 0.4704032152816303, 0.785181787782797, 0.8168590830113629, 0.9495022320926207, 0.0863183847356928, 0.5746986425118296, 0.2873493212559148, 1.001082459471158, 0.9732902278636041, 0.8570301731595118, 0.057135344877300785, 0.11427068975460157, 1.0062151166897209, 0.5327227913807211, 0.9025887079117177, 0.07521572565930981, 0.8579811771618219, 0.8027029927426559, 0.5334344639016056, 0.9294097302692153, 0.06196064868461435, 0.030980324342307176, 0.8224363629039667, 0.1285056817037448, 0.05140227268149792, 0.7855393274061887, 0.08728214748957652, 0.17456429497915305, 0.8168389100984123, 0.6696624521087976, 0.3348312260543988, 0.4705666851757874, 0.4705666851757874, 0.5327167423468818, 1.006148016018713, 0.8168520466951297, 0.8969747424283855, 0.8577252330818929, 0.8919344007375627, 0.05246672945515075, 0.07870009418272612, 0.8577614603432246, 0.9513940346872074, 0.7856084990306582, 0.951645924792455, 0.4699399995889717, 0.4699399995889717, 0.816859746281842, 0.47063177962897856, 0.47063177962897856, 0.533454631805484, 0.5624620567557465, 0.7856510793829923, 0.7856545314055973, 0.8168572945991498, 0.7856427991359731, 0.8168521737108527, 0.7856876508689089, 0.669811620657228, 0.334905810328614, 0.264143120653033, 0.264143120653033, 0.528286241306066, 0.7856416111166169, 0.8168607913917912, 0.8168559904600093, 0.9272912711512197, 0.7153109021792419, 0.23843696739308062, 0.9595597767566061, 0.019582852586869513, 0.019582852586869513, 0.7856430044102715, 0.780096683103502, 0.14626812808190662, 0.048756042693968875, 0.8168527487603129, 0.8167116438851685, 0.858089842907697, 0.9597646328702271, 0.023408893484639686, 0.04681778696927937, 0.8330095416061715, 0.1388349236010286, 0.8168502435906845, 0.5330114685325757, 0.8168613514730025, 0.5334606323149117, 0.785662687323813, 0.8577509488824914, 0.78581210301548, 0.9732700345190194, 0.7975395055053013, 0.2392618516515904, 0.8167041961640205, 0.8168551044747698, 0.9732576635960862, 0.9284357395702741, 0.5334426253378614, 0.790517320552123, 0.2635057735173743], \"Term\": [\"10,100\", \"103,000\", \"18,038\", \"1889\", \"1889.\", \"1909.\", \"20,000\", \"a\", \"a\", \"allowed\", \"an\", \"and\", \"and\", \"and\", \"approximately\", \"art.\", \"as\", \"as\", \"as\", \"ascend\", \"attraction\", \"attracts\", \"became\", \"became\", \"become\", \"been\", \"been\", \"been\", \"bulbs\", \"but\", \"by\", \"by\", \"can\", \"city\", \"combined\", \"completed\", \"completion.\", \"constructed\", \"constructed\", \"creativity\", \"cultural\", \"design\", \"distance\", \"due\", \"each\", \"each\", \"eiffel\", \"elevators\", \"evening.\", \"every\", \"excellence.\", \"expired\", \"first\", \"first\", \"five\", \"fixture\", \"for\", \"for\", \"french\", \"french\", \"from\", \"gustave\", \"has\", \"has\", \"has\", \"icon.\", \"illuminated\", \"in\", \"in\", \"innovation\", \"innovation.\", \"iron.\", \"is\", \"is\", \"is\", \"it\", \"it\", \"it\", \"its\", \"its\", \"its\", \"km\", \"levels.\", \"levels.\", \"lift\", \"lift\", \"light\", \"many\", \"masterpiece\", \"most\", \"observation\", \"of\", \"of\", \"of\", \"offers\", \"one\", \"or\", \"paris.\", \"people\", \"people\", \"permanent\", \"permit\", \"permit\", \"pieces\", \"pride\", \"proved\", \"purchased\", \"radiotelegraph\", \"radiotelegraphy,\", \"regarded\", \"remain\", \"second\", \"second\", \"since\", \"since\", \"since\", \"stairs\", \"station.\", \"structural\", \"structures\", \"symbol\", \"symbol\", \"the\", \"the\", \"the\", \"tickets\", \"to\", \"to\", \"to\", \"today,\", \"tons.\", \"tourist\", \"tower\", \"tower\", \"tower\", \"tower's\", \"tower's\", \"travel\", \"two\", \"usefulness\", \"using\", \"valuable\", \"views\", \"visited\", \"visitors\", \"was\", \"was\", \"weighs\", \"widely\", \"world's\", \"world.\", \"wrought\", \"year.\", \"year.\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# # Preprocessing the corpus\n",
        "# tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# # Creating the dictionary\n",
        "# dictionary = corpora.Dictionary(tokenized_corpus)\n",
        "\n",
        "# # Creating the document-term matrix\n",
        "# doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "\n",
        "# # Training the LDA model\n",
        "# lda_model = models.LdaModel(\n",
        "#     corpus=doc_term_matrix,\n",
        "#     id2word=dictionary,\n",
        "#     num_topics=3,\n",
        "#     passes=10\n",
        "# )\n",
        "\n",
        "# Prepare the data for visualization\n",
        "lda_vis_data = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ApGfuqklwDs_",
        "outputId": "6353535a-dc25-40a6-e899-40aa82a6eff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bertopic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-970680bb9872>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Example corpus of documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "import pyLDAvis\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# Initialize and train the Bertopic model\n",
        "bertopic_model = BERTopic()\n",
        "topics, _ = bertopic_model.fit_transform(docs)\n",
        "\n",
        "# Convert the topics to a Pandas DataFrame\n",
        "df_topics = pd.DataFrame(topics, columns=[\"Topic\"])\n",
        "\n",
        "# Generate the topic visualization using pyLDAvis\n",
        "lda_vis_data = pyLDAvis.prepare(\n",
        "    df_topics,\n",
        "    bertopic_model.transform(docs),\n",
        "    bertopic_model.get_topics(),\n",
        "    df_topics[\"Topic\"].value_counts(),\n",
        "    R=10,  # Number of relevant terms to display per topic\n",
        "    lambda_step=0.01\n",
        ")\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JkR5yJXswDql"
      },
      "outputs": [],
      "source": [
        "%pip show pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FvsR34hmwDoT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G0yBckH8wDl5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gensim"
      ],
      "metadata": {
        "id": "rODrj--rQWgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "topic modelling: extract smenatic topics\n",
        "gensim algos (Word2Vec, Latent Semantic Indexing, LDA, etc.) discover semantic structure of documeents. Gensim supports streaming so all data in RAM not required\n",
        "\n"
      ],
      "metadata": {
        "id": "AIibmp8dQUwE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-wbJfySTl6fU",
        "eN9R03nzkIG2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
