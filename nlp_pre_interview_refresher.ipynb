{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/nlp/blob/main/nlp_pre_interview_refresher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - Zero to Hero"
      ],
      "metadata": {
        "id": "rpD9s7kANeGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 0.3, 0.6"
      ],
      "metadata": {
        "id": "VNPtLvjFedUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBuxDf8vfF5"
      },
      "outputs": [],
      "source": [
        "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
        "# https://pberba.github.io/stats/2020/07/08/intro-hdbscan/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36f-Q0WtvfCh"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pyLDAvis scikit-learn hdbscan --quiet --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scipy==1.10.1 svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmehdhOMO05L",
        "outputId": "8db1083a-7a73-48d5-b048-747f5f853d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting svgling\n",
            "  Downloading svgling-0.5.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.26.4)\n",
            "Collecting svgwrite (from svgling)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svgling-0.5.0-py3-none-any.whl (31 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, scipy, svgling\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "Successfully installed scipy-1.10.1 svgling-0.5.0 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNfQ119kve_7"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "assert scipy.__version__ == '1.10.1'\n",
        "from __future__ import print_function\n",
        "import pyLDAvis\n",
        "#import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "#import torch\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "#from bertopic import BERTopic\n",
        "#from umap import UMAP\n",
        "\n",
        "import hdbscan\n",
        "import logging\n",
        "logging.basicConfig()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "bnuHnjAJPvhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define docs"
      ],
      "metadata": {
        "id": "-wbJfySTl6fU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSvfrKkv-ub",
        "outputId": "e67403e4-0241-44f0-de8a-1f7cecb7eb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "# docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data'][0:1000]\n",
        "\n",
        "docs = [\n",
        "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\",\n",
        "    \"The tower is 324 meters tall, about the same height as an 81-story building.\",\n",
        "    \"It held this title for 41 years until the Chrysler Building in New York City was finished in 1930.\",\n",
        "    \"The tower has three levels for visitors, with restaurants on the first and second levels.\",\n",
        "    \"Tickets can be purchased to ascend by stairs or lift to the first and second levels.\",\n",
        "]\n",
        "\n",
        "\n",
        "# # Save the documents to disk\n",
        "# with open('docs.pkl', 'wb') as file:\n",
        "#     pickle.dump(docs, file)\n",
        "\n",
        "docs[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('docs.pkl', 'rb') as file:\n",
        "#     docs = pickle.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFK-Bcl7KGZM",
        "outputId": "a3ffbc6e-9c50-4537-f591-64a180b7cea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "jWlLeyIPl9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpasIcBvmBoD",
        "outputId": "95c18a98-32db-46cb-82eb-c39a151ce13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "Qu6VCWHKmBlt",
        "outputId": "d170e121-e176-4d3e-c1cc-1e39ca74cef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This is the second second document.',\n",
        "    'And the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG8pMGFsmBjX",
        "outputId": "0fd3e298-dcac-4956-bbe5-0dc0c0398447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 19 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "analyze(\"This is a text document to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb268R6omBhA",
        "outputId": "085c11e2-2c72-4455-c924-8a8d0c1eda26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'text', 'document', 'to', 'analyze']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()\n",
        "\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbEf9xTImBe8",
        "outputId": "6004955a-81f9-4c92-a172-0f9c8c83fbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform(['Something completely new.']).toarray() # ignored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGAYAHRmj5x",
        "outputId": "203eac18-6277-45c7-d1ae-67f1e4d53375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to preserve ordering to some extent can use bigrams\n",
        "bigram_counts = CountVectorizer(ngram_range=(1,2))\n",
        "bigram_counts.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ1JQhOAmj3b",
        "outputId": "c0c686d4-5365-48dc-b844-6d178f44301f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4vd6ptdmj1F",
        "outputId": "c4fed3af-0b09-47d5-bcde-56e52cc71655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'and the', 'document', 'first', 'first document', 'is',\n",
              "       'is the', 'is this', 'one', 'second', 'second document',\n",
              "       'second second', 'the', 'the first', 'the second', 'the third',\n",
              "       'third', 'third one', 'this', 'this is', 'this the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "J1IboAHSmjyN",
        "outputId": "3f3c5061-08e8-420d-9a3a-491a681264ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(smooth_idf=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer(smooth_idf=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfTransformer(smooth_idf=False)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = [[3, 0, 1],\n",
        "          [2, 0, 0],\n",
        "          [3, 0, 0],\n",
        "          [4, 0, 0],\n",
        "          [3, 2, 0],\n",
        "          [3, 0, 2]]\n",
        "\n",
        "tfidf = transformer.fit_transform(counts)\n",
        "tfidf\n",
        "\n",
        "tfidf.toarray() # each row a unit vector normalzied by eculidean norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBH68Wbmjvn",
        "outputId": "e48baf53-2009-4444-ac86-ba7e74cfbdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x3 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81940995, 0.        , 0.57320793],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.47330339, 0.88089948, 0.        ],\n",
              "       [0.58149261, 0.        , 0.81355169]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TfidfTransformer()\n",
        "transformer.fit_transform(counts).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILrkmPBjmjsw",
        "outputId": "2518993d-fa38-4ba6-e4f4-6207f5e86be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85151335, 0.        , 0.52433293],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.55422893, 0.83236428, 0.        ],\n",
              "       [0.63035731, 0.        , 0.77630514]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.idf_ # weifhts of each feature # maybe related to IDFs (some partial calculation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDQQ_KrxmjqK",
        "outputId": "9c4f7fac-9db4-4c0f-8778-d91df4ea64c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 2.25276297, 1.84729786])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPuAvFHcmjlM",
        "outputId": "df910920-cc05-418c-bb08-50779846f1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674],\n",
              "       [0.        , 0.27230147, 0.        , 0.27230147, 0.        ,\n",
              "        0.85322574, 0.22262429, 0.        , 0.27230147],\n",
              "       [0.55280532, 0.        , 0.        , 0.        , 0.55280532,\n",
              "        0.        , 0.28847675, 0.55280532, 0.        ],\n",
              "       [0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short texts noisty tfidf. binary occurrence as used in naive bayes can be set in CountVectorizer (binary=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuU5a8Y8mjit",
        "outputId": "b5516afa-383b-42c1-db68-a664d4ab4ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bow: cannot capture phrases/multi-words although can use ngrams, order, grammaer, potential misspellings, word derivations\n",
        "# chars can help in misspellings\n",
        "\n",
        "# analyzer is essetnial tokenizer\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
        "counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "counts.toarray().astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5oGexxypy_R",
        "outputId": "93746a5a-3b9b-4bb0-ac0f-fb043d28fa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 1, 1, 1, 0],\n",
              "       [1, 1, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# across words. more noisy than white-space aware char_wb\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqW2mfzmBaQ",
        "outputId": "ded090d5-5919-4c79-e261-1375d3e01706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', ' ju', 'fox', 'jum', 'mpy', 'ox ', 'py ', 'ump'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x7 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 7 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', 'fox', 'jum', 'mpy', 'py ', 'ump', 'y f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGjXSy2frFCb",
        "outputId": "423edaa9-7a02-44cc-f38a-add501bc7f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jum': 2, 'ump': 5, 'mpy': 3, 'py ': 4, 'y f': 6, ' fo': 0, 'fox': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2y4dkjqoq26",
        "outputId": "e366bb05-48b2-42fa-b9d5-a5080f8f3ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', 'fox', 'jum', 'mpy', 'py ', 'ump', 'y f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.get_stop_words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbZsBKZsHDf",
        "outputId": "f6960a04-bac8-48b1-ba65-c04286469a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2go07Ffnro0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "x2jimh2bUA_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\"hello world\", \"hello\", \"world hello\"]\n",
        "\n",
        "# Step 1: Build the vocabulary\n",
        "# Create a set of unique words\n",
        "vocab = set()\n",
        "for sentence in corpus:\n",
        "    vocab.update(sentence.split())\n",
        "\n",
        "# Create a word-to-index dictionary\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Step 2: Create one-hot representations\n",
        "def one_hot_encode(word, word_to_index):\n",
        "    \"\"\"\n",
        "    Create a one-hot vector for the given word.\n",
        "    \"\"\"\n",
        "    vector = torch.zeros(len(word_to_index), dtype=torch.float32)\n",
        "    vector[word_to_index[word]] = 1.0\n",
        "    return vector\n",
        "\n",
        "# Encode the entire corpus\n",
        "one_hot_encoded_corpus = []\n",
        "for sentence in corpus:\n",
        "    encoded_sentence = []\n",
        "    for word in sentence.split():\n",
        "        encoded_sentence.append(one_hot_encode(word, word_to_index))\n",
        "    one_hot_encoded_corpus.append(encoded_sentence)\n",
        "\n",
        "one_hot_encoded_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNhmwg59Touf",
        "outputId": "e85272ca-eb99-400b-c2c2-44e9178819f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor([0., 1.]), tensor([1., 0.])],\n",
              " [tensor([0., 1.])],\n",
              " [tensor([1., 0.]), tensor([0., 1.])]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-13KdGhmWxnR",
        "outputId": "a43b5f44-6868-4190-8b62-72d684606efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  This technique is useful for high-cardinality categorical features (e.g., URLs, words, or user IDs) where one-hot encoding is too memory-intensive.\n",
        "\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "import pandas as pd\n",
        "\n",
        "# Sample email subjects\n",
        "emails = [\n",
        "    {\"free\": 1, \"money\": 1, \"win\": 1},     # spam\n",
        "    {\"meeting\": 1, \"schedule\": 1},         # ham\n",
        "    {\"lottery\": 1, \"winner\": 1},           # spam\n",
        "    {\"project\": 1, \"update\": 1}            # ham\n",
        "]\n",
        "\n",
        "# Use FeatureHasher (e.g., 8 hashed features)\n",
        "hasher = FeatureHasher(n_features=8, input_type='dict')\n",
        "X_hashed = hasher.transform(emails)\n",
        "\n",
        "# Convert to array or DataFrame for viewing\n",
        "df_hashed = pd.DataFrame(X_hashed.toarray())\n",
        "print(df_hashed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9SvdhUArqnp",
        "outputId": "55403d27-0839-44e6-ca2d-0bf5583f2104"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0    1    2    3    4    5    6    7\n",
            "0  0.0  0.0 -1.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  1.0  0.0 -1.0  0.0  0.0\n",
            "2  0.0  0.0 -1.0  0.0  0.0  0.0 -1.0  0.0\n",
            "3 -1.0 -1.0  0.0  0.0  0.0  0.0  0.0  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can implement custom hasher or use python's built-in\n",
        "hash('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPP4y6Cnr6sR",
        "outputId": "8f41d255-0c81-427d-a6ce-31ef5fc43f35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7847095065649335254"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "aSEQn2lKe_Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec (Google) - 2 techniques: Continuous Bag of Words (CBoW) and Skip-Gram;\n",
        "Bow: use context of window size m to predict target. softmax layer and negative log-likelihood given context to train. faster.\n",
        "\n",
        "Skip-gram: use center to predict context in window size m to predict context words. one output layer + softmax predicts (center, context) pair. Avg. neg. log likelihood to train. better for infrequent words.\n",
        "\n",
        "Goal is to learn weights that are the vectors. Both Can use negative sampling to optimize (better for frequent). Hierarchical softmax (better for infrequent words).\n",
        "Linear substructures like vector(man) - vector(woman) + vector(king) = vector(queen). Can average embeddings of multiple words to find closest vectors during inference.\n",
        "\n",
        "\n",
        "Global Vectors or GloVe (Stanford); trained on co-occurence/frequency matrix of word pairs. Can use KNN to get similar words. Linear substructurs: vector difference of man-woman is similar to king-queen. This is encoded as its trained so its dot product equals log of prob ratio. This encodes meaning of the word e.g. ice/steam/gas/water example.\n",
        "\n",
        "fastText (Facebook) —interesting fact: accounts for out of vocabulary words.\n"
      ],
      "metadata": {
        "id": "VMZk8nJVhA7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"I love natural language processing\",\n",
        "    \"word2vec is a cool technique\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec model using CBOW\n",
        "model_cbow = Word2Vec(tokenized_sentences, vector_size=100, window=2, min_count=1, sg=0) # switch skip-gram\n",
        "\n",
        "# Get the word vector for a word\n",
        "vector = model_cbow.wv['fox']\n",
        "print(vector)\n",
        "\n",
        "# Find most similar words\n",
        "similar_words = model_cbow.wv.most_similar('fox')\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJv9GlWJfAwn",
        "outputId": "9f8b4770-42ee-40af-cb44-23d353c756dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n",
            "[('processing', 0.2529142200946808), ('quick', 0.1701662242412567), ('language', 0.15018442273139954), ('jumps', 0.13887980580329895), ('a', 0.10852645337581635), ('over', 0.034764934331178665), ('is', 0.016065234318375587), ('cool', 0.004503022879362106), ('natural', -0.005900727119296789), ('the', -0.027750348672270775)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use pre-trained\n",
        "\n",
        "# import gensim.downloader as api\n",
        "\n",
        "# # Load the pre-trained Word2Vec model (Google's pretrained model)\n",
        "# model = api.load(\"word2vec-google-news-300\")\n",
        "# model.most_similar('fox')"
      ],
      "metadata": {
        "id": "stp69JgJfAuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5990da1b-e99c-467e-afca-fb29aaaf865c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc2Vec"
      ],
      "metadata": {
        "id": "CagFqGHY4E7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- based on word2vec, shallow network. random init doc vvector to predict a sample of words in that document. results in static embeddings, treats all context words equally regardless of order/sposition. BERT is bidirection (processes words right and left), is deep, finetuend on sentence similarity, higher scores in benchmakrs,"
      ],
      "metadata": {
        "id": "lOVOLHMh4uqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"I love machine learning.\",\n",
        "    \"Gensim is a useful library for NLP.\",\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"This is an example document.\"\n",
        "]\n",
        "\n",
        "# Preprocess and tag the documents\n",
        "tagged_documents = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "\n",
        "# Initialize and train the Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, window=2, min_count=1, workers=4, epochs=100)\n",
        "\n",
        "# Build the vocabulary\n",
        "model.build_vocab(tagged_documents)\n",
        "\n",
        "# Train the model\n",
        "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "# Inference: Get the vector for a new document\n",
        "new_doc = \"Machine learning is fascinating.\"\n",
        "new_vec = model.infer_vector(new_doc.split())\n",
        "\n",
        "# Print the vector\n",
        "print(f\"Vector for the new document: {new_vec}\")\n"
      ],
      "metadata": {
        "id": "gYpLIHLsfAqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ac0afb-7f86-4521-a4ff-78aa4694c94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for the new document: [-0.01021536  0.00431636 -0.00353114  0.00395402  0.00446658  0.00122819\n",
            "  0.00196246 -0.00237312 -0.00503703 -0.0094545   0.01013314  0.00038311\n",
            "  0.00098956 -0.01006637  0.00578416 -0.00822289  0.00440096 -0.0083645\n",
            "  0.00731886 -0.00190531 -0.00151291 -0.00170916  0.00713491  0.00718142\n",
            "  0.003907    0.00862515 -0.00584027  0.00674695  0.00358911  0.00922674\n",
            "  0.0001482   0.00885134 -0.0065098  -0.00556093 -0.00839748  0.00877584\n",
            " -0.00432476 -0.00813925  0.00268146  0.00272961  0.00858418  0.00119933\n",
            " -0.00661389  0.00665232 -0.00986029 -0.00806856  0.00627114  0.00496203\n",
            "  0.00542394 -0.00270844]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "jaP_tMYU-gE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DSqtPdQ4-6Xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae761eb0-4eb2-4111-dc76-714bc3847c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# brief chatgpt example:\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the SpaCy English model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Example set of documents\n",
        "documents = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\",\n",
        "    \"This is not a document.\",\n",
        "    \"We have more documents to explore.\"\n",
        "]\n",
        "\n",
        "# Function to convert documents to vectors\n",
        "def document_vectors(documents):\n",
        "    doc_vectors = []\n",
        "    for doc in documents:\n",
        "        doc_vector = nlp(doc).vector\n",
        "        doc_vectors.append(doc_vector)\n",
        "    return np.array(doc_vectors)\n",
        "\n",
        "# Convert documents to vectors\n",
        "doc_vectors = document_vectors(documents)\n",
        "\n",
        "# Test document\n",
        "test_doc = \"More documents should be explored.\"\n",
        "\n",
        "# Convert test document to vector\n",
        "test_doc_vector = nlp(test_doc).vector\n",
        "\n",
        "# Calculate cosine similarity between test document and each document in the set\n",
        "similarities = cosine_similarity([test_doc_vector], doc_vectors)[0]\n",
        "\n",
        "# Retrieve indices of most similar documents\n",
        "most_similar_indices = similarities.argsort()[:-4:-1]\n",
        "\n",
        "# Print most similar documents\n",
        "print(\"Most similar documents to the test document:\")\n",
        "for idx in most_similar_indices:\n",
        "    print(f\"Document {idx}: {documents[idx]}\")\n"
      ],
      "metadata": {
        "id": "EBaOuy9v-hui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58879be-fdaf-48e2-a88a-ae6a833bc046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar documents to the test document:\n",
            "Document 5: We have more documents to explore.\n",
            "Document 1: This document is the second document.\n",
            "Document 0: This is the first document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.tag_, token.has_vector, token.vector_norm)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "sWiq7Fdu-hsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1cd959-84b7-466c-ad7a-9d3b94684a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN nsubj NNP True 49.544395\n",
            "is be AUX aux VBZ True 110.41255\n",
            "looking look VERB ROOT VBG True 48.28714\n",
            "at at ADP prep IN True 118.82375\n",
            "buying buy VERB pcomp VBG True 45.90773\n",
            "U.K. U.K. PROPN compound NNP True 34.055897\n",
            "startup startup NOUN dobj NN True 39.72299\n",
            "for for ADP prep IN True 69.12914\n",
            "$ $ SYM quantmod $ True 190.25487\n",
            "1 1 NUM compound CD True 118.7086\n",
            "billion billion NUM pobj CD True 67.87469\n",
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))\n"
      ],
      "metadata": {
        "id": "P-5oXL2u-hqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882343f5-b644-4ae3-cc76-b5c1e1a67840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
            "salty fries <-> hamburgers 0.6938489675521851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "64Rgzdm2eTrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
        "    return similarity\n",
        "\n",
        "# Example vectors\n",
        "vec1 = np.array([1, 2, 3])\n",
        "vec2 = np.array([4, 5, 6])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity(vec1, vec2)\n",
        "print(f\"Cosine Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "id": "ycey4uqU0tUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff92de74-7d65-4219-812e-fc3ba8d3097b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.9746318461970762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter('A quick brown fox jumps')\n",
        "\n",
        "Counter(['Abc bcg', 'def'])"
      ],
      "metadata": {
        "id": "YMnKymUmeHZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977e6647-227c-4563-c1b7-8d06a193de4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'A': 1,\n",
              "         ' ': 4,\n",
              "         'q': 1,\n",
              "         'u': 2,\n",
              "         'i': 1,\n",
              "         'c': 1,\n",
              "         'k': 1,\n",
              "         'b': 1,\n",
              "         'r': 1,\n",
              "         'o': 2,\n",
              "         'w': 1,\n",
              "         'n': 1,\n",
              "         'f': 1,\n",
              "         'x': 1,\n",
              "         'j': 1,\n",
              "         'm': 1,\n",
              "         'p': 1,\n",
              "         's': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Abc bcg': 1, 'def': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK Stuff"
      ],
      "metadata": {
        "id": "eWiz7u1_3Y2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "puncs = set(string.punctuation)\n",
        "print(puncs)"
      ],
      "metadata": {
        "id": "Mi1rmXY64U20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0801cf-61d8-4e48-e5f2-f14e9ec348a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'`', '*', '~', '$', ')', '_', '|', '?', '#', '!', '.', '/', '&', '{', '<', '\\\\', '%', '@', '=', '\"', ']', '}', ':', '-', '>', '+', ',', '(', ';', '[', '^', \"'\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "0Nmk7ETcrFAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2490c021-cf62-4c8e-a7a9-f994092a2f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) # can also just specify in sklearn\n",
        "len(stop_words)"
      ],
      "metadata": {
        "id": "jp7vWTKl5un_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c186d7f-9200-4431-f8ee-d75b77a92969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "8lZl8Vvf3a_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ebbc6d-3fde-4a73-a82a-44b1207bd74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "  tokens = [lemmatizer.lemmatize(word.lower()) for word in doc.split(' ') if word not in stop_words and word not in puncs]\n",
        "  return tokens\n",
        "\n",
        "tokenized_docs = [preprocess(doc) for doc in docs]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "id": "XVabJuxw3a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffc620e-eb2e-4c2d-be4b-260ac1ff8b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'eiffel', 'tower', 'wrought-iron', 'lattice', 'tower', 'champ', 'de', 'mar', 'paris,', 'france.'], ['the', 'tower', '324', 'meter', 'tall,', 'height', '81-story', 'building.'], ['it', 'held', 'title', '41', 'year', 'chrysler', 'building', 'new', 'york', 'city', 'finished', '1930.'], ['the', 'tower', 'three', 'level', 'visitors,', 'restaurant', 'first', 'second', 'levels.'], ['ticket', 'purchased', 'ascend', 'stair', 'lift', 'first', 'second', 'levels.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since already tokenized, if wanna create BoW, can use:\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, smooth_idf=True, stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(tokenized_docs)\n",
        "\n",
        "tfidf_matrix.toarray().shape\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "id": "grNrPvfJ3a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a2b725-2192-45bd-d819-00c78ecaad3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.33721386 0.         0.         0.33721386 0.\n",
            "  0.33721386 0.         0.         0.33721386 0.         0.\n",
            "  0.         0.33721386 0.         0.         0.33721386 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.4516721  0.         0.33721386 0.         0.        ]\n",
            " [0.         0.39379499 0.         0.39379499 0.         0.\n",
            "  0.39379499 0.         0.         0.         0.         0.\n",
            "  0.         0.39379499 0.         0.         0.         0.\n",
            "  0.         0.         0.39379499 0.         0.         0.\n",
            "  0.         0.         0.         0.39379499 0.         0.\n",
            "  0.26372909 0.         0.         0.         0.        ]\n",
            " [0.30151134 0.         0.30151134 0.         0.         0.30151134\n",
            "  0.         0.         0.30151134 0.30151134 0.         0.30151134\n",
            "  0.         0.         0.30151134 0.         0.         0.\n",
            "  0.         0.         0.         0.30151134 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.30151134\n",
            "  0.         0.         0.         0.30151134 0.30151134]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.45881476 0.37016886\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.45881476 0.37016886 0.         0.         0.         0.\n",
            "  0.30727359 0.45881476 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.39835162 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.32138758\n",
            "  0.39835162 0.         0.         0.         0.         0.39835162\n",
            "  0.         0.32138758 0.39835162 0.         0.39835162 0.\n",
            "  0.         0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "# for better handling of ambiguous situations like U.S.A.\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "text = \"Natural language processing is an exciting area. Huge budget have been allocated for this.\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "id": "WkSQfyIV69Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fb930d-afc1-498b-d6ee-b07719f213f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing is an exciting area.', 'Huge budget have been allocated for this.']\n",
            "['Natural', 'language', 'processing', 'is', 'an', 'exciting', 'area', '.', 'Huge', 'budget', 'have', 'been', 'allocated', 'for', 'this', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos tagging\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "\n",
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(text))\n",
        "tagged"
      ],
      "metadata": {
        "id": "CNS3KQ8HNivU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568dc29c-9e44-4989-ba1d-924f6f032177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('processing', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('exciting', 'JJ'),\n",
              " ('area', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Huge', 'NNP'),\n",
              " ('budget', 'NN'),\n",
              " ('have', 'VBP'),\n",
              " ('been', 'VBN'),\n",
              " ('allocated', 'VBN'),\n",
              " ('for', 'IN'),\n",
              " ('this', 'DT'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Trees"
      ],
      "metadata": {
        "id": "WZQ8uNptcaKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty grammar example\n",
        "\n",
        "# Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {}   # To extract Noun Phrases\n",
        "                    P: {}    # To extract Prepositions\n",
        "                    V: {}    # To extract Verbs\n",
        "                    PP: {}   # To extract Prepositional Phrases\n",
        "                    VP: {}   # To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)\n",
        "\n",
        "# another set of grammar rules:\n",
        "\n",
        "#Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "                    P: {<IN>}            #To extract Prepositions\n",
        "                    V: {<V.*>}           #To extract Verbs\n",
        "                    PP: {<p> <NP>}       #To extract Prepositional Phrases\n",
        "                    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)"
      ],
      "metadata": {
        "id": "ihFxRklMNXmy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "fe70a281-4c4c-4a71-db2d-4cbd2f5ade65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Extracting\n",
            " (S\n",
            "  Natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  is/VBZ\n",
            "  an/DT\n",
            "  exciting/JJ\n",
            "  area/NN\n",
            "  ./.\n",
            "  Huge/NNP\n",
            "  budget/NN\n",
            "  have/VBP\n",
            "  been/VBN\n",
            "  allocated/VBN\n",
            "  for/IN\n",
            "  this/DT\n",
            "  ./.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('exciting', 'JJ'), ('area', 'NN'), ('.', '.'), ('Huge', 'NNP'), ('budget', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('allocated', 'VBN'), ('for', 'IN'), ('this', 'DT'), ('.', '.')])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,880.0,120.0\" width=\"880px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"8.18182%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Natural</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.09091%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.09091%\" x=\"8.18182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">language</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.9091%\" x=\"17.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">processing</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.54545%\" x=\"28.1818%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">is</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBZ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.4545%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.63636%\" x=\"32.7273%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">an</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.09091%\" x=\"36.3636%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">exciting</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.9091%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"45.4545%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">area</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.1818%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72727%\" x=\"50.9091%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"53.6364%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Huge</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.3636%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.27273%\" x=\"59.0909%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">budget</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"66.3636%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">have</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.0909%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"71.8182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">been</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10%\" x=\"77.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">allocated</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.54545%\" x=\"87.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">for</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"89.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"91.8182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">this</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"94.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72727%\" x=\"97.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6364%\" y1=\"20px\" y2=\"48px\" /></svg>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Extracting\n",
            " (S\n",
            "  (NP Natural/JJ language/NN)\n",
            "  (NP processing/NN)\n",
            "  (VP (V is/VBZ) (NP an/DT exciting/JJ area/NN))\n",
            "  ./.\n",
            "  Huge/NNP\n",
            "  (NP budget/NN)\n",
            "  (VP (V have/VBP))\n",
            "  (VP (V been/VBN))\n",
            "  (VP (V allocated/VBN))\n",
            "  (P for/IN)\n",
            "  this/DT\n",
            "  ./.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [('Natural', 'JJ'), ('language', 'NN')]), Tree('NP', [('processing', 'NN')]), Tree('VP', [Tree('V', [('is', 'VBZ')]), Tree('NP', [('an', 'DT'), ('exciting', 'JJ'), ('area', 'NN')])]), ('.', '.'), ('Huge', 'NNP'), Tree('NP', [('budget', 'NN')]), Tree('VP', [Tree('V', [('have', 'VBP')])]), Tree('VP', [Tree('V', [('been', 'VBN')])]), Tree('VP', [Tree('V', [('allocated', 'VBN')])]), Tree('P', [('for', 'IN')]), ('this', 'DT'), ('.', '.')])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,880.0,216.0\" width=\"880px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"17.2727%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"47.3684%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Natural</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.6842%\" y1=\"20px\" y2=\"48px\" /><svg width=\"52.6316%\" x=\"47.3684%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">language</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.6842%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.63636%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.9091%\" x=\"17.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">processing</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"22.7273%\" x=\"28.1818%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"20%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">is</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBZ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10%\" y1=\"20px\" y2=\"48px\" /><svg width=\"80%\" x=\"20%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"20%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">an</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10%\" y1=\"20px\" y2=\"48px\" /><svg width=\"50%\" x=\"20%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">exciting</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45%\" y1=\"20px\" y2=\"48px\" /><svg width=\"30%\" x=\"70%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">area</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"39.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72727%\" x=\"50.9091%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"53.6364%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Huge</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.3636%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.27273%\" x=\"59.0909%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">budget</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"66.3636%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">have</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.0909%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"71.8182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">been</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10%\" x=\"77.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">allocated</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.54545%\" x=\"87.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">P</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">for</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"89.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.45455%\" x=\"91.8182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">this</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"94.5455%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72727%\" x=\"97.2727%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6364%\" y1=\"20px\" y2=\"48px\" /></svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# CFGs can not be used with english as its not as expressive.\n",
        "\n",
        "# Define a context-free grammar\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N | 'I'\n",
        "    VP -> V NP | V\n",
        "    Det -> 'the' | 'a'\n",
        "    N -> 'dog' | 'cat'\n",
        "    V -> 'chased' | 'ate'\n",
        "\"\"\")\n",
        "\n",
        "# Create a recursive descent parser\n",
        "parser = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "# Define a sentence to parse\n",
        "sentence = \"I chased the cat\"\n",
        "\n",
        "# Parse the sentence and print the parse trees\n",
        "for tree in parser.parse(sentence.split()):\n",
        "    print(tree)\n",
        "    display(tree)\n"
      ],
      "metadata": {
        "id": "buLE6Z7ZMxXf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "59f88526-0d5b-4724-f505-8a0b5dc4fbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP I) (VP (V chased) (NP (Det the) (N cat))))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', ['I']), Tree('VP', [Tree('V', ['chased']), Tree('NP', [Tree('Det', ['the']), Tree('N', ['cat'])])])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,176.0,216.0\" width=\"176px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"18.1818%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.09091%\" y1=\"20px\" y2=\"48px\" /><svg width=\"81.8182%\" x=\"18.1818%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"44.4444%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">chased</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.2222%\" y1=\"20px\" y2=\"48px\" /><svg width=\"55.5556%\" x=\"44.4444%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Det</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"20px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">N</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cat</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.2222%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.0909%\" y1=\"20px\" y2=\"48px\" /></svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_syntactic_analysis.htm\n",
        "2. https://www.analyticsvidhya.com/blog/2022/03/syntactical-parsing-in-nlp/\n",
        "3. https://intellipaat.com/blog/what-is-parsing-in-nlp/"
      ],
      "metadata": {
        "id": "ExlT62TJcSeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "eM2KJwbrdAoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4LjM_q4_Pl0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [5, 2, 5]])\n",
        "t"
      ],
      "metadata": {
        "id": "ouPBT0I8XP0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0153085c-5372-464e-e27c-44a47e8d1d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.t()"
      ],
      "metadata": {
        "id": "I_TqwXs4XPxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577d6941-7a1c-4c6e-f2f1-76f447def993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 5],\n",
              "        [2, 2],\n",
              "        [3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape\n",
        "\n",
        "un_t = torch.unsqueeze(t, dim=0) # equivalent of np.expand(x, axis=0)\n",
        "un_t"
      ],
      "metadata": {
        "id": "YBHdVErTD3Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bbc6868-6342-434f-b111-f57d5b9c3c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [5, 2, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.squeeze()"
      ],
      "metadata": {
        "id": "ZqTRarNhD3Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91669a4b-0557-40c7-ceda-af4ee241ff8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [5, 2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(un_t).item()"
      ],
      "metadata": {
        "id": "anUwsI4cD2_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f1ba97-a137-48d6-d408-929d61f034cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.view(-1, 1, 1) # only one dimension can be inferred"
      ],
      "metadata": {
        "id": "qhb5t_GVEK-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedcbae1-8ac4-4ebe-baf4-c402efe6e44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[3]],\n",
              "\n",
              "        [[5]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 3, 5)"
      ],
      "metadata": {
        "id": "o35wGkAPEK7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9bc8b9-6b85-45de-8dfd-eae65982e246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(t) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(t, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "ZiFToM1xNysP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1b1e43-e5a3-42d6-fe41-b595a321378f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1, 1],\n",
            "        [1, 1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5523, 0.3378, 0.4315],\n",
            "        [0.2393, 0.6719, 0.6633]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 1], [1, 1]])\n",
        "\n",
        "# This computes the matrix multiplication between two tensors. y1, y2 will have the same value\n",
        "y1 = t @ t.T\n",
        "y2 = t.matmul(t.T)\n",
        "y1\n",
        "y2\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = t * t\n",
        "z2 = t.mul(t)\n",
        "z1\n",
        "z2"
      ],
      "metadata": {
        "id": "zN7GHbOPOKi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ce782a-b9fd-4076-8da0-e7ac1cb14e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2],\n",
              "        [2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2],\n",
              "        [2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeLLqjZ4P0pi",
        "outputId": "eda4eae4-f1d7-4425-b5d7-ab58163a2512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(1,-1).squeeze()\n",
        "n = t.view(1,-1).squeeze().numpy()\n",
        "np.dot(n, n)"
      ],
      "metadata": {
        "id": "8z0AXWvsOKgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0111b3d1-77e6-448f-92f9-e5d6e69edfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t\n",
        "torch.cat((t, t, t), dim=1)"
      ],
      "metadata": {
        "id": "YTj6M4PEHe6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3099a9ed-ee05-4e73-9a5e-58e6501dc391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t\n",
        "t[-1, 0:2]"
      ],
      "metadata": {
        "id": "yMBpdFt8He3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf70995-bd14-47d3-babb-2dd10477802c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.tensor([[1, 2, 0, -1]]) == 1) # masking"
      ],
      "metadata": {
        "id": "tdjIAB-ofPj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8da52ae-c018-4c66-846c-7ff326ce788e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sz=3\n",
        "mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
        "mask"
      ],
      "metadata": {
        "id": "NkfIpAONfAuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a78e00f-d84d-41dd-c5c3-ff6961349e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False],\n",
              "        [ True,  True, False],\n",
              "        [ True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, 10)"
      ],
      "metadata": {
        "id": "03yrPTOGfAsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd6ff99-b759-4c2b-832f-c1983b1d2de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., -inf, -inf],\n",
              "        [10., 10., -inf],\n",
              "        [10., 10., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1, 2, 3]\n",
        "np.where(x == 1)[0]"
      ],
      "metadata": {
        "id": "PvFeixU0fAnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161f3f0a-b5bc-4b0c-fa3f-fa42d1d8a75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-64-1f551e9a54fd>:2: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
            "  np.where(x == 1)[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(torch.tensor(5))\n",
        "\n",
        "torch.nn.ReLU()(torch.tensor(-4))"
      ],
      "metadata": {
        "id": "uITKOw5AHe03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3226ad0-f59e-4add-e11d-37bb89049f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9933)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 5)\n",
        "X"
      ],
      "metadata": {
        "id": "vuPq3klXKGee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f3299e-3732-4498-e501-061becdc9817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0444, 0.9645, 0.4451, 0.3913, 0.8871],\n",
              "        [0.4436, 0.3104, 0.9310, 0.3896, 0.4953]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = torch.nn.Softmax(dim=-1)(torch.tensor([[9], [10], [5]], dtype=float))\n",
        "probs\n",
        "\n",
        "probs.argmax(0)"
      ],
      "metadata": {
        "id": "3Y6R13IQJnCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b61a6ef-af81-452d-a6b2-b58d0696f48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an ordered container\n",
        "import torch.nn as nn\n",
        "\n",
        "img_size = 28\n",
        "\n",
        "# no need to define forward()\n",
        "seq_modules = nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(img_size * img_size, 10)\n",
        ")\n",
        "\n",
        "# 5 is probably channels I think\n",
        "input_image = torch.rand(5,img_size,img_size)\n",
        "logits = seq_modules(input_image)\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "yiPbaCPsLB4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac1e4e5-7da5-49b2-dc78-85151ef5f753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = nn.Linear(4, 1)\n",
        "for x in linear_layer.named_parameters():\n",
        "  print('---------')\n",
        "  print(x[0], x[1].numel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnoCbcKkGwAW",
        "outputId": "00227e09-32a2-4989-a330-79bf48366e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------\n",
            "weight 4\n",
            "---------\n",
            "bias 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    nn.Linear(3, 2),\n",
        "    nn.Linear(2, 1)\n",
        ")\n",
        "for x in seq_modules.named_parameters():\n",
        "  print('---------')\n",
        "  print(x[0], x[1].numel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx-hRXgCHqe8",
        "outputId": "dc831b73-c424-483f-b448-46298dce6bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------\n",
            "0.weight 6\n",
            "---------\n",
            "0.bias 2\n",
            "---------\n",
            "1.weight 2\n",
            "---------\n",
            "1.bias 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can use within collate_fn in dataloader\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Example list of sequences with varying lengths\n",
        "sequences = [torch.tensor([1, 2, 3], dtype=torch.float),\n",
        "             torch.tensor([4, 5], dtype=torch.float),\n",
        "             torch.tensor([6], dtype=torch.float)]\n",
        "\n",
        "# Pad the sequences\n",
        "padded_sequence = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
        "padded_sequence"
      ],
      "metadata": {
        "id": "1X4qRbMiXaOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522f5051-660f-426f-8579-e5a003017847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 0.],\n",
              "        [6., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serves different purpose.\n",
        "# ignores pad values and leads to better memory utilization\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "lengths = torch.tensor([len(t) for t in padded_sequence])\n",
        "\n",
        "# Pack the padded sequence\n",
        "packed_sequence = pack_padded_sequence(padded_sequence, lengths, batch_first=True)\n",
        "packed_sequence"
      ],
      "metadata": {
        "id": "C31KE7KNXPvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b899b06f-ad46-4bc4-dc0b-5ba1e37b2379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([1., 4., 6., 2., 5., 0., 3., 0., 0.]), batch_sizes=tensor([3, 3, 3]), sorted_indices=None, unsorted_indices=None)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "# can't use tensordataset directly for variable input lengths\n",
        "# need to implement class\n",
        "\n",
        "# can't init tensor on variable. otherwise, just init as tensor and use tensordataset\n",
        "X = [[1, 2, 3], [5, 7], [5]]\n",
        "\n",
        "# needed\n",
        "X = list(map(torch.tensor, X))\n",
        "\n",
        "y = torch.tensor([0, 1, 1])\n",
        "\n",
        "# can't use for variable\n",
        "#dataset = TensorDataset(X, y)\n",
        "\n",
        "class SequenceDataset(Dataset): # just a protocol class so doesn't inherit anythinmg no super()\n",
        "  def __init__(self, sequences, labels):\n",
        "    self.sequences = sequences\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sequences)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.sequences[idx], self.labels[idx]\n",
        "\n",
        "dataset = SequenceDataset(X, y)\n",
        "\n",
        "def collate_fn(batch):\n",
        "  sequences, labels = zip(*batch)\n",
        "  lengths = [len(seq) for seq in sequences]\n",
        "  padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "  return padded, lengths, labels\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through DataLoader\n",
        "for batch in dataloader:\n",
        "    padded_sequences, lengths, labels = batch\n",
        "    print(\"Padded Sequences:\\n\", padded_sequences)\n",
        "    print(\"Lengths:\\n\", lengths)\n",
        "    print(\"Labels:\\n\", labels)"
      ],
      "metadata": {
        "id": "zBg1bgVGftR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa1b00f-62d8-4e0f-bf87-738a1e856a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences:\n",
            " tensor([[1, 2, 3],\n",
            "        [5, 7, 0]])\n",
            "Lengths:\n",
            " [3, 2]\n",
            "Labels:\n",
            " (tensor(0), tensor(1))\n",
            "Padded Sequences:\n",
            " tensor([[5]])\n",
            "Lengths:\n",
            " [1]\n",
            "Labels:\n",
            " (tensor(1),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Data"
      ],
      "metadata": {
        "id": "xWAvUqpsM2Q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can also use pandas(chunk_size) or maybe using numpy.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MCpkyRlLM9zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "file = 'example6.h5'\n",
        "\n",
        "# Create an HDF5 file\n",
        "with h5py.File(file, 'w') as f:\n",
        "    f.create_dataset('data', data=np.arange(100), compression=\"gzip\")\n",
        "    f.create_dataset('labels', data=np.random.randint(0, 3, size=(100,)), compression=\"gzip\")\n",
        "\n",
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, h5_file):\n",
        "        self.file = h5_file\n",
        "        self.dataset = h5py.File(h5_file, 'r')\n",
        "        self.data = self.dataset['data']\n",
        "        self.labels = self.dataset['labels']\n",
        "        #self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# Usage example\n",
        "h5_file = file\n",
        "dataset = HDF5Dataset(h5_file)"
      ],
      "metadata": {
        "id": "5SuvxbxOfAcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95076981-7982-45fb-d714-4af794ce94b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<HDF5 dataset \"data\": shape (100,), type \"<i8\">"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<HDF5 dataset \"labels\": shape (100,), type \"<i8\">"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Iterate over DataLoader in training loop\n",
        "for inputs, labels in data_loader:\n",
        "    # Perform training step\n",
        "    print(inputs)\n",
        "    print('===========')"
      ],
      "metadata": {
        "id": "jeNRRLuBfAaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e53fdaa-216d-4a46-fa4d-a2f0b0aa2099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([72., 94., 85., 61.,  8., 16., 74., 62., 20., 56., 96., 81., 14., 71.,\n",
            "        67., 64., 68., 57., 39., 41.,  3., 59.,  1., 31., 77., 19., 66., 50.,\n",
            "        21., 28., 58.,  0.])\n",
            "===========\n",
            "tensor([ 5., 17., 51., 99., 95., 91., 48., 33., 79., 70., 78., 90., 27., 30.,\n",
            "        44., 55., 73., 83., 23., 18., 86., 24., 63., 25., 32., 45., 87., 34.,\n",
            "        11., 75.,  2., 80.])\n",
            "===========\n",
            "tensor([13.,  7., 97., 38., 92., 89., 54., 10., 15., 82., 26., 60., 40., 12.,\n",
            "         6., 76., 69., 37., 36.,  4., 98., 88., 42., 52., 93., 49., 43., 53.,\n",
            "        22., 47., 84., 65.])\n",
            "===========\n",
            "tensor([46., 29., 35.,  9.])\n",
            "===========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW in PyTroch"
      ],
      "metadata": {
        "id": "03T4Ex22F-YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "corpus = [\n",
        "    \"he is the king\",\n",
        "    \"the king is royal\",\n",
        "    \"she is the queen\",\n",
        "    \"the queen is royal\",\n",
        "    \"royal is nice\",\n",
        "    \"she is nice\"\n",
        "]\n",
        "\n",
        "# Tokenize corpus\n",
        "words = set()\n",
        "for sentence in corpus:\n",
        "    for word in sentence.split():\n",
        "      words.add(word)\n",
        "\n",
        "#print([word for sent in corpus for word in sent.split(' ')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR4i6lXPGlbK",
        "outputId": "f7335951-7ae0-4e57-c807-96f93c06d681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_counts = Counter(words)\n",
        "vocab = {word: idx for idx, word in enumerate(words)}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDDB6ndvHRHr",
        "outputId": "8e110296-4daa-4663-aa7e-bf1b57393118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CBOW Dataset\n",
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, corpus, window_size=2):\n",
        "        self.corpus = corpus\n",
        "        self.window_size = window_size\n",
        "        self.data = self.generate_data()\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = []\n",
        "        for sentence in self.corpus:\n",
        "            words = sentence.split()\n",
        "            for i, target_word in enumerate(words):\n",
        "                context = [words[j] for j in range(max(0, i - self.window_size), min(len(words), i + self.window_size + 1)) if j != i]\n",
        "                data.append((context, target_word))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, target_word = self.data[idx]\n",
        "        context_idx = [vocab[word] for word in context]\n",
        "        target_idx = vocab[target_word]\n",
        "        return torch.tensor(context_idx), torch.tensor(target_idx)\n",
        "\n",
        "# CBOW Model\n",
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).mean(dim=1)  # Average embedding of context words\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcxmHJQzIWNk",
        "outputId": "dbfd3ca1-4610-491d-b904-56f370d4e64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 5\n",
        "window_size = 2\n",
        "batch_size = 4\n",
        "lr = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = CBOWDataset(corpus, window_size=window_size)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = CBOW(vocab_size, embedding_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WudfZa7FJVbr",
        "outputId": "74af8122-2fa0-4639-c723-5d4571ec81e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq1yg7-VLVzC",
        "outputId": "1905ce5b-3fab-4075-fc5c-5b8859091c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embedding): Embedding(8, 5)\n",
              "  (linear): Linear(in_features=5, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnfpRETDLS7O",
        "outputId": "8447acee-9cb6-4f42-c84f-f57dad1818b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.1160, -0.4899,  0.2274, -1.5028, -0.6685],\n",
              "        [ 0.8415, -1.0474,  0.8950, -0.0022, -0.3813],\n",
              "        [ 0.4222,  0.9556, -0.1896,  0.1746,  0.3745],\n",
              "        [ 0.8796,  0.8799, -0.7767,  0.9415, -0.6332],\n",
              "        [ 2.1625, -1.2053,  0.0026, -0.4953,  0.8557],\n",
              "        [ 2.0018,  0.6339,  1.0876, -2.1512,  0.8558],\n",
              "        [ 0.3649, -1.0374, -1.6773,  0.4491,  0.3523],\n",
              "        [ 0.7458, -1.0501,  0.2714,  1.5829, -0.6661]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get word embeddings\n",
        "word_embeddings = model.embedding.weight.detach().numpy()\n",
        "\n",
        "# Print word embeddings\n",
        "for idx, word in idx_to_word.items():\n",
        "    print(f\"{word}: {word_embeddings[idx]}\")\n"
      ],
      "metadata": {
        "id": "M9TmKFVVi1j2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0f81bd-7d60-4667-8e1c-319c333ab3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "king: [-1.1159676  -0.48994532  0.22737613 -1.5027516  -0.6684592 ]\n",
            "queen: [ 0.8414821  -1.0473682   0.8950346  -0.00221192 -0.38132346]\n",
            "the: [ 0.42217904  0.9556126  -0.18964411  0.17457695  0.374534  ]\n",
            "nice: [ 0.87963414  0.87990624 -0.77670836  0.94145584 -0.63320166]\n",
            "royal: [ 2.1624844  -1.2053202   0.00262507 -0.49533412  0.85569453]\n",
            "is: [ 2.001756    0.63385695  1.0876482  -2.1512113   0.85579574]\n",
            "she: [ 0.36486816 -1.0373968  -1.6773473   0.44908097  0.35231712]\n",
            "he: [ 0.74577373 -1.050102    0.2714224   1.5828917  -0.6661278 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression with RNN"
      ],
      "metadata": {
        "id": "8XV2iXkJbNo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example data: a sequence of numbers\n",
        "data = torch.arange(1, 11, dtype=torch.float32).view(-1, 1)\n",
        "sequence_length = 3  # Length of each sequence\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts8SDTJebZEO",
        "outputId": "26b8cc31-c166-41d7-cb6e-aef4145f3e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.],\n",
              "        [ 2.],\n",
              "        [ 3.],\n",
              "        [ 4.],\n",
              "        [ 5.],\n",
              "        [ 6.],\n",
              "        [ 7.],\n",
              "        [ 8.],\n",
              "        [ 9.],\n",
              "        [10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inout_sequences(input_data, seq_length):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-seq_length):\n",
        "        seq = input_data[i:i+seq_length]\n",
        "        label = input_data[i+seq_length:i+seq_length+1]\n",
        "        inout_seq.append((seq, label))\n",
        "    return inout_seq\n",
        "\n",
        "seq_data = create_inout_sequences(data, sequence_length)\n",
        "for seq, labels in seq_data:\n",
        "  print(seq, labels)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpUmbMTLbZCG",
        "outputId": "9ec375bd-22d5-4c27-9c95-408d37d5a979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]]) tensor([[4.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=10, output_size=1):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)  # Initial hidden state\n",
        "\n",
        "        out, hn = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])  # Fully connected layer on the last time step\n",
        "        # according to chatgpt\n",
        "        # this equals\n",
        "        # out = self.fc(hn.squeeze(0))  # Using hn instead of out[:, -1, :]\n",
        "        # i dont think its true for bidirectional coz output has last layer only (all t).\n",
        "        # h as last time step (both layers)\n",
        "\n",
        "        # a single number\n",
        "        return out\n",
        "\n",
        "model = SimpleRNN()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train the Model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    for seq, labels in seq_data:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(seq.unsqueeze(0))  # Add batch dimension\n",
        "        loss = criterion(y_pred, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBLRk1Owbu0I",
        "outputId": "427dd293-e89f-44de-f817-39a5e306fd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 75.97752380371094\n",
            "Epoch 10, Loss: 12.765766143798828\n",
            "Epoch 20, Loss: 7.616011619567871\n",
            "Epoch 30, Loss: 2.254009962081909\n",
            "Epoch 40, Loss: 0.9366371035575867\n",
            "Epoch 50, Loss: 0.42715272307395935\n",
            "Epoch 60, Loss: 0.1998358815908432\n",
            "Epoch 70, Loss: 0.10094868391752243\n",
            "Epoch 80, Loss: 0.07928889244794846\n",
            "Epoch 90, Loss: 0.050036802887916565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Generation with RNN"
      ],
      "metadata": {
        "id": "Hgy9MNlrNerP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# Define constants\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "BATCH_SIZE = 2\n",
        "NUM_EPOCHS = 10\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "\n",
        "# Define dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Function to build vocabulary and tokenizer\n",
        "def build_vocab_and_tokenizer(data):\n",
        "    words = [word for sentence in data for word in sentence.split()]\n",
        "    word_counts = Counter(words)\n",
        "    vocab = [word for word, count in word_counts.items()]\n",
        "    vocab.append(START_TOKEN)\n",
        "    vocab.append(END_TOKEN)\n",
        "    vocab.append(PAD_TOKEN)\n",
        "    tokenizer = {word: idx for idx, word in enumerate(vocab)}\n",
        "    return vocab, tokenizer\n",
        "\n",
        "# Function to convert text to tensor indices\n",
        "def text_to_tensor(text, tokenizer):\n",
        "    tensor = [tokenizer.get(word, tokenizer[PAD_TOKEN]) for word in text.split()]\n",
        "    return tensor\n",
        "\n",
        "# Custom collate function to handle variable length sequences\n",
        "def collate_fn(batch):\n",
        "    texts = [item for item in batch]\n",
        "    tensor_texts = [torch.LongTensor(text_to_tensor(text, tokenizer)) for text in texts]\n",
        "    padded_texts = pad_sequence(tensor_texts, batch_first=True, padding_value=tokenizer[PAD_TOKEN])\n",
        "    return padded_texts\n",
        "\n",
        "# Define the RNN model\n",
        "class RNNLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(RNNLanguageModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('Batch size: ', x.size())\n",
        "        embedded = self.embedding(x)\n",
        "        print('Embeddings size: ', embedded.size())\n",
        "\n",
        "        output, _ = self.rnn(embedded)\n",
        "        print('Output: ', output.size())\n",
        "        output = self.fc(output)\n",
        "        print('Final size: ', output.size())\n",
        "\n",
        "        # i think outputting all because we are modelling language at each step\n",
        "        return output\n",
        "\n",
        "# Prepare data\n",
        "data = docs.copy() # from above\n",
        "\n",
        "# Split data into train and test\n",
        "random.shuffle(data)\n",
        "train_size = int(0.8 * len(data))\n",
        "train_data = data[:train_size]\n",
        "test_data = data[train_size:]\n",
        "\n",
        "# Build vocabulary and tokenizer\n",
        "vocab, tokenizer = build_vocab_and_tokenizer(train_data)\n",
        "\n",
        "# Define datasets and dataloaders\n",
        "train_dataset = TextDataset(train_data)\n",
        "test_dataset = TextDataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = RNNLanguageModel(len(vocab), EMBEDDING_DIM, HIDDEN_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch[:, :-1])  # Ignore the last token\n",
        "        target = batch[:, 1:]  # Predict next token\n",
        "\n",
        "        # all tokens of entire batch contribute to loss\n",
        "        loss = criterion(output.reshape(-1, len(vocab)), target.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        output = model(batch[:, :-1])  # Ignore the last token\n",
        "        target = batch[:, 1:]  # Predict next token\n",
        "        loss = criterion(output.reshape(-1, len(vocab)), target.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "print(f\"Test Loss: {total_loss/len(test_loader)}\")\n",
        "\n",
        "# Inference function\n",
        "def generate_text(model, tokenizer, max_length=20):\n",
        "    model.eval()\n",
        "    current_token = tokenizer[START_TOKEN]\n",
        "    generated_text = [current_token]\n",
        "    while len(generated_text) < max_length:\n",
        "        input_tensor = torch.LongTensor([[current_token]])\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
        "        next_token = torch.multinomial(probabilities, num_samples=1).item()\n",
        "        if next_token == tokenizer[END_TOKEN]:\n",
        "            break\n",
        "        generated_text.append(next_token)\n",
        "        current_token = next_token\n",
        "    return ' '.join([vocab[token] for token in generated_text])\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(model, tokenizer, max_length=20)\n",
        "print(\"Generated Text:\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJLAsToNlp8",
        "outputId": "0de0ea7d-4728-41f9-98d2-3ece7b653079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 1, Train Loss: 4.144920825958252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 2, Train Loss: 3.895688772201538\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Epoch 3, Train Loss: 3.716145634651184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 4, Train Loss: 3.5171313285827637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 5, Train Loss: 3.315058469772339\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Epoch 6, Train Loss: 3.1272069215774536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 7, Train Loss: 2.9433690309524536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 8, Train Loss: 2.758808970451355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Epoch 9, Train Loss: 2.5313172340393066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([2, 18])\n",
            "Embeddings size:  torch.Size([2, 18, 100])\n",
            "Output:  torch.Size([2, 18, 128])\n",
            "Final size:  torch.Size([2, 18, 59])\n",
            "Batch size:  torch.Size([2, 15])\n",
            "Embeddings size:  torch.Size([2, 15, 100])\n",
            "Output:  torch.Size([2, 15, 128])\n",
            "Final size:  torch.Size([2, 15, 59])\n",
            "Epoch 10, Train Loss: 2.4061310291290283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (embedding): Embedding(59, 100)\n",
              "  (rnn): RNN(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  torch.Size([1, 14])\n",
            "Embeddings size:  torch.Size([1, 14, 100])\n",
            "Output:  torch.Size([1, 14, 128])\n",
            "Final size:  torch.Size([1, 14, 59])\n",
            "Test Loss: 2.629478693008423\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Batch size:  torch.Size([1, 1])\n",
            "Embeddings size:  torch.Size([1, 1, 100])\n",
            "Output:  torch.Size([1, 1, 128])\n",
            "Final size:  torch.Size([1, 1, 59])\n",
            "Generated Text: <START> the tall, 41 <PAD> 41 <START> 81-story the same finished about New 81-story was lift Tower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU for Text Generation"
      ],
      "metadata": {
        "id": "AwrqQDO9RVEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "START_TOKEN = \"<START>\"\n",
        "END_TOKEN = \"<END>\"\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "\n",
        "\n",
        "# Define the dataset\n",
        "class LanguageDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "# Function to tokenize the text and build vocabulary\n",
        "def build_vocab(texts):\n",
        "    vocab = set()\n",
        "    for text in texts:\n",
        "        vocab.update(text.split())\n",
        "    vocab = list(vocab)\n",
        "    vocab.append(START_TOKEN)\n",
        "    vocab.append(END_TOKEN)\n",
        "    vocab.append(PAD_TOKEN)\n",
        "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
        "    return vocab, word_to_idx, idx_to_word\n",
        "\n",
        "# Function to encode text into tensor sequence\n",
        "def encode_text(text, word_to_idx):\n",
        "    return torch.tensor([word_to_idx[word] for word in text.split()])\n",
        "\n",
        "# Function to decode tensor sequence into text\n",
        "def decode_sequence(sequence, idx_to_word):\n",
        "    return ' '.join([idx_to_word[idx.item()] for idx in sequence])\n",
        "\n",
        "# Define the GRU language model\n",
        "class GRULanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(GRULanguageModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.gru(embedded)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "# Function to handle variable length sequences in DataLoader\n",
        "def collate_fn(batch):\n",
        "    texts = [item for item in batch]\n",
        "    encoded_texts = [encode_text(text, word_to_idx) for text in texts]\n",
        "    padded_texts = pad_sequence(encoded_texts, batch_first=True, padding_value=PAD_IDX)\n",
        "    return padded_texts\n",
        "\n",
        "# Define training and evaluation loop\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs = batch[:, :-1]\n",
        "            targets = batch[:, 1:]\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.permute(0, 2, 1), targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "# Define generator function for inference\n",
        "def generate_text(model, start_token_idx, end_token_idx, max_length):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        current_token = torch.tensor([start_token_idx]).unsqueeze(0)\n",
        "        generated_text = []\n",
        "        while len(generated_text) < max_length:\n",
        "            output_probs = model(current_token)\n",
        "\n",
        "            # use logits of the last elemet in the sequence\n",
        "            _, next_token = torch.max(output_probs[:, -1, :], dim=1)\n",
        "            if next_token.item() == end_token_idx:\n",
        "                break\n",
        "            generated_text.append(next_token.item())\n",
        "            current_token = torch.cat((current_token, next_token.unsqueeze(0)), dim=1)\n",
        "        return generated_text\n",
        "\n",
        "# Example usage\n",
        "texts = docs.copy()#[\"This is an example text.\", \"Another example text.\"]\n",
        "vocab, word_to_idx, idx_to_word = build_vocab(texts)\n",
        "PAD_IDX = len(vocab)\n",
        "vocab_size = len(vocab) + 1\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "start_token_idx = vocab.index('<START>')\n",
        "end_token_idx = vocab.index('<END>')\n",
        "max_length = 5\n",
        "\n",
        "dataset = LanguageDataset(texts)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "model = GRULanguageModel(vocab_size, embedding_dim, hidden_dim)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "generated_text = generate_text(model, start_token_idx, end_token_idx, max_length)\n",
        "print(decode_sequence(torch.tensor(generated_text), idx_to_word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6XCWJRCNllT",
        "outputId": "074ce3d4-1e87-4059-8588-16075490a0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 4.211387634277344\n",
            "Epoch 2/10, Loss: 4.061304330825806\n",
            "Epoch 3/10, Loss: 3.923961639404297\n",
            "Epoch 4/10, Loss: 3.796614170074463\n",
            "Epoch 5/10, Loss: 3.659853935241699\n",
            "Epoch 6/10, Loss: 3.5301506519317627\n",
            "Epoch 7/10, Loss: 3.386394739151001\n",
            "Epoch 8/10, Loss: 3.251697063446045\n",
            "Epoch 9/10, Loss: 3.1070022583007812\n",
            "Epoch 10/10, Loss: 2.955905795097351\n",
            "81-story building. City visitors, with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another GRU for Text Generation (duplicated)"
      ],
      "metadata": {
        "id": "wAG2HbNwR9iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Define your dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # no labels coz self-supervised\n",
        "        return self.data[idx]\n",
        "\n",
        "# Define your model architecture\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        print('Embedding size: ', embedded.size())\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 1 = n_layers\n",
        "        return torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "# Define your data processing functions\n",
        "def build_vocab(data):\n",
        "    word_counter = Counter()\n",
        "    for sentence in data:\n",
        "        word_counter.update(sentence.split())\n",
        "    vocab = ['<pad>', '<start>', '<end>', '<unk>'] + [word for word, _ in word_counter.most_common()]\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "    return vocab, word2idx, idx2word\n",
        "\n",
        "def encode_sentence(sentence, word2idx):\n",
        "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences = [torch.LongTensor(item) for item in batch]\n",
        "    padded_sentences = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    return padded_sentences\n",
        "\n",
        "# Define your training loop\n",
        "def train(model, train_loader, criterion, optimizer, batch_size, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs = batch[:, :-1].to(device)\n",
        "        targets = batch[:, 1:].to(device)\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(inputs, hidden)\n",
        "        loss = criterion(outputs.view(-1, outputs.size(2)), targets.contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# Define your evaluation loop\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = batch[:, :-1].to(device)\n",
        "            targets = batch[:, 1:].to(device)\n",
        "            hidden = model.init_hidden(len(batch))\n",
        "            outputs, _ = model(inputs, hidden)\n",
        "            loss = criterion(outputs.view(-1, outputs.size(2)), targets.contiguous().view(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "# Define your inference function\n",
        "def generate_sentence(model, start_token_idx, end_token_idx, max_length, batch_size, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        current_token_idx = start_token_idx\n",
        "        sentence = [current_token_idx]\n",
        "        hidden = model.init_hidden(1)\n",
        "        for _ in range(max_length):\n",
        "            inputs = torch.LongTensor([[current_token_idx]]).to(device)\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "            predicted_token_idx = outputs.argmax().item()\n",
        "            if predicted_token_idx == end_token_idx:\n",
        "                break\n",
        "            sentence.append(predicted_token_idx)\n",
        "            current_token_idx = predicted_token_idx\n",
        "    return sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-gY8lQFR8yv",
        "outputId": "b112d7a3-36cb-4587-9ea5-e1f602a22be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "#data = ['<start> hello how are you <end>', '<start> i am fine thank you <end>']\n",
        "data = docs.copy()\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "vocab, word2idx, idx2word = build_vocab(train_data)\n",
        "train_data_encoded = [encode_sentence(sentence, word2idx) for sentence in train_data]\n",
        "val_data_encoded = [encode_sentence(sentence, word2idx) for sentence in val_data]\n",
        "\n",
        "train_dataset = MyDataset(train_data_encoded)\n",
        "val_dataset = MyDataset(val_data_encoded)\n",
        "\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_U7UJIhVzcn",
        "outputId": "9695b824-e5f3-4a64-a22f-1777b22309e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MyModel(vocab_size=len(vocab), embed_size=50, hidden_size=100)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hTd2YaTVssj",
        "outputId": "ebefd6ab-1fd7-4fc6-cc66-2dd5392f9ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (embedding): Embedding(56, 50)\n",
              "  (gru): GRU(50, 100, batch_first=True)\n",
              "  (fc): Linear(in_features=100, out_features=56, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, batch_size, device)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "# Example inference\n",
        "start_token_idx = word2idx['<start>']\n",
        "end_token_idx = word2idx['<end>']\n",
        "generated_sentence = generate_sentence(model, start_token_idx, end_token_idx, 10, batch_size, device)\n",
        "generated_sentence = ' '.join([idx2word[idx] for idx in generated_sentence])\n",
        "print(generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F59091A_Vspr",
        "outputId": "cc9e892b-bfbc-4ec3-bae5-f85ff42ad3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding size:  torch.Size([2, 18, 50])\n",
            "Embedding size:  torch.Size([2, 15, 50])\n",
            "Embedding size:  torch.Size([1, 13, 50])\n",
            "Epoch [1/5], Train Loss: 4.0238, Val Loss: 4.1578\n",
            "Embedding size:  torch.Size([2, 18, 50])\n",
            "Embedding size:  torch.Size([2, 15, 50])\n",
            "Embedding size:  torch.Size([1, 13, 50])\n",
            "Epoch [2/5], Train Loss: 4.0238, Val Loss: 4.1578\n",
            "Embedding size:  torch.Size([2, 18, 50])\n",
            "Embedding size:  torch.Size([2, 15, 50])\n",
            "Embedding size:  torch.Size([1, 13, 50])\n",
            "Epoch [3/5], Train Loss: 4.0238, Val Loss: 4.1578\n",
            "Embedding size:  torch.Size([2, 18, 50])\n",
            "Embedding size:  torch.Size([2, 15, 50])\n",
            "Embedding size:  torch.Size([1, 13, 50])\n",
            "Epoch [4/5], Train Loss: 4.0238, Val Loss: 4.1578\n",
            "Embedding size:  torch.Size([2, 18, 50])\n",
            "Embedding size:  torch.Size([2, 15, 50])\n",
            "Embedding size:  torch.Size([1, 13, 50])\n",
            "Epoch [5/5], Train Loss: 4.0238, Val Loss: 4.1578\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "Embedding size:  torch.Size([1, 1, 50])\n",
            "<start> until levels Eiffel Eiffel <unk> purchased purchased purchased Mars Mars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM for Sentiment Analysis"
      ],
      "metadata": {
        "id": "Zs37MjfFKfSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# IMDb reviews data as a dictionary\n",
        "imdb_reviews = {\n",
        "    \"review\": [\n",
        "        \"The Shawshank Redemption is an incredible movie. The acting is superb and the storyline is captivating.\",\n",
        "        \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n",
        "        \"Great movie! The special effects were amazing and the characters were well-developed.\",\n",
        "        \"The dialogue felt forced and unrealistic. I couldn't connect with any of the characters.\",\n",
        "        \"The Godfather is a masterpiece. The performances are outstanding and the direction is flawless.\",\n",
        "        \"The pacing of the film was too slow, and I found myself losing interest halfway through.\",\n",
        "        \"Titanic is a classic love story that will tug at your heartstrings. I highly recommend it.\",\n",
        "        \"The acting was wooden and the plot was predictable. I was not impressed.\",\n",
        "        \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n",
        "        \"I felt the movie lacked depth and the characters were one-dimensional. Overall, it was underwhelming.\"\n",
        "    ],\n",
        "    \"sentiment\": [\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(imdb_reviews)\n",
        "df = pd.concat([df, df]).reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "eXpQALyWdB6_",
        "outputId": "bd0ec253-7e81-4b0c-a3bb-b7a2a0f0b9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review sentiment\n",
              "0   The Shawshank Redemption is an incredible movi...  positive\n",
              "1   I found the plot to be confusing and the actin...  negative\n",
              "2   Great movie! The special effects were amazing ...  positive\n",
              "3   The dialogue felt forced and unrealistic. I co...  negative\n",
              "4   The Godfather is a masterpiece. The performanc...  positive\n",
              "5   The pacing of the film was too slow, and I fou...  negative\n",
              "6   Titanic is a classic love story that will tug ...  positive\n",
              "7   The acting was wooden and the plot was predict...  negative\n",
              "8   Jurassic Park is a thrilling adventure that ke...  positive\n",
              "9   I felt the movie lacked depth and the characte...  negative\n",
              "10  The Shawshank Redemption is an incredible movi...  positive\n",
              "11  I found the plot to be confusing and the actin...  negative\n",
              "12  Great movie! The special effects were amazing ...  positive\n",
              "13  The dialogue felt forced and unrealistic. I co...  negative\n",
              "14  The Godfather is a masterpiece. The performanc...  positive\n",
              "15  The pacing of the film was too slow, and I fou...  negative\n",
              "16  Titanic is a classic love story that will tug ...  positive\n",
              "17  The acting was wooden and the plot was predict...  negative\n",
              "18  Jurassic Park is a thrilling adventure that ke...  positive\n",
              "19  I felt the movie lacked depth and the characte...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc786684-36f3-422e-a614-b599a6afc820\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc786684-36f3-422e-a614-b599a6afc820')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc786684-36f3-422e-a614-b599a6afc820 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc786684-36f3-422e-a614-b599a6afc820');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-04e1ab11-7299-45f9-a63d-d8e114a16628\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04e1ab11-7299-45f9-a63d-d8e114a16628')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-04e1ab11-7299-45f9-a63d-d8e114a16628 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7f404282-37dd-458c-baeb-93e938742d6b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7f404282-37dd-458c-baeb-93e938742d6b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n          \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n          \"The pacing of the film was too slow, and I found myself losing interest halfway through.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['review'], df['sentiment']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# can also use random_split() by torch on top of pytorch's dataset\n",
        "# like: train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A7tNkD7dB4o",
        "outputId": "1562acdc-3236-42d6-faf9-3fb748502e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "WP8H2ZL5dB2m",
        "outputId": "4afb6cfc-eb97-42a5-9019-4206c1dced49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    9\n",
              "negative    7\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import string\n",
        "\n",
        "def preprocess_word(w):\n",
        "    return w.lower()\n",
        "\n",
        "def build_vocab(X_train):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_list = set()\n",
        "\n",
        "    # Building the vocabulary\n",
        "    for sent in X_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_word(word)\n",
        "            if word not in stop_words and word != '' and word not in string.punctuation:\n",
        "                word_list.add(word)\n",
        "\n",
        "    vocab = {w: i for i, w in enumerate(word_list)}\n",
        "    return vocab\n",
        "\n",
        "def tokenize(sentences):\n",
        "    tokenized_list = []\n",
        "    for sent in sentences:\n",
        "        tokenized_words = [vocab[preprocess_word(w)] for w in sent.lower().split() if preprocess_word(w) in vocab]\n",
        "        if len(tokenized_words) == 0:\n",
        "          print(sent)\n",
        "          continue\n",
        "        tokenized_list.append(torch.tensor(tokenized_words))\n",
        "    return tokenized_list\n",
        "\n",
        "def encode_labels(labels):\n",
        "  return torch.tensor([1 if label == 'positive' else 0 for label in labels])\n",
        "\n",
        "\n",
        "def preprocess(X, y):\n",
        "    tokenized_text = tokenize(X.values)\n",
        "    encoded_labels = encode_labels(y.values)\n",
        "    return tokenized_text, encoded_labels\n",
        "\n",
        "vocab = build_vocab(X_train)\n",
        "\n",
        "# Tokenize/encode\n",
        "X_train_tokenized, y_train_tokenized = preprocess(X_train, y_train)\n",
        "X_test_tokenized, y_test_tokenized = preprocess(X_test, y_test)\n",
        "\n",
        "print(X_train_tokenized)\n",
        "print(y_train_tokenized)\n",
        "print(X_test_tokenized)\n",
        "print(y_test_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G1H_gL2tL7A",
        "outputId": "6294c54f-7f41-4a79-d0cc-bfe233694e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([15, 50, 65, 10, 42,  9, 58, 47, 41]), tensor([27, 44, 52, 26, 40, 48]), tensor([ 6, 29, 16, 39, 59, 33, 28, 14]), tensor([61, 60, 53, 62, 43, 35, 49,  3]), tensor([54,  8, 30,  0,  1, 55, 63,  5]), tensor([31,  6, 38,  4, 19, 32]), tensor([ 0, 56, 22, 43, 21, 28, 34, 13]), tensor([15, 50, 65, 10, 42,  9, 58, 47, 41]), tensor([37, 66, 57, 45, 20, 59, 11]), tensor([43, 17, 56, 36, 64]), tensor([ 6, 29, 16, 39, 59, 33, 28, 14]), tensor([54,  8, 30,  0,  1, 55, 63,  5]), tensor([37, 66, 57, 45, 20, 59, 11]), tensor([ 7, 24, 51, 23, 46, 25,  2, 18, 12]), tensor([ 7, 24, 51, 23, 46, 25,  2, 18, 12]), tensor([27, 44, 52, 26, 40, 48])]\n",
            "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1])\n",
            "[tensor([43, 17, 56, 36, 64]), tensor([ 0, 56, 22, 43, 21, 28, 34, 13]), tensor([31,  6, 38,  4, 19, 32]), tensor([61, 60, 53, 62, 43, 35, 49,  3])]\n",
            "tensor([0, 0, 0, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "# create Tensor datasets\n",
        "\n",
        "# using custom class for variable input\n",
        "train_data = SequenceDataset(X_train_tokenized, y_train_tokenized)\n",
        "valid_data = SequenceDataset(X_test_tokenized, y_test_tokenized)\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 2\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences, labels = zip(*batch)\n",
        "    lengths = [len(sent) for sent in sentences]\n",
        "    padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    return padded, torch.tensor(lengths), torch.tensor(labels)\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_lengths, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample output: \\n', sample_y)\n",
        "print('Sample sample_lengths: \\n', sample_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBPixNFHdBvg",
        "outputId": "42ba620e-21ba-4a44-e9df-efdedadd0324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([2, 9])\n",
            "Sample input: \n",
            " tensor([[ 6, 29, 16, 39, 59, 33, 28, 14,  0],\n",
            "        [15, 50, 65, 10, 42,  9, 58, 47, 41]])\n",
            "Sample output: \n",
            " tensor([0, 1])\n",
            "Sample sample_lengths: \n",
            " tensor([8, 9])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwlossk_-Te",
        "outputId": "d243f7dc-c463-414d-b738-f1dbadbc96b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(torch.nn.Module):\n",
        "    def __init__(self, no_layers, vocab_size,hidden_dim,embedding_dim,output_dim,drop_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #lstm: DOES NOT DEPEND ON SEQUENCE LENGTH. SHARED WEIGHTS.\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=no_layers,\n",
        "            batch_first=True #bidirectional=True\n",
        "        )\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layer\n",
        "        self.fc = torch.nn.Linear(self.hidden_dim, output_dim) # *2 because of bidirectional\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, lengths, hidden):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "\n",
        "        # using packed sequences\n",
        "        packed_embed = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # handles feedback loop and processes all the tokens in a sequence\n",
        "        lstm_out, hidden = self.lstm(packed_embed, hidden)\n",
        "\n",
        "        # for BILSTM: concatenate the final forward and backward hidden states\n",
        "        # forward even indices, backward odd`\n",
        "        # hidden_concat = torch.cat((hidden[0][-2, :, :], hidden[0][-1, :, :]), dim=1)\n",
        "\n",
        "        # Unpack the PackedSequence\n",
        "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        \"\"\"\n",
        "        Reshapes the lstm_out tensor to have shape (batch_size * sequence_length, hidden_dim).\n",
        "        The -1 is a placeholder that infers the appropriate size automatically based on the\n",
        "        other dimension (hidden_dim). This essentially flattens the tensor so that each time step\n",
        "        for each batch item is treated as an independent sample.\n",
        "        \"\"\"\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get element of each batch I guess\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "\n",
        "        # twice layers for BILSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden\n",
        "\n",
        "    # optionally:\n",
        "    # def init_weights(self):\n",
        "    #     for param in self.parameters():\n",
        "    #         nn.init.kaiming_uniform_(param, a=math.sqrt(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5G35IyndBtb",
        "outputId": "aaad9734-8104-489a-d293-5be556cb7afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 # extra 1 for padding????\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 12\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim, output_dim, drop_prob=0.5)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vOR2JzBBr5",
        "outputId": "e2cc80c9-df7b-455c-b683-721c4b463e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeS8f0YaLiGg",
        "outputId": "17c2ff82-e3b4-4650-bf42-da2d0e73cfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: embedding.weight | Size: torch.Size([68, 64])\n",
            "\n",
            "Layer: lstm.weight_ih_l0 | Size: torch.Size([48, 64])\n",
            "\n",
            "Layer: lstm.weight_hh_l0 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.weight_ih_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.weight_hh_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: fc.weight | Size: torch.Size([1, 12])\n",
            "\n",
            "Layer: fc.bias | Size: torch.Size([1])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to calculate correct labels\n",
        "def acc(pred,label):\n",
        "    # simple way to convert probs into classes\n",
        "    pred = torch.round(pred.squeeze())\n",
        "\n",
        "    # count correct predictions\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWwZs9nzBBpZ",
        "outputId": "6130b94f-cb05-4ae7-e14a-423abc4acb2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5 # gradient clipping for exploding gradients\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "\n",
        "    # layers like dropout are enabled. gradients ar eclcualed. batch normalziation uses batch statistics.\n",
        "    model.train()\n",
        "\n",
        "    for inputs, lengths, labels in train_loader:\n",
        "        # move to GPU\n",
        "        inputs, lengths, labels = inputs.to(device), lengths.to(device), labels.to(device)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise we'd backprop through the entire training history\n",
        "        # h = tuple([each.data for each in h])\n",
        "\n",
        "        # why not just init wihtin the loop\n",
        "        # initialize hidden states and cell states of LSTM\n",
        "        h = model.init_hidden(batch_size)\n",
        "\n",
        "        # clear grad to prevent gradient accumulation across batches.\n",
        "        model.zero_grad()\n",
        "\n",
        "        # forward() pass. maintain operations gradient functions in DAG .grad_fn\n",
        "        output, _ = model(inputs, lengths, h)  # h not used outside\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels.float())\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # calculate gradients through backpropagation into .grad, applies chain rule\n",
        "        loss.backward()\n",
        "\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculating accuracy (correct labels)\n",
        "        accuracy = acc(output, labels)\n",
        "        train_acc += accuracy # actually correct predictions\n",
        "\n",
        "\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "\n",
        "    # disable some operations\n",
        "    model.eval()\n",
        "\n",
        "    # no gradient calculations needed\n",
        "    with torch.no_grad():\n",
        "      for inputs, lengths, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        #val_h = tuple([each.data for each in val_h])\n",
        "        val_h = model.init_hidden(batch_size)\n",
        "\n",
        "        output, val_h = model(inputs, lengths, val_h)\n",
        "\n",
        "        val_loss = criterion(output, labels.float())\n",
        "\n",
        "        val_losses.append(val_loss.item())\n",
        "        accuracy = acc(output,labels)\n",
        "        val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8370CoXE9tq",
        "outputId": "5bb2c676-ab4f-4c01-b075-cd9eda47ee54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4476)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6162)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4798)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7009)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6145)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4382)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5129)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2409)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.6941387727856636 val_loss : 0.773928314447403\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (inf --> 0.773928).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4518)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1779)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4610)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6086)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1610)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1773)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1664)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2073)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "train_loss : 0.6831552758812904 val_loss : 0.773928314447403\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.773928 --> 0.773928).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1702)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6227)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4421)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1707)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1527)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6879)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4503)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4580)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "train_loss : 0.6816720142960548 val_loss : 0.773928314447403\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.773928 --> 0.773928).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4483)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1257)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1633)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6750)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4350)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1389)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1874)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1560)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "train_loss : 0.6783403530716896 val_loss : 0.773928314447403\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.773928 --> 0.773928).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6061)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1477)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1427)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2125)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4471)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1575)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4799)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2103)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5\n",
            "train_loss : 0.6770043671131134 val_loss : 0.773928314447403\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.773928 --> 0.773928).  Saving model ...\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "  model.eval()\n",
        "\n",
        "  word_seq = np.array([vocab[preprocess_word(word)] for word in text.split() if preprocess_word(word) in vocab])\n",
        "  length = torch.tensor([len(word_seq)])\n",
        "  word_seq = np.expand_dims(word_seq, axis=0)\n",
        "  inputs = torch.from_numpy(word_seq).to(device)\n",
        "  batch_size = 1\n",
        "  h = model.init_hidden(batch_size)\n",
        "  # h = tuple([each.data for each in h]) # maybe unnecessary\n",
        "  with torch.no_grad():\n",
        "    output, h = model(inputs, length, h)\n",
        "  probability = output.item()\n",
        "  return probability\n",
        "\n",
        "index = 0\n",
        "predict_text('this movie sucks.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnFpZq2xE9qu",
        "outputId": "6a15d968-bda7-4107-c254-2ef72d03f6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.579501211643219"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "id": "xnbpvCZ6f9Wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5000f208-6a97-4d3a-c7a2-9f3abbc2ac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN for Sentiment Analysis"
      ],
      "metadata": {
        "id": "0anGERTo_JRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data\n",
        "texts = [\n",
        "    \"I love this movie\",\n",
        "    \"This film was terrible\",\n",
        "    \"Absolutely fantastic\",\n",
        "    \"Worst movie ever\",\n",
        "    \"I enjoyed it\",\n",
        "    \"Not my favorite\",\n",
        "    \"Best movie I have seen\",\n",
        "    \"Could be better\",\n",
        "    \"I would watch it again\",\n",
        "    \"Awful experience\"\n",
        "]\n",
        "\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "# Train-test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenized_train_texts = [text.split() for text in train_texts]\n",
        "\n",
        "# Vocabulary creation\n",
        "train_vocab = Counter(itertools.chain(*tokenized_train_texts))\n",
        "train_vocab = {word: i + 2 for i, (word, _) in enumerate(train_vocab.most_common())}  # Start indices from 2\n",
        "\n",
        "# I don't think this info is needed for tasks other than langauge modelling\n",
        "train_vocab['<PAD>'] = 0\n",
        "train_vocab['<UNK>'] = 1\n",
        "\n",
        "# Convert texts to sequences of indices\n",
        "def text_to_sequence(text, vocab):\n",
        "    return [vocab.get(word, vocab['<UNK>']) for word in text]\n",
        "\n",
        "# Padding\n",
        "def pad_sequence(seq, max_len):\n",
        "    return seq + [train_vocab['<PAD>']] * (max_len - len(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TmbSZ8hJw6H",
        "outputId": "3c5af632-45d0-4c30-992a-11330ed53281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.data = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    print('Batch: ')\n",
        "    print(batch)\n",
        "    print('Unpacked:')\n",
        "    print(*batch)\n",
        "    print('Zipped:')\n",
        "    print(zip(*batch))\n",
        "    texts, labels = zip(*batch)\n",
        "    sequences = [pad_sequence(text, max_len) for text in texts]\n",
        "    return torch.tensor(sequences, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_sequences = [text_to_sequence(text, train_vocab) for text in tokenized_train_texts]\n",
        "max_len = max(len(seq) for seq in train_sequences)\n",
        "train_dataset = SentimentDataset(train_sequences, train_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "for batch in train_dataloader:\n",
        "  tokens, labels = batch\n",
        "  print(tokens, labels)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJTtNT14J07P",
        "outputId": "0a066f56-f2c2-445c-c88a-e49569a03bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: \n",
            "[([12, 13], 1), ([2, 7, 8, 3], 1)]\n",
            "Unpacked:\n",
            "([12, 13], 1) ([2, 7, 8, 3], 1)\n",
            "Zipped:\n",
            "<zip object at 0x790e7949bf40>\n",
            "tensor([[12, 13,  0,  0,  0],\n",
            "        [ 2,  7,  8,  3,  0]]) tensor([1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
        "        super(SimpleCNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # treat embedding dimension as in_channels, kernel size is just a window for context words\n",
        "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=50, kernel_size=3)  # 50 filters, kernel size 3\n",
        "        self.fc = nn.Linear(50 * (max_len - 3 + 1), num_classes)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, max_len)\n",
        "        x = self.embedding(x)  # (batch_size, max_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1)  # Rearrange to (batch_size, embed_dim, max_len)\n",
        "        x = F.relu(self.conv(x))  # Apply convolution: (batch_size, 50, max_len-3+1)\n",
        "        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 50 * (max_len-3+1))\n",
        "        x = self.fc(x)  # Fully connected layer: (batch_size, num_classes)\n",
        "        return x\n",
        "\n",
        "vocab_size = len(train_vocab)\n",
        "embed_dim = 50  # Reduced embedding dimension for simplicity\n",
        "num_classes = 2\n",
        "\n",
        "model = SimpleCNNModel(vocab_size, embed_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    print('==='*50)\n",
        "    for batch_data, batch_labels in train_dataloader:\n",
        "        outputs = model(batch_data)  # logits\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Sample inference\n",
        "sample_text = \"I really love this movie\"\n",
        "sample_sequence = text_to_sequence(sample_text.split(), train_vocab)\n",
        "sample_sequence_padded = pad_sequence(sample_sequence, max_len)\n",
        "sample_data = torch.tensor([sample_sequence_padded], dtype=torch.long)\n",
        "output = model(sample_data)  # logits\n",
        "\n",
        "print(output)\n",
        "\n",
        "_, predicted = torch.max(output, 1)\n",
        "print(f'Predicted: {predicted.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEc02VIT_d4v",
        "outputId": "f3468523-34ba-46ef-94c3-13ee92000463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Batch: \n",
            "[([2, 7, 8, 3], 1), ([20, 3, 2, 21, 22], 1)]\n",
            "Unpacked:\n",
            "([2, 7, 8, 3], 1) ([20, 3, 2, 21, 22], 1)\n",
            "Zipped:\n",
            "<zip object at 0x790e79ca9280>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: \n",
            "[([14, 15], 0), ([9, 10, 11], 0)]\n",
            "Unpacked:\n",
            "([14, 15], 0) ([9, 10, 11], 0)\n",
            "Zipped:\n",
            "<zip object at 0x790e9d6618c0>\n",
            "Batch: \n",
            "[([12, 13], 1), ([4, 5, 6], 0)]\n",
            "Unpacked:\n",
            "([12, 13], 1) ([4, 5, 6], 0)\n",
            "Zipped:\n",
            "<zip object at 0x790e9dc7e0c0>\n",
            "Batch: \n",
            "[([18, 3, 19], 0), ([2, 16, 17], 1)]\n",
            "Unpacked:\n",
            "([18, 3, 19], 0) ([2, 16, 17], 1)\n",
            "Zipped:\n",
            "<zip object at 0x790e79492140>\n",
            "Epoch [1/2], Loss: 0.8213\n",
            "======================================================================================================================================================\n",
            "Batch: \n",
            "[([4, 5, 6], 0), ([2, 7, 8, 3], 1)]\n",
            "Unpacked:\n",
            "([4, 5, 6], 0) ([2, 7, 8, 3], 1)\n",
            "Zipped:\n",
            "<zip object at 0x790e8cc8b280>\n",
            "Batch: \n",
            "[([2, 16, 17], 1), ([20, 3, 2, 21, 22], 1)]\n",
            "Unpacked:\n",
            "([2, 16, 17], 1) ([20, 3, 2, 21, 22], 1)\n",
            "Zipped:\n",
            "<zip object at 0x790e8cb0a740>\n",
            "Batch: \n",
            "[([18, 3, 19], 0), ([9, 10, 11], 0)]\n",
            "Unpacked:\n",
            "([18, 3, 19], 0) ([9, 10, 11], 0)\n",
            "Zipped:\n",
            "<zip object at 0x790e8cb0a740>\n",
            "Batch: \n",
            "[([12, 13], 1), ([14, 15], 0)]\n",
            "Unpacked:\n",
            "([12, 13], 1) ([14, 15], 0)\n",
            "Zipped:\n",
            "<zip object at 0x790e794dc9c0>\n",
            "Epoch [2/2], Loss: 0.6567\n",
            "tensor([[-0.3525,  0.1536]], grad_fn=<AddmmBackward0>)\n",
            "Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "uDfRnhUZ_Gfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c943cca9-9186-47d5-f2f3-fe27f75e87c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline / Sklearn"
      ],
      "metadata": {
        "id": "TbynZe0D8Ydm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X = pd.DataFrame(\n",
        "    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n",
        "     'state' : ['NY', 'NJ', 'ON', 'QB'],\n",
        "     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n",
        "               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n",
        "     'expert_rating': [5, 3, 4, 5],\n",
        "     'user_rating': [4, 5, 4, 3]})\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "RYB5Axo269HR",
        "outputId": "55856af5-d66e-4d79-f8d8-c9599090624d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       city state                         title  expert_rating  user_rating\n",
              "0    London    NY                  His Last Bow              5            4\n",
              "1    London    NJ  How Watson Learned the Trick              3            5\n",
              "2     Paris    ON              A Moveable Feast              4            4\n",
              "3  Sallisaw    QB           The Grapes of Wrath              5            3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9086bc27-8ec8-4fe5-a725-bc155724b288\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>title</th>\n",
              "      <th>expert_rating</th>\n",
              "      <th>user_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>London</td>\n",
              "      <td>NY</td>\n",
              "      <td>His Last Bow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>London</td>\n",
              "      <td>NJ</td>\n",
              "      <td>How Watson Learned the Trick</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paris</td>\n",
              "      <td>ON</td>\n",
              "      <td>A Moveable Feast</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sallisaw</td>\n",
              "      <td>QB</td>\n",
              "      <td>The Grapes of Wrath</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9086bc27-8ec8-4fe5-a725-bc155724b288')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9086bc27-8ec8-4fe5-a725-bc155724b288 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9086bc27-8ec8-4fe5-a725-bc155724b288');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-803fab7c-00bc-4f24-a688-49d63cf44b0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-803fab7c-00bc-4f24-a688-49d63cf44b0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-803fab7c-00bc-4f24-a688-49d63cf44b0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3c0bafd8-a15e-40ea-a58c-7a3f91ba87be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3c0bafd8-a15e-40ea-a58c-7a3f91ba87be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"London\",\n          \"Paris\",\n          \"Sallisaw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"NJ\",\n          \"QB\",\n          \"NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"How Watson Learned the Trick\",\n          \"The Grapes of Wrath\",\n          \"His Last Bow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expert_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector\n",
        "\n",
        "# using columntrasnformer avoids data leakage that happens if we preprocess before splitting/sklearn training.\n",
        "# Also, can be parameterized.\n",
        "\n",
        "column_trans = ColumnTransformer(\n",
        "    [('categories', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['city']), # list for most transformers like this one\n",
        "     ('title_bow', CountVectorizer(), 'title'),\n",
        "     ('standard_scaler', StandardScaler(), make_column_selector(dtype_include=np.number))\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# NOTE:\n",
        "# shouldn't fit before split\n",
        "column_trans.fit(X)\n",
        "\n",
        "column_trans.get_feature_names_out()\n",
        "\n",
        "feature_set = column_trans.transform(X)#.toarray()\n",
        "feature_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "bpPEb5Px8dIf",
        "outputId": "0caa41dd-bd56-4fc8-c47e-8bad8c7a7052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('categories',\n",
              "                                 OneHotEncoder(dtype='int',\n",
              "                                               handle_unknown='ignore'),\n",
              "                                 ['city']),\n",
              "                                ('title_bow', CountVectorizer(), 'title'),\n",
              "                                ('standard_scaler', StandardScaler(),\n",
              "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90>)])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>categories</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>title_bow</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>standard_scaler</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['categories__city_London', 'categories__city_Paris',\n",
              "       'categories__city_Sallisaw', 'title_bow__bow', 'title_bow__feast',\n",
              "       'title_bow__grapes', 'title_bow__his', 'title_bow__how',\n",
              "       'title_bow__last', 'title_bow__learned', 'title_bow__moveable',\n",
              "       'title_bow__of', 'title_bow__the', 'title_bow__trick',\n",
              "       'title_bow__watson', 'title_bow__wrath',\n",
              "       'standard_scaler__expert_rating', 'standard_scaler__user_rating'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.90453403,  0.        ],\n",
              "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
              "         0.        , -1.50755672,  1.41421356],\n",
              "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        , -0.30151134,  0.        ],\n",
              "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.90453403, -1.41421356]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "import joblib\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = make_pipeline(column_trans, RandomForestClassifier())\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X.drop(columns=['user_rating']),\n",
        "    X['user_rating'],\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the pipeline for future use\n",
        "joblib.dump(pipeline, 'pipeline.pkl')\n",
        "\n",
        "# Later, load the pipeline and use it to make predictions on new data\n",
        "pipeline_loaded = joblib.load('pipeline.pkl')\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = pipeline_loaded.predict(X_valid)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "yaMpQrVS-vEO",
        "outputId": "41368304-26a4-41d3-bcc2-c52daa3bcb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('categories',\n",
              "                                                  OneHotEncoder(dtype='int',\n",
              "                                                                handle_unknown='ignore'),\n",
              "                                                  ['city']),\n",
              "                                                 ('title_bow',\n",
              "                                                  CountVectorizer(), 'title'),\n",
              "                                                 ('standard_scaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90>)])),\n",
              "                ('randomforestclassifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>columntransformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>categories</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>title_bow</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>standard_scaler</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7ac0ccfecf90&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# can use cross_val_score for pileine\n",
        "\n",
        "scores = cross_val_score(pipeline, X.drop(columns=['user_rating']), X['user_rating'], cv=2)\n",
        "print(f\"Mean accuracy: {scores.mean():.2f}+/-{scores.std():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bErLizKk8dGK",
        "outputId": "f4f73daa-d5d4-49b6-f3ea-038711f23910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.25+/-0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "eN9R03nzkIG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "embedding_model = \"all-MiniLM-L12-v2\""
      ],
      "metadata": {
        "id": "Cjamqpgpll2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dec2fe4-d8e1-4dd7-b5af-583f7dd64d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "782BsT8iv-rR",
        "outputId": "62502b33-e091-42df-fbcb-3acc99c65302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
        "                                stop_words = 'english',\n",
        "                                lowercase = True,\n",
        "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
        "                                max_df = 0.5,\n",
        "                                min_df = 1)\n",
        "\n",
        "dtm_tf = tf_vectorizer.fit_transform(docs)\n",
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "dtm_tfidf = tfidf_vectorizer.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = dtm_tf.toarray()\n",
        "dense_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZSqLl0eNca7",
        "outputId": "3027f761-badc-4656-852f-04971ea74c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix_tfidf = dtm_tfidf.toarray()\n",
        "print(dense_matrix_tfidf.shape)\n",
        "dense_matrix_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkuUfBpcN9yE",
        "outputId": "e5d989f5-4965-4ae6-f55e-bcc60dcd235b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.35355339, 0.        , 0.        ,\n",
              "        0.35355339, 0.        , 0.35355339, 0.        , 0.        ,\n",
              "        0.35355339, 0.35355339, 0.        , 0.        , 0.35355339,\n",
              "        0.        , 0.        , 0.35355339, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.35355339, 0.        , 0.        ],\n",
              "       [0.        , 0.37410477, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.46369322, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.46369322, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.46369322, 0.46369322, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.27430356, 0.        , 0.3399922 , 0.3399922 ,\n",
              "        0.        , 0.3399922 , 0.        , 0.        , 0.3399922 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.3399922 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3399922 , 0.        , 0.        , 0.3399922 , 0.3399922 ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.70392028, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.43624552,\n",
              "        0.35196014, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.43624552, 0.        , 0.        , 0.        ],\n",
              "       [0.39835162, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.32138758, 0.39835162, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.39835162, 0.        ,\n",
              "        0.32138758, 0.39835162, 0.        , 0.        , 0.39835162,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "uDxUZISdv-pM",
        "outputId": "ce4127f1-94fa-4177-f9e7-05d00bd73043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-5 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-5 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-5 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-5 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-5 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LatentDirichletAllocation<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-6 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-6 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-6 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-6 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-6 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LatentDirichletAllocation<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "# for TF DTM\n",
        "lda_tf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tf.fit(dtm_tf)\n",
        "\n",
        "# for TFIDF DTM\n",
        "lda_tfidf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tfidf.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCKyiTWEve41",
        "outputId": "d980b938-679e-4e74-a041-03d0e15bcefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from pyLDAvis import lda_model as psk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "_UC_HKnLPA_n",
        "outputId": "edeb4e56-5bf7-4c3b-b65b-1b8772f809a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "corpus = docs.copy()\n",
        "\n",
        "# Preprocessing the corpus\n",
        "tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# Creating the dictionary\n",
        "dictionary = corpora.Dictionary(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35wyJZsXOq2N",
        "outputId": "29f5ef9c-58dc-4ecd-eb1b-226734dc6ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BHIyW4OrTm",
        "outputId": "2de13467-19f4-49c2-89ba-f340593af271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'wrought-iron',\n",
              "  'lattice',\n",
              "  'tower',\n",
              "  'on',\n",
              "  'the',\n",
              "  'champ',\n",
              "  'de',\n",
              "  'mars',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'france.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall,',\n",
              "  'about',\n",
              "  'the',\n",
              "  'same',\n",
              "  'height',\n",
              "  'as',\n",
              "  'an',\n",
              "  '81-story',\n",
              "  'building.'],\n",
              " ['it',\n",
              "  'held',\n",
              "  'this',\n",
              "  'title',\n",
              "  'for',\n",
              "  '41',\n",
              "  'years',\n",
              "  'until',\n",
              "  'the',\n",
              "  'chrysler',\n",
              "  'building',\n",
              "  'in',\n",
              "  'new',\n",
              "  'york',\n",
              "  'city',\n",
              "  'was',\n",
              "  'finished',\n",
              "  'in',\n",
              "  '1930.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'three',\n",
              "  'levels',\n",
              "  'for',\n",
              "  'visitors,',\n",
              "  'with',\n",
              "  'restaurants',\n",
              "  'on',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.'],\n",
              " ['tickets',\n",
              "  'can',\n",
              "  'be',\n",
              "  'purchased',\n",
              "  'to',\n",
              "  'ascend',\n",
              "  'by',\n",
              "  'stairs',\n",
              "  'or',\n",
              "  'lift',\n",
              "  'to',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.']]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XidTIK7yOtHg",
        "outputId": "fa06ad14-9dbf-4f2f-edd1-b627fdf0181b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x790e79376e00>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRm-v7jeP-sk",
        "outputId": "1b4aad7a-3a6c-4304-dfd9-10cb28a688ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'champ': 1, 'de': 2, 'eiffel': 3, 'france.': 4, 'in': 5, 'is': 6, 'lattice': 7, 'mars': 8, 'on': 9, 'paris,': 10, 'the': 11, 'tower': 12, 'wrought-iron': 13, '324': 14, '81-story': 15, 'about': 16, 'an': 17, 'as': 18, 'building.': 19, 'height': 20, 'meters': 21, 'same': 22, 'tall,': 23, '1930.': 24, '41': 25, 'building': 26, 'chrysler': 27, 'city': 28, 'finished': 29, 'for': 30, 'held': 31, 'it': 32, 'new': 33, 'this': 34, 'title': 35, 'until': 36, 'was': 37, 'years': 38, 'york': 39, 'and': 40, 'first': 41, 'has': 42, 'levels': 43, 'levels.': 44, 'restaurants': 45, 'second': 46, 'three': 47, 'visitors,': 48, 'with': 49, 'ascend': 50, 'be': 51, 'by': 52, 'can': 53, 'lift': 54, 'or': 55, 'purchased': 56, 'stairs': 57, 'tickets': 58, 'to': 59}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the document-term-frequency matrix\n",
        "doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcFKUHZPUju",
        "outputId": "e60f5a15-800a-4643-8c1b-fd29556b37d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1),\n",
              "  (1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 2),\n",
              "  (12, 2),\n",
              "  (13, 1)],\n",
              " [(6, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (14, 1),\n",
              "  (15, 1),\n",
              "  (16, 1),\n",
              "  (17, 1),\n",
              "  (18, 1),\n",
              "  (19, 1),\n",
              "  (20, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 1)],\n",
              " [(5, 2),\n",
              "  (11, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (35, 1),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 1)],\n",
              " [(9, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1),\n",
              "  (44, 1),\n",
              "  (45, 1),\n",
              "  (46, 1),\n",
              "  (47, 1),\n",
              "  (48, 1),\n",
              "  (49, 1)],\n",
              " [(11, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (44, 1),\n",
              "  (46, 1),\n",
              "  (50, 1),\n",
              "  (51, 1),\n",
              "  (52, 1),\n",
              "  (53, 1),\n",
              "  (54, 1),\n",
              "  (55, 1),\n",
              "  (56, 1),\n",
              "  (57, 1),\n",
              "  (58, 1),\n",
              "  (59, 2)]]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLxrzWRZwDy6",
        "outputId": "35188cba-23d4-44c6-d929-8308602791f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic ID: 0\n",
            "Keywords: 0.060*\"in\" + 0.034*\"for\" + 0.034*\"was\" + 0.034*\"chrysler\" + 0.034*\"years\" + 0.034*\"it\" + 0.034*\"this\" + 0.034*\"building\" + 0.034*\"1930.\" + 0.034*\"until\"\n",
            "\n",
            "Topic ID: 1\n",
            "Keywords: 0.065*\"to\" + 0.037*\"and\" + 0.037*\"first\" + 0.037*\"levels.\" + 0.037*\"second\" + 0.037*\"by\" + 0.037*\"stairs\" + 0.037*\"lift\" + 0.037*\"purchased\" + 0.037*\"or\"\n",
            "\n",
            "Topic ID: 2\n",
            "Keywords: 0.098*\"the\" + 0.067*\"tower\" + 0.036*\"is\" + 0.036*\"on\" + 0.021*\"same\" + 0.021*\"324\" + 0.021*\"an\" + 0.021*\"as\" + 0.021*\"meters\" + 0.021*\"tall,\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the LDA model\n",
        "lda_model = models.LdaModel(\n",
        "    corpus=doc_term_matrix,\n",
        "    id2word=dictionary,\n",
        "    num_topics=3,\n",
        "    passes=10\n",
        ")\n",
        "\n",
        "# Print the topics and their associated keywords\n",
        "for topic_id, topic_keywords in lda_model.print_topics():\n",
        "    print(f\"Topic ID: {topic_id}\")\n",
        "    print(f\"Keywords: {topic_keywords}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.039 + 0.025 + 0.021 + 0.019 + 0.018 + 0.017 + 0.017 + 0.017 + 0.017 + 0.017 + 0.016 + 0.016"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3Sde2YeMEb",
        "outputId": "b2a95c72-acf6-4914-9d22-bb69814fa16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2390000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# probabilityies of classes\n",
        "count = 0\n",
        "for doc in lda_model[doc_term_matrix]:\n",
        "  print('doc: ', count, doc)\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A588pKN5SQlS",
        "outputId": "532ff48c-e32c-4873-8c12-b93a3b505f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc:  0 [(0, 0.020546991), (1, 0.019881219), (2, 0.95957184)]\n",
            "doc:  1 [(0, 0.02252996), (1, 0.022557931), (2, 0.9549121)]\n",
            "doc:  2 [(0, 0.96567845), (1, 0.016908834), (2, 0.017412743)]\n",
            "doc:  3 [(0, 0.021457594), (1, 0.023028541), (2, 0.9555139)]\n",
            "doc:  4 [(0, 0.019870628), (1, 0.9593015), (2, 0.020827854)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "zLltgZMQwDvl",
        "outputId": "ca082796-8db0-4e41-9d3a-12d1021cb1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el10991331030687302402002158436\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el10991331030687302402002158436_data = {\"mdsDat\": {\"x\": [0.07871256129178125, -0.08568363624636055, 0.006971074954579274], \"y\": [-0.04421019106861899, -0.034231446813707704, 0.07844163788232665], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [54.64855640343214, 24.539792308084678, 20.811651288483183]}, \"tinfo\": {\"Term\": [\"to\", \"in\", \"by\", \"stairs\", \"lift\", \"purchased\", \"or\", \"be\", \"tickets\", \"can\", \"ascend\", \"it\", \"years\", \"was\", \"chrysler\", \"this\", \"until\", \"building\", \"city\", \"1930.\", \"title\", \"held\", \"new\", \"york\", \"finished\", \"41\", \"and\", \"first\", \"levels.\", \"second\", \"tower\", \"is\", \"on\", \"the\", \"same\", \"324\", \"an\", \"as\", \"meters\", \"tall,\", \"81-story\", \"about\", \"building.\", \"height\", \"restaurants\", \"levels\", \"three\", \"has\", \"visitors,\", \"with\", \"paris,\", \"mars\", \"champ\", \"lattice\", \"eiffel\", \"de\", \"france.\", \"a\", \"wrought-iron\", \"second\", \"for\", \"it\", \"was\", \"years\", \"chrysler\", \"this\", \"building\", \"until\", \"city\", \"1930.\", \"title\", \"held\", \"new\", \"york\", \"finished\", \"41\", \"in\", \"for\", \"or\", \"ascend\", \"by\", \"lift\", \"be\", \"purchased\", \"stairs\", \"tickets\", \"can\", \"wrought-iron\", \"a\", \"de\", \"france.\", \"the\", \"champ\", \"mars\", \"height\", \"with\", \"second\", \"and\", \"first\", \"levels.\", \"tower\", \"on\", \"is\", \"tall,\", \"about\", \"to\", \"by\", \"stairs\", \"lift\", \"purchased\", \"or\", \"be\", \"tickets\", \"can\", \"ascend\", \"and\", \"first\", \"levels.\", \"second\", \"41\", \"finished\", \"until\", \"city\", \"it\", \"title\", \"years\", \"this\", \"new\", \"york\", \"building\", \"was\", \"chrysler\", \"held\", \"1930.\", \"wrought-iron\", \"the\", \"a\", \"france.\", \"de\", \"eiffel\", \"lattice\", \"champ\", \"mars\", \"paris,\", \"tower\", \"on\", \"in\", \"is\", \"for\", \"three\"], \"Freq\": [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.9129685930806364, 1.569165156539865, 1.5689114122691197, 4.270011845411979, 0.8974492676744348, 0.8974294795300859, 0.8974289909339291, 0.8974269551166093, 0.8974198704723362, 0.8974160431357749, 0.8974122972319064, 0.8974096099530442, 0.8974070041068748, 0.8973991865683666, 0.897391939058708, 0.8973803756163312, 0.8973800498855601, 0.8973793169913249, 0.8973770368759267, 0.897369382202804, 0.8959654825790392, 0.8957451257123392, 0.8955983839999248, 0.8955803873748174, 0.8954303069219984, 0.8953710239216446, 0.8953598676427318, 0.8953022947289266, 0.895206937045665, 0.894562478714895, 0.8949996908425049, 0.6707427698916186, 0.6707431355630105, 0.6707427698916186, 0.670743062428732, 0.6707416728774431, 0.6707411609374945, 0.6707403564604324, 0.6707402833261541, 0.6707410146689378, 0.6707377236264112, 0.6707374310892976, 0.6707353833295033, 0.6707337743753792, 0.670722657965067, 0.6707149788658382, 1.1790246881420305, 0.6727081804885182, 0.16782011327654764, 0.16783435617726009, 0.16780879574696997, 0.16781336663936805, 0.16781797409890534, 0.16781148343170005, 0.16780747932995932, 0.16781437223569565, 0.16781236104304048, 0.16788388636728577, 0.16788745166335628, 0.16788196659247856, 0.1678813815182516, 0.6680950164775323, 0.16788864009537977, 0.167892845316386, 0.16790023187850134, 0.16789306471922114, 0.16798376950796878, 0.1679777907807121, 0.16797190347130336, 0.16796519340126295, 0.16795568594507493, 0.16791972216368678, 0.1678962277767606, 0.1678930830027907, 0.16789059643732615, 1.076653204151081, 0.6153212757370916, 0.615268245599631, 0.6152489562747768, 0.6152162078390117, 0.6151836454739043, 0.6151679535151001, 0.6151562310636615, 0.6151518894149804, 0.6149847979643149, 0.6176992587432217, 0.6176882805744142, 0.6176601839050929, 0.6176211710905166, 0.15398719200464991, 0.15398182696735127, 0.15397697362436144, 0.15397596574163194, 0.1539751439295602, 0.15397500437656686, 0.15397469425880392, 0.15397474077646836, 0.1539747872941328, 0.1539748493176854, 0.15397379491729143, 0.15397312816410114, 0.15397118992808284, 0.15397092632798437, 0.15396957731571562, 0.15557997234093512, 0.6146732536596777, 0.15551138979766363, 0.15547747842028747, 0.1554692602995699, 0.15543001489667138, 0.1553286373999703, 0.15530725478021642, 0.15520279161177422, 0.15506933243249824, 0.1572142309280119, 0.15534783368949553, 0.1555137156808856, 0.15519556586789798, 0.1541955601295611, 0.15409534557447097], \"Total\": [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.2381385099537234, 1.8922569501845237, 1.892178968122302, 5.552780115549189, 1.2193751160519122, 1.2193699234378228, 1.2193694358998692, 1.2193688565098335, 1.2193667238332413, 1.2193662341928677, 1.2193646284228472, 1.2193639819765751, 1.2193631197170824, 1.2193614883853767, 1.219357090467474, 1.2193539753380918, 1.2193536504878824, 1.2193536080081284, 1.2193531759390994, 1.2193515436235731, 1.2189084808634212, 1.2188407626404993, 1.2187942788755208, 1.218787810026157, 1.2187407891584419, 1.218722250813693, 1.218718727581271, 1.2187011361899467, 1.2186707957538858, 1.6801674193133804, 1.721903431460584, 1.0492620088682765, 1.0492628221131661, 1.0492622513754088, 1.0492637423198101, 1.0492626259510218, 1.0492631225365232, 1.0492619748025678, 1.0492623799322034, 1.0492652325654679, 1.0492638059034827, 1.0492658074259977, 1.0492646483390649, 1.0492652390166792, 1.0492658029940418, 1.0492658504802026, 2.223395138051829, 1.721903431460584, 1.0079329897181177, 1.0080193727526854, 1.0078738802102358, 1.0079054795255278, 1.0079410134616333, 1.007920969704509, 1.0078986455168137, 1.0079475741831732, 1.0079502400125642, 1.2186707957538858, 1.2187011361899467, 1.218722250813693, 1.218718727581271, 5.552780115549189, 1.2187942788755208, 1.2188407626404993, 1.2193614883853767, 1.2193515436235731, 1.6801674193133804, 1.680133584305504, 1.6801406600389692, 1.6801557715402904, 3.2381385099537234, 1.892178968122302, 1.8922569501845237, 1.2193662341928677, 1.2193639819765751, 1.469726347909071, 1.0078738802102358, 1.0078986455168137, 1.0079054795255278, 1.007920969704509, 1.0079329897181177, 1.0079410134616333, 1.0079475741831732, 1.0079502400125642, 1.0080193727526854, 1.680133584305504, 1.6801406600389692, 1.6801557715402904, 1.6801674193133804, 1.0492658504802026, 1.0492658029940418, 1.0492619748025678, 1.0492623799322034, 1.0492620088682765, 1.0492638059034827, 1.0492622513754088, 1.0492626259510218, 1.0492646483390649, 1.0492652390166792, 1.0492631225365232, 1.0492628221131661, 1.0492637423198101, 1.0492658074259977, 1.0492652325654679, 1.2186707957538858, 5.552780115549189, 1.2187011361899467, 1.218718727581271, 1.218722250813693, 1.2187407891584419, 1.218787810026157, 1.2187942788755208, 1.2188407626404993, 1.2189084808634212, 3.2381385099537234, 1.892178968122302, 2.223395138051829, 1.8922569501845237, 1.721903431460584, 1.2193536504878824], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7086, -3.3272, -3.3274, -2.3262, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.886, -3.8861, -3.8861, -3.8861, -3.8861, -3.8861, -3.8876, -3.8879, -3.888, -3.8881, -3.8882, -3.8883, -3.8883, -3.8884, -3.8885, -3.8892, -3.8887, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3765, -3.3766, -3.3766, -2.8125, -3.3736, -4.762, -4.7619, -4.7621, -4.7621, -4.762, -4.7621, -4.7621, -4.762, -4.7621, -4.7616, -4.7616, -4.7616, -4.7617, -3.3805, -4.7616, -4.7616, -4.7615, -4.7616, -4.761, -4.7611, -4.7611, -4.7612, -4.7612, -4.7614, -4.7616, -4.7616, -4.7616, -2.7385, -3.298, -3.2981, -3.2981, -3.2982, -3.2982, -3.2982, -3.2982, -3.2983, -3.2985, -3.2941, -3.2941, -3.2942, -3.2942, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6833, -4.6834, -4.6834, -4.6834, -4.673, -3.299, -4.6734, -4.6736, -4.6737, -4.6739, -4.6746, -4.6747, -4.6754, -4.6763, -4.6625, -4.6745, -4.6734, -4.6754, -4.6819, -4.6826], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4984, 0.417, 0.4169, 0.3416, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2977, 0.2976, 0.2976, 0.2976, 0.2964, 0.2962, 0.2961, 0.2961, 0.296, 0.2959, 0.2959, 0.2959, 0.2958, -0.0261, -0.0501, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.9574, 0.7705, 0.465, -0.3879, -0.3879, -0.3879, -0.3879, -0.3879, -0.3879, -0.3879, -0.3879, -0.388, -0.5774, -0.5774, -0.5774, -0.5774, -0.7127, -0.5774, -0.5775, -0.5778, -0.5779, -0.8979, -0.8979, -0.898, -0.898, -1.5542, -1.0171, -1.0173, -0.5779, -0.5779, 1.2584, 1.0762, 1.0761, 1.0761, 1.076, 1.0759, 1.0759, 1.0759, 1.0759, 1.0755, 0.569, 0.569, 0.569, 0.5689, -0.3493, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.3494, -0.4887, -0.6313, -0.4892, -0.4894, -0.4895, -0.4897, -0.4904, -0.4906, -0.4913, -0.4922, -1.4555, -0.9302, -1.0904, -0.9312, -0.8433, -0.4988]}, \"token.table\": {\"Topic\": [2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 3, 3, 2, 1, 3, 3, 1, 2, 2, 1, 1, 2, 1, 3, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 1, 1, 3, 3, 1, 1, 2, 3, 2, 1, 3, 2, 3, 1, 2, 1, 2, 1, 1, 2, 2], \"Freq\": [0.9530478748018614, 0.8200956746420778, 0.9530473135500829, 0.8200992358564819, 0.8205457189662783, 0.8200996706323992, 0.8200960025392311, 0.5951907689610035, 0.5951907689610035, 0.8200963922125032, 0.992044425960995, 0.9921215494204755, 0.9530497913455369, 0.8201002505570455, 0.9921876334283081, 0.992112467761836, 0.8204830112286186, 0.9530492283942898, 0.9530504658564177, 0.8205315028361378, 0.8205190216785264, 0.9530473566817258, 0.5951882623784642, 0.5951882623784642, 0.5807526611128023, 0.5807526611128023, 0.8205338749365484, 0.8201066478439729, 0.8201013477341774, 0.9530473526561836, 0.449762609841908, 0.449762609841908, 1.056938910862486, 0.9530508028958278, 0.8204873660317774, 0.8201064007871289, 0.5951829091913576, 0.5951829091913576, 0.992156526890548, 0.8204517199060506, 0.8200978265639127, 0.9530484054551458, 1.056982470312887, 0.9921294472955625, 0.8204061385245626, 0.9921412789865546, 0.820104305635868, 0.8200921823284338, 0.5951787830814274, 0.5951787830814274, 0.9921632541605773, 0.8200981558767926, 0.7203598768117953, 0.1800899692029488, 0.1800899692029488, 0.9530502423963004, 0.8201066192731571, 0.992115091710386, 0.9530491706410635, 0.6803987704395893, 0.9264582076332718, 0.9530508338379107, 0.8201069384428659, 0.9530500642213234, 0.8201080362995881, 0.8205661475471617, 0.9530505826252358, 0.9530478689422245], \"Term\": [\"1930.\", \"324\", \"41\", \"81-story\", \"a\", \"about\", \"an\", \"and\", \"and\", \"as\", \"ascend\", \"be\", \"building\", \"building.\", \"by\", \"can\", \"champ\", \"chrysler\", \"city\", \"de\", \"eiffel\", \"finished\", \"first\", \"first\", \"for\", \"for\", \"france.\", \"has\", \"height\", \"held\", \"in\", \"in\", \"is\", \"it\", \"lattice\", \"levels\", \"levels.\", \"levels.\", \"lift\", \"mars\", \"meters\", \"new\", \"on\", \"or\", \"paris,\", \"purchased\", \"restaurants\", \"same\", \"second\", \"second\", \"stairs\", \"tall,\", \"the\", \"the\", \"the\", \"this\", \"three\", \"tickets\", \"title\", \"to\", \"tower\", \"until\", \"visitors,\", \"was\", \"with\", \"wrought-iron\", \"years\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el10991331030687302402002158436\", ldavis_el10991331030687302402002158436_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el10991331030687302402002158436\", ldavis_el10991331030687302402002158436_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el10991331030687302402002158436\", ldavis_el10991331030687302402002158436_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# # Preprocessing the corpus\n",
        "# tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# # Creating the dictionary\n",
        "# dictionary = corpora.Dictionary(tokenized_corpus)\n",
        "\n",
        "# # Creating the document-term matrix\n",
        "# doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "\n",
        "# # Training the LDA model\n",
        "# lda_model = models.LdaModel(\n",
        "#     corpus=doc_term_matrix,\n",
        "#     id2word=dictionary,\n",
        "#     num_topics=3,\n",
        "#     passes=10\n",
        "# )\n",
        "\n",
        "# Prepare the data for visualization\n",
        "lda_vis_data = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "ApGfuqklwDs_",
        "outputId": "c584a5c0-f363-40d3-a146-ce2c3c2caa13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bertopic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-970680bb9872>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Example corpus of documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "import pyLDAvis\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# Initialize and train the Bertopic model\n",
        "bertopic_model = BERTopic()\n",
        "topics, _ = bertopic_model.fit_transform(docs)\n",
        "\n",
        "# Convert the topics to a Pandas DataFrame\n",
        "df_topics = pd.DataFrame(topics, columns=[\"Topic\"])\n",
        "\n",
        "# Generate the topic visualization using pyLDAvis\n",
        "lda_vis_data = pyLDAvis.prepare(\n",
        "    df_topics,\n",
        "    bertopic_model.transform(docs),\n",
        "    bertopic_model.get_topics(),\n",
        "    df_topics[\"Topic\"].value_counts(),\n",
        "    R=10,  # Number of relevant terms to display per topic\n",
        "    lambda_step=0.01\n",
        ")\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkR5yJXswDql"
      },
      "outputs": [],
      "source": [
        "%pip show pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvsR34hmwDoT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0yBckH8wDl5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-wbJfySTl6fU",
        "jWlLeyIPl9Qp",
        "aSEQn2lKe_Ub",
        "jaP_tMYU-gE0",
        "eWiz7u1_3Y2x",
        "eN9R03nzkIG2"
      ],
      "authorship_tag": "ABX9TyNFVMgF4LHyaxewYwFvLWP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}